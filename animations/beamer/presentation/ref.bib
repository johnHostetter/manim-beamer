@ARTICLE{efficient_processing_of_dnns,
  author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S.},
  journal={Proceedings of the IEEE},
  title={Efficient Processing of Deep Neural Networks: A Tutorial and Survey},
  year={2017},
  volume={105},
  number={12},
  pages={2295-2329},
  keywords={Neurons;Biological neural networks;Artificial intelligence;Machine learning;Neural networks;Tutorials;Convolutional neural networks;Artificial intelligence;Benchmark testing;Computer architecture;ASIC;computer architecture;convolutional neural networks;dataflow processing;deep learning;deep neural networks;energy-efficient accelerators;low power;machine learning;spatial architectures;VLSI},
  doi={10.1109/JPROC.2017.2761740}}


@article{aghaeipoor_mokblmoms_2019,
	title = {{MOKBL}+{MOMs}: {An} interpretable multi-objective evolutionary fuzzy system for learning high-dimensional regression data},
	volume = {496},
	issn = {0020-0255},
	shorttitle = {{MOKBL}+{MOMs}},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025519303494},
	doi = {10.1016/j.ins.2019.04.035},
	abstract = {This work presents a multi-objective evolutionary linguistic fuzzy system that addresses regression problems, especially those that are dimensional and scalable. A multi-objective knowledge base learning (MOKBL) is developed in the first stage of this model. MOKBL learns the most relevant and least redundant features by considering the desirability of the components of the fuzzy system. At the same time as feature selection, MOKBL slightly tunes the membership functions to provide greater initial adaptation of the fuzzy rule-based system components. In the second stage, multi-objective modifications (MOMs) are organized to modify the generated fuzzy system and to perform post-processing tasks. MOMs more finely tune the membership functions and prune additional rules. The newly proposed rule pruning method can eliminate weak rules from the rule base using the concepts of support and confidence. The membership functions tuning process is accomplished using the tasks of core displacement and width alteration of the symmetric functions. MOKBL+MOMs and its stages were validated using 28 real-world datasets and compared with two state-of-the-art regression solutions through non-parametric statistical tests. The experimental results confirmed the effectiveness of MOKBL+MOMs in terms of interpretability (complexity), accuracy, and time.},
	language = {en},
	urldate = {2023-05-25},
	journal = {Information Sciences},
	author = {Aghaeipoor, Fatemeh and Javidi, Mohammad Masoud},
	month = sep,
	year = {2019},
	keywords = {Fuzzy feature selection, Fuzzy mutual information, Fuzzy rule-based systems, High-dimensional regression problems, Multi-objective evolutionary algorithms, Rule pruning},
	pages = {1--24},
}

@article{van2011effects,
  title={Effects of worked examples, example-problem, and problem-example pairs on novices’ learning},
  author={Van Gog, Tamara and Kester, Liesbeth and Paas, Fred},
  journal={Contemporary Educational Psychology},
  volume={36},
  number={3},
  pages={212--218},
  year={2011},
  publisher={Elsevier}
}

@article{renkl2002,
  title={From example study to problem solving: Smooth transitions help learning},
  author={Renkl, Alexander and Atkinson, Robert K and Maier, Uwe H and Staley, Richard},
  journal={J Exp Educ},
  volume={70},
  number={4},
  pages={293--315},
  year={2002},
  publisher={Taylor \& Francis}
}

@incollection{najar2014,
  title={Adaptive Support versus Alternating Worked Examples and Tutored Problems: Which Leads to Better Learning?},
  author={Najar, Amir Shareghi and Mitrovic, Antonija and McLaren, Bruce M},
  booktitle={UMAP},
  pages={171--182},
  year={2014},
  publisher={Springer}
}

@ARTICLE{fuzzy_logic,
  author={Zadeh, L.A.},
  journal={Computer}, 
  title={Fuzzy logic}, 
  year={1988},
  volume={21},
  number={4},
  pages={83-93},
  keywords={Fuzzy logic;Decision making;Linguistics;Application software;Process control;Fuzzy sets;Expert systems;Uncertainty;Precision engineering},
  doi={10.1109/2.53}}

@article{giles1976lukasiewicz,
  title={{\L}ukasiewicz logic and fuzzy set theory},
  author={Giles, Robin},
  journal={International Journal of Man-Machine Studies},
  volume={8},
  number={3},
  pages={313--327},
  year={1976},
  publisher={Elsevier}
}

@article{is_there_a_need_for_fuzzy_logic,
title = {Is there a need for fuzzy logic?},
journal = {Information Sciences},
volume = {178},
number = {13},
pages = {2751-2779},
year = {2008},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508000716},
author = {Lotfi A. Zadeh},
keywords = {Fuzzy logic, Fuzzy sets, Approximate reasoning, Computing with words, Computing with perceptions, Generalized theory of uncertainty},
}

@INPROCEEDINGS{equivalence_implications,  author={Ciftioglu, O.},  booktitle={FUZZ},   title={On the implication of equivalence of fuzzy systems to neural networks},   year={2003},  volume={1},  number={},  pages={19-24 vol.1},  
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/839006
@ARTICLE{fls_ann_equivalence,  author={Hong-Xing Li and Chen, C.L.P.},  journal={IEEE Transactions on Neural Networks},   title={The equivalence between fuzzy logic systems and feedforward neural networks},   year={2000},  volume={11},  number={2},  pages={356-365},  
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/977279
@ARTICLE{black_box_ext,  author={Castro, J.L. and Mantas, C.J. and Benitez, J.M.},  journal={IEEE Transactions on Neural Networks},   title={Interpretation of artificial neural networks by means of fuzzy rules},   year={2002},  volume={13},  number={1},  pages={101-116},  
}

@article{kosko_blue_book,
    author = {Kosko, Bart and Burgess, John C.},
    title = "{Neural Networks and Fuzzy Systems}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {103},
    number = {6},
    pages = {3131-3131},
    year = {1998},
    month = {06},
    issn = {0001-4966},
    doi = {10.1121/1.423096},
    url = {https://doi.org/10.1121/1.423096},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/103/6/3131/8084637/3131\_1\_online.pdf},
}

@ARTICLE{are_ann_black_boxes,
  author={Benitez, J.M. and Castro, J.L. and Requena, I.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Are artificial neural networks black boxes?}, 
  year={1997},
  volume={8},
  number={5},
  pages={1156-1164},
  keywords={Artificial neural networks;Neurons;Neural networks;Fuzzy neural networks;Fuzzy systems;Fuzzy logic;Multi-layer neural network;Artificial intelligence;Knowledge based systems;Computer networks},
  doi={10.1109/72.623216}}

@ARTICLE{are_ann_white_boxes,
  author={Kolman, E. and Margaliot, M.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Are artificial neural networks white boxes?}, 
  year={2005},
  volume={16},
  number={4},
  pages={844-852},
  keywords={Artificial neural networks;Neural networks;Fuzzy neural networks;Fuzzy systems;Fuzzy reasoning;Logistics;Computer networks;Equations;Fuzzy sets;Mathematical model;Feedforward neural networks;hybrid intelligent systems;knowledge-based networks;rule extraction;rule generation;rule refinement},
  doi={10.1109/TNN.2005.849843}}

@ARTICLE{new_lers,
  title={A New Version of the Rule Induction System LERS},
  author={Jerzy W. Grzymala-Busse},
  journal={Fundam. Informaticae},
  year={1997},
  volume={31},
  pages={27-39}
}

% https://ieeexplore.ieee.org/document/159070
@ARTICLE{wang_mendel_universal_function_approx,  author={Wang, L.-X. and Mendel, J.M.},  journal={IEEE Transactions on Neural Networks},   title={Fuzzy basis functions, universal approximation, and orthogonal least-squares learning},   year={1992},  volume={3},  number={5},  pages={807-814},  doi={10.1109/72.159070}}

% https://ieeexplore.ieee.org/document/258721
@INPROCEEDINGS{wang_universal_function_approx,  author={Wang, L.-X.},  booktitle={[1992 Proceedings] IEEE International Conference on Fuzzy Systems},   title={Fuzzy systems are universal approximators},   year={1992},  volume={},  number={},  pages={1163-1170},  doi={10.1109/FUZZY.1992.258721}}

% https://ieeexplore.ieee.org/document/324566
@ARTICLE{kosko_universal_function_approx,  author={Kosko, B.},  journal={IEEE Transactions on Computers},   title={Fuzzy systems as universal approximators},   year={1994},  volume={43},  number={11},  pages={1329-1333},  doi={10.1109/12.324566}}

% http://www.diva-portal.org/smash/get/diva2:316004/FULLTEXT02
@Inbook{fuzzy_modeling_from_grey_box,
author="Lindskog, P.",
editor="Hellendoorn, Hans
and Driankov, Dimiter",
title="Fuzzy Identification from a Grey Box Modeling Point of View",
bookTitle="Fuzzy Model Identification: Selected Approaches",
year="1997",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="3--50",
abstract="The design of mathematical models of complex real-world (and typically nonlinear) systems is essential in many fields of science and engineering. The developed models can be used, e.g., to explain the behavior of the underlying system as well as for prediction and control purposes",
isbn="978-3-642-60767-7",
}

@inproceedings{Ausin2019LeveragingDR,
  title={Leveraging Deep Reinforcement Learning for Pedagogical Policy Induction in an Intelligent Tutoring System},
  author={Markel Sanz Ausin and Hamoon Azizsoltani and Tiffany Barnes and Min Chi},
  booktitle={EDM},
  year={2019}
}

@Article{Gottesman2019,
author={Gottesman, Omer
and Johansson, Fredrik
and Komorowski, Matthieu
and Faisal, Aldo
and Sontag, David
and Doshi-Velez, Finale
and Celi, Leo Anthony},
title={Guidelines for reinforcement learning in healthcare},
journal={Nature Medicine},
year={2019},
month={Jan},
day={01},
volume={25},
number={1},
pages={16-18},
abstract={In this Comment, we provide guidelines for reinforcement learning for decisions about patient treatment that we hope will accelerate the rate at which observational cohorts can inform healthcare practice in a safe, risk-conscious manner.},
issn={1546-170X},
}

@INPROCEEDINGS{dqn_septic_shock,
  author={Kim, Yeo Jin and Ausin, Markel Sanz and Chi, Min},
  booktitle={2021 IEEE International Conference on Big Data (Big Data)}, 
  title={Multi-Temporal Abstraction with Time-Aware Deep Q-Learning for Septic Shock Prevention}, 
  year={2021},
  volume={},
  number={},
  pages={1657-1663}}

% the background

@ARTICLE{ahc,  author={Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},  journal={IEEE Transactions on Systems, Man, and Cybernetics},   title={Neuronlike adaptive elements that can solve difficult learning control problems},   year={1983},  volume={SMC-13},  number={5},  pages={834-846},  doi={10.1109/TSMC.1983.6313077}}

@inproceedings{neuro_fuzzy_survey,
author = {Vieira, José and Morgado-Dias, F. and Mota, Alexandre},
year = {2004},
month = {03},
pages = {},
title = {Neuro-Fuzzy Systems: A Survey}
}

@article{BUCKLEY19941,
title = {Fuzzy neural networks: A survey},
journal = {Fuzzy Sets and Systems},
volume = {66},
number = {1},
pages = {1-13},
year = {1994},
issn = {0165-0114},
doi = {https://doi.org/10.1016/0165-0114(94)90297-6},
url = {https://www.sciencedirect.com/science/article/pii/0165011494902976},
author = {James J. Buckley and Yoichi Hayashi},
keywords = {Neural networks, Learning algorithms, Regression, Fuzzy controller, Fuzzy expert systems, Hierarchical analysis, Fuzzy equations, Universal approximator},
abstract = {In this paper a fuzzy neural network will be a layered, feedforward, neural net that has fuzzy signals and/or fuzzy weights. We survey recent results on learning algorithms and applications for fuzzy neural networks.}
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/995117
@ARTICLE{denfis,  author={Kasabov, N.K. and Qun Song},  journal={IEEE Transactions on Fuzzy Systems},   title={DENFIS: dynamic evolving neural-fuzzy inference system and its application for time-series prediction},   year={2002},  volume={10},  number={2},  pages={144-154},  doi={10.1109/91.995117}}

% https://www.sciencedirect.com/science/article/pii/S1474667016328002
@article{denfis_rl,
title = {A Reinforcement Learning Algorithm with Evolving Fuzzy Neural Networks},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {1},
pages = {1161-1165},
year = {2014},
note = {3rd International Conference on Advances in Control and Optimization of Dynamical Systems (2014)},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140313-3-IN-3024.00058},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016328002},
author = {Hitesh Shah and M. Gopal},
keywords = {Reinforcement learning, Neuro-fuzzy system, preferably taken from the IF AC keyword list},
abstract = {}
}

% the apfrb method

@article{cordova1996intrinsic,
  title={Intrinsic motivation and the process of learning: Beneficial effects of contextualization, personalization, and choice.},
  author={Cordova, Diana I and Lepper, Mark R},
  journal={Journal of educational psychology},
  volume={88},
  number={4},
  pages={715},
  year={1996},
  publisher={American Psychological Association}
}

@article{kinzie1989continuing,
  title={Continuing motivation, learner control, and CAI},
  author={Kinzie, Mable B and Sullivan, Howard J},
  journal={Educational Technology Research and Development},
  volume={37},
  number={2},
  pages={5--14},
  year={1989},
  publisher={Springer}
}

@article{flowerday2004role,
  title={The role of choice and interest in reader engagement},
  author={Flowerday, Terri and Schraw, Gregory and Stevens, Joseph},
  journal={The Journal of Experimental Education},
  volume={72},
  number={2},
  pages={93--114},
  year={2004},
  publisher={Taylor \& Francis}
}

@inproceedings{aleven2000limitations,
  title={Limitations of Student Control: Do Students Know when They Need Help?},
  author={Aleven, Vincent and Koedinger, Kenneth R.},
  booktitle={ITSs},
  pages={292--303},
  year={2000}
}

%   author={Roll, Ido and Wiese, Eliane Stampfer and Long, Yanjin and Aleven, Vincent and Koedinger, Kenneth R},
@article{roll2014tutoring,
  title={Tutoring self-and co-regulation with intelligent tutoring systems to help students acquire better learning skills},
  author={Roll, Ido and others},
  journal={Design recommendations for intelligent tutoring systems},
  volume={2},
  pages={169--182},
  year={2014}
}

@inproceedings{abdelshiheed2023bridging,
    title={Bridging Declarative, Procedural, and Conditional Metacognitive Knowledge Gap Using Deep Reinforcement Learning},
    author={Abdelshiheed, Mark and Hostetter, John Wesley and Barnes, Tiffany and Chi, Min},
    booktitle={Proceedings of the 45th annual conference of the cognitive science society},
    year={2023}
}

@inproceedings{rowe2014optimizing,
  title={Optimizing player experience in interactive narrative planning: a modular reinforcement learning approach},
  author={Rowe, Jonathan and Mott, Bradford and Lester, James},
  booktitle={Tenth Artificial Intelligence and Interactive Digital Entertainment Conference},
  year={2014}
}

@inproceedings{abdelshiheed2023leveraging,
    title={Leveraging Deep Reinforcement Learning for Metacognitive Interventions across Intelligent Tutoring Systems},
    author={Abdelshiheed, Mark and Hostetter, John Wesley and Barnes, Tiffany and Chi, Min},
    booktitle={Proceedings of the 24th International Conference on Artificial Intelligence in Education},
    Organization={Springer International Publishing},
    year={2023}
}

% https://papers.nips.cc/paper/2014/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html
@inproceedings{knowledge_distillation,
 author = {Ba, Jimmy and Caruana, Rich},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Do Deep Nets Really Need to be Deep?},
 volume = {27},
 year = {2014}
}

@ARTICLE{universal,  author={Castro, J.L.},  journal={IEEE Transactions on Systems, Man, and Cybernetics},   title={Fuzzy logic controllers are universal approximators},   year={1995},  volume={25},  number={4},  pages={629-635},  
}

% https://journals.lww.com/jspinaldisorders/Abstract/2009/06000/Fuzzy_logic_assisted_Surgical_Planning_in.6.aspx
@Article{scoliosis,
author={Nault, Marie-Lyne and others
},
title={Fuzzy--logic--assisted {S}urgical {P}lanning in {A}dolescent {I}diopathic {S}coliosis},
journal={Clinical Spine Surgery},
year={2009},
volume={22},
number={4},
keywords={adolescent idiopathic scoliosis; preoperative planning; fuzzy logic; curve fusion levels},
issn={2380-0186},
}

@incollection{control_chaos,
title={{C}haos {C}ontrol {U}sing {F}uzzy {C}ontrollers ({M}amdani {M}odel)},
author={Harb, Ahmad M. and Al-Smadi, Issam},
series={Studies in Fuzziness and Soft Computing},
booktitle={Integration of Fuzzy Logic and Chaos Theory},
publisher={Springer},
address={{B}erlin, {H}eidelberg},
volume={187},
year={2006},
}

% https://www.hindawi.com/journals/afs/2012/989051/
@Article{uav,
author={Sabo, Chelsea
and Cohen, Kelly},
title={Fuzzy {L}ogic {U}nmanned {A}ir {V}ehicle {M}otion {P}lanning},
journal={Advances in Fuzzy Systems},
year={2012},
publisher={Hindawi Publishing Corporation},
volume={2012},
pages={989051},
issn={1687-7101},
}

@article{chen2008hybrid,
  title={Hybrid {C}ontrol for {R}obot {N}avigation - {A} {H}ierarchical {Q}-{L}earning {A}lgorithm},
  author={Chen, Chunlin and Li, Han-Xiong and Dong, Daoyi},
  journal={IEEE Robotics \& Automation Magazine},
  volume={15},
  number={2},
  pages={37--47},
  year={2008},
  publisher={IEEE}
}

% https://libstore.ugent.be/fulltxt/RUG01/002/787/409/RUG01-002787409_2019_0001_AC.pdf
% author={Gevaert, Arne and Peck, Jonathan and Saeys, Yvan},
@misc{anfis_policy_distillation,
author={Gevaert, Arne and others},
title={Distillatie van diepe reinforcement learning modellen},
year={2019},
}

% https://link.springer.com/article/10.1007/s00521-017-3311-2#citeas
% month={Aug},
@Article{its_turkish,
author={Karaci, Abdulkadir},
title={Intelligent tutoring system model based on fuzzy logic and constraint-based student model},
journal={Neural Computing and Applications},
year={2019},
day={01},
volume={31},
number={8},
pages={3619-3628},
issn={1433-3058},
}

% https://link.springer.com/chapter/10.1007/978-3-319-93846-2_67
% https://www.researchgate.net/publication/325866886_Machine_Learning_and_Fuzzy_Logic_Techniques_for_Personalized_Tutoring_of_Foreign_Languages
% author="Troussas, Christos
%and Chrysafiadi, Konstantina
%and Virvou, Maria",
% publisher="Springer International Publishing",
%address="Cham",
@InProceedings{its_aied,
author={Troussas, Christos and others},
title={Machine Learning and Fuzzy Logic Techniques for Personalized Tutoring of Foreign Languages},
booktitle={AIED},
year={2018},
pages={358--362},
}

% month = {12},
@article{its_linear,
author = {Machado, Maria and others},
year = {2016},
pages = {19-26},
title = {A Fuzzy Logic Application in Virtual Education},
volume = {91},
journal = {Procedia Computer Science},
}

% https://www.scirp.org/journal/paperinformation.aspx?paperid=17551
@article{its_fuzzy,
author={Zarandi, Mohammad and others},
title={A {F}uzzy {E}xpert {S}ystem {A}rchitecture for {I}ntelligent {T}utoring {S}ystems: {A} {C}ognitive {M}apping {A}pproach},
journal={Intelligent Learning Systems and Applications}, 
volume={4},
number={1},
year={2012},
pages={29-40},
}

% https://ieeexplore.ieee.org/abstract/document/8392930
@INPROCEEDINGS{ftarm_tfig,  author={Li, Zebang and Bu, Fan and Yu, Fusheng},  booktitle={2017 13th ICNC-FSKD},   title={Temporal fuzzy association rules mining based on fuzzy information granulation},   year={2017},  volume={},  number={},  pages={1168-1174},  
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/4182389
@ARTICLE{apfrb_led,  author={Kolman, Eyal and Margaliot, Michael},  journal={IEEE Transactions on Neural Networks},   title={{K}nowledge {E}xtraction {F}rom {N}eural {N}etworks {U}sing the {A}ll-{P}ermutations {F}uzzy {R}ule {B}ase: {T}he {LED} {D}isplay {R}ecognition {P}roblem},   year={2007},  volume={18},  number={3},  pages={925-931},  }

@book{sutton2018,
  author = "RS. Sutton and AG. Barto",
  title = "Reinforcement Learning: An Introduction",
  publisher = "MIT Press",
  address = "",
  year = "2018"
}

%   author={Mandel, Travis and Liu, Yun-En and Levine, Sergey and Brunskill, Emma and Popovic, Zoran},
@inproceedings{mandel2014offline,
  title={Offline policy evaluation across representations with applications to educational games},
  author={Mandel, Travis and others},
  booktitle={AAMAS},
  pages={1077--1084},
  year={2014}
}

@inproceedings{wang2017interactive,
  title={Interactive narrative personalization with deep reinforcement learning},
  author={Wang, Pengcheng and others},
  booktitle={IJCAI},
  year={2017}
}

@InProceedings{markel_deep_rl_its,
author="Sanz Ausin, Markel
and others",
title="Exploring the Impact of Simple Explanations and Agency on Batch Deep Reinforcement Learning Induced Pedagogical Policies",
booktitle="Artificial Intelligence in Education",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="472--485",
isbn="978-3-030-52237-7"
}

@article{sascha2018choice,
  title={The autonomy-enhancing effects of choice on cognitive load, motivation and learning with digital media},
  author={Sascha Schneider and others},
  journal={Learning and Instruction},
  volume={58},
  pages={161--172},
  year={2018}
}

@article{wood1999help,
  title={Help seeking, learning and contingent tutoring},
  author={Wood, H and Wood, D},
  journal={Computers \& Education},
  volume={33},
  number={2},
  pages={153--169},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{mitrovic2003scaffolding,
  title={Scaffolding and fading problem selection in SQL-Tutor},
  author={Mitrovic, Antonija and Martin, Brent},
  booktitle={AIED},
  pages={479--481},
  year={2003}
}

% the cew method

@misc{offline_rl_survey_2022,
  doi = {10.48550/ARXIV.2203.01387},
  url = {https://arxiv.org/abs/2203.01387},
  author = {Prudencio, Rafael Figueiredo and Maximo, Marcos R. O. A. and Colombini, Esther Luna},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% https://www.sciencedirect.com/science/article/pii/B9781558602007500970
@incollection{aric_1,
title = {Refinement of {A}pproximate {R}easoning-based {C}ontrollers by {R}einforcement {L}earning},
editor = {Lawrence A. Birnbaum and Gregg C. Collins},
booktitle = {Machine Learning Proceedings 1991},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {475-479},
year = {1991},
isbn = {978-1-55860-200-7},
author = {Hamid R. Berenji and Sterling Software},
abstract = {}
}

% https://www.sciencedirect.com/science/article/pii/S0952197699000573
@article{fuzzy_logic_limited_data,
title = {Fuzzy-logic-based process modeling using limited experimental data},
journal = {Engineering Applications of Artificial Intelligence},
volume = {13},
number = {2},
pages = {121-135},
year = {2000},
issn = {0952-1976},
doi = {https://doi.org/10.1016/S0952-1976(99)00057-3},
url = {https://www.sciencedirect.com/science/article/pii/S0952197699000573},
author = {H.H. Lou and Y.L. Huang},
abstract = {Process modeling with limited experimental data is always a difficult task. It becomes even more difficult if the process is highly nonlinear and is characterized by multiple inputs and outputs. Under these circumstances, fuzzy logic may show its capabilities for model development. In this paper, an efficient fuzzy modeling methodology is introduced. The resulting fuzzy model consists of a number of fuzzy implications, each of which is of an IF–THEN form. The IF part consists of a set of logically related antecedents, while the THEN part contains a consequent expressed as a set of linear models. To ensure model simplicity and to accelerate the modeling process, an effective model-development route has been developed. To guarantee the model’s reliability, a t-test-based non-linearity analysis is proposed when each fuzzy implication is developed. The efficacy of the methodology is demonstrated by modeling two nonlinear industrial processes.}
}

@article{anfis,  author={Jang, J.-S.R.},  journal={IEEE Transactions on Systems, Man, and Cybernetics},   title={{ANFIS}: adaptive-network-based fuzzy inference system},   year={1993},  volume={23},  number={3},  pages={665-685},  
}

% https://www.semanticscholar.org/reader/99fda5647aa4063994dde09d9a984878be8fe12b
@article{object_sensitive_drl,
  title={Object-sensitive Deep Reinforcement Learning},
  author={Yuezhang Li and Katia P. Sycara and Rahul Radhakrishnan Iyer},
  journal={ArXiv},
  year={2017},
  volume={abs/1809.06064}
}

% the latent lockstep method

@article{DELVE,
title={The {DELVE} Manual},
author={C.E. Rasmussen and R.M. Neal and G.E. Hinton and D. van Camp and M.Revow and Z. Ghahramani and R. Kustra and R. Tibshirani},
year={1996},
journal={The University of Toronto}
}

@ARTICLE{Corke_robotics,
  author={Corke, P.I.},
  journal={IEEE Robotics & Automation Magazine}, 
  title={A robotics toolbox for MATLAB}, 
  year={1996},
  volume={3},
  number={1},
  pages={24-32},
  doi={10.1109/100.486658}
}

@inproceedings{Rumelhart1986LearningIR,
  title={Learning internal representations by error propagation},
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  year={1986}
}

% FCQL + LERS

@article{llm_hallucination,
	doi = {10.1145/3571730},
  
	url = {https://doi.org/10.1145%2F3571730},
  
	year = 2022,
	month = {nov},
  
	publisher = {Association for Computing Machinery ({ACM})},
  
	author = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Yejin Bang and Andrea Madotto and Pascale Fung},
  
	title = {Survey of Hallucination in Natural Language Generation},
  
	journal = {{ACM} Computing Surveys}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Start of Intelligent Tutoring System References %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{anderson_its,
author = {John R. Anderson  and C. Franklin Boyle  and Brian J. Reiser },
title = {Intelligent Tutoring Systems},
journal = {Science},
volume = {228},
number = {4698},
pages = {456-462},
year = {1985},
}

@article{chi2011empirically,
  title={Empirically evaluating the application of reinforcement learning to the induction of effective and adaptive pedagogical strategies},
  author={Chi, Min and VanLehn, Kurt and Litman, Diane and Jordan, Pamela},
  journal={User Modeling and User-Adapted Interaction},
  volume={21},
  number={1},
  pages={137--180},
  year={2011},
  publisher={Springer}
}

@article{vanlehn2006,
  title={The behavior of tutoring systems},
  author={Vanlehn, Kurt},
  journal={IJAIED},
  volume={16},
  number={3},
  pages={227--265},
  year={2006},
  publisher={IOS Press}
}

@inproceedings{inproceedingsIJCAI19InferGP,
author = {Azizsoltani, Hamoon and Kim, Yeo Jin and Ausin, Markel and Barnes, Tiffany and Chi, Min},
year = {2019},
month = {08},
pages = {1974-1980},
title = {Unobserved Is Not Equal to Non-existent: Using Gaussian Processes to Infer Immediate Rewards Across Contexts},
doi = {10.24963/ijcai.2019/273}
}

@article{liu2022giving,
  title={Giving Feedback on Interactive Student Programs with Meta-Exploration},
  author={Liu, Evan and Stephan, Moritz and Nie, Allen and Piech, Chris and Brunskill, Emma and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36282--36294},
  year={2022}
}

@article{zhou2022leveraging,
  title={Leveraging granularity: Hierarchical reinforcement learning for pedagogical policy induction},
  author={Zhou, Guojing and Azizsoltani, Hamoon and Ausin, Markel Sanz and Barnes, Tiffany and Chi, Min},
  journal={International journal of artificial intelligence in education},
  volume={32},
  number={2},
  pages={454--500},
  year={2022},
  publisher={Springer}
}

@inproceedings{rowe2015improving,
  title={Improving student problem solving in narrative-centered learning environments: A modular reinforcement learning framework},
  author={Rowe, Jonathan P and Lester, James C},
  booktitle={AIED},
  pages={419--428},
  year={2015},
  organization={Springer}
}

@inproceedings{shen2016reinforcement,
  title={Reinforcement Learning: the Sooner the Better, or the Later the Better?},
  author={Shen, Shitian and Chi, Min},
  booktitle={UMAP},
  pages={37--44},
  year={2016},
  organization={ACM}
}

@inproceedings{ju2019importance,
  title={Importance Sampling to Identify Empirically Valid Policies and their Critical Decisions.},
  author={Ju, Song and Shen, Shitian and Azizsoltani, Hamoon and Barnes, Tiffany and Chi, Min},
  booktitle={EDM (Workshops)},
  pages={69--78},
  year={2019}
}

@article{guilford1950fundamental,
  title={Fundamental statistics in psychology and education},
  author={Guilford, Joy Paul},
  year={1950},
  publisher={McGraw-Hill}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  End of Intelligent Tutoring System References  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{discrete_sac,
  author       = {Petros Christodoulou},
  title        = {Soft Actor-Critic for Discrete Action Settings},
  journal      = {CoRR},
  volume       = {abs/1910.07207},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.07207},
  eprinttype    = {arXiv},
  eprint       = {1910.07207},
  timestamp    = {Tue, 22 Oct 2019 18:17:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-07207.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{pawlak1991roughsets,
  title = {Rough Sets: Theoretical Aspects of Reasoning about Data},
  author = {Zdzis{\l}aw Pawlak},
  series = {Theory and Decision Library D},
  publisher = {Springer Dordrecht},
  year = {1991},
  doi = {10.1007/978-94-011-3534-4},
  isbn = {978-0-7923-1472-1},
  note = {Hardcover ISBN: 978-0-7923-1472-1, Published: 31 October 1991},
  url = {https://doi.org/10.1007/978-94-011-3534-4},
  topics = {Artificial Intelligence, Mathematical Logic and Foundations, Operations Research/Decision Theory},
  copyright = {Springer Science+Business Media Dordrecht 1991},
  edition = {1},
  pages = {XVI, 231},
  }

@article{eclaire,
  author       = {Mateo Espinosa Zarlenga and
                  Zohreh Shams and
                  Mateja Jamnik},
  title        = {Efficient Decompositional Rule Extraction for Deep Neural Networks},
  journal      = {CoRR},
  volume       = {abs/2111.12628},
  year         = {2021},
  url          = {https://arxiv.org/abs/2111.12628},
  eprinttype    = {arXiv},
  eprint       = {2111.12628},
  timestamp    = {Fri, 26 Nov 2021 13:48:43 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2111-12628.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{fed_hql,
author = {Fan, Flint Xiaofeng and Ma, Yining and Dai, Zhongxiang and Tan, Cheston and Low, Bryan Kian Hsiang},
title = {FedHQL: Federated Heterogeneous Q-Learning},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This study introduces the problem setting of Federated Reinforcement Learning with Heterogeneous And bLack-box agEnts (FedRL-HALE), in which multiple RL agents with varying policy parameterizations, training configurations, and exploration strategies work together to optimize their policies through the proposed Federated Heterogeneous Q-Learning (FedHQL) algorithm. Empirical results demonstrate the effectiveness of FedHQL in improving system performance and increasing the sample efficiency of individual agents with high confidence.},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {2810–2812},
numpages = {3},
keywords = {q-learning, federated learning, federated reinforcement learning},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@inproceedings{fedmm,
author = {Shen, Yan and Du, Jian and Zhao, Han and Ji, Zhanghexuan and Ma, Chunwei and Gao, Mingchen},
title = {FedMM: A Communication Efficient Solver for Federated Adversarial Domain Adaptation},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Federated adversary domain adaptation is a unique distributed minimax training task due to the heterogeneous data among different local clients, where each client only sees a subset of the data that merely belongs to either the source or target domain. Despite the extensive research in distributed minimax optimization, existing communication efficient solvers that exploit multiple steps of the local update are still not able to generate satisfactory solutions for federated adversarial domain adaptation because of the gradient divergence issue among clients. To tackle this problem, we propose a distributed minimax optimizer, referred to as FedMM, by introducing dual variables to bridge the gradient gap among clients. This algorithm is effective even in the extreme case where each client has different label classes and some clients only have unlabeled data. We prove that FedMM admits benign convergence to a stationary point under domain-shifted unlabeled data. On a variety of benchmark datasets, extensive experiments show that FedMM consistently achieves both better communication savings and significant accuracy improvements over existing federated optimizers based on the stochastic gradient descent ascent (SGDA) algorithm. When training from scratch, for example, it outperforms other SGDA based federated average methods by around 20\% in accuracy over the same communication rounds; and it consistently outperforms when training from pre-trained models.},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1808–1816},
numpages = {9},
keywords = {domain adaptation, federated learning, adversarial learning},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@inproceedings{NIPS1995_8f1d4362,
 author = {Sutton, Richard S},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky and M.C. Mozer and M. Hasselmo},
 pages = {},
 publisher = {MIT Press},
 title = {Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding},
 url = {https://proceedings.neurips.cc/paper_files/paper/1995/file/8f1d43620bc6bb580df6e80b0dc05c48-Paper.pdf},
 volume = {8},
 year = {1995}
}

@misc{d3rlpy,
  doi = {10.48550/ARXIV.2111.03788},
  url = {https://arxiv.org/abs/2111.03788},
  author = {Seno, Takuma and Imai, Michita},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {d3rlpy: An Offline Deep Reinforcement Learning Library},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{openai_gym,
  doi = {10.48550/ARXIV.1606.01540},
  url = {https://arxiv.org/abs/1606.01540},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {OpenAI Gym},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@ARTICLE{cart_pole,
  author={Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
  title={Neuronlike adaptive elements that can solve difficult learning control problems}, 
  year={1983},
  volume={SMC-13},
  number={5},
  pages={834-846},
  doi={10.1109/TSMC.1983.6313077}}

@Article{Jha2020,
author={Jha, Anupama
and K. Aicher, Joseph
and R. Gazzara, Matthew
and Singh, Deependra
and Barash, Yoseph},
title={Enhanced Integrated Gradients: improving interpretability of deep learning models using splicing codes as a case study},
journal={Genome Biology},
year={2020},
month={Jun},
day={19},
volume={21},
number={1},
pages={149},
abstract={Despite the success and fast adaptation of deep learning models in biomedical domains, their lack of interpretability remains an issue. Here, we introduce Enhanced Integrated Gradients (EIG), a method to identify significant features associated with a specific prediction task. Using RNA splicing prediction as well as digit classification as case studies, we demonstrate that EIG improves upon the original Integrated Gradients method and produces sets of informative features. We then apply EIG to identify A1CF as a key regulator of liver-specific alternative splicing, supporting this finding with subsequent analysis of relevant A1CF functional (RNA-seq) and binding data (PAR-CLIP).},
issn={1474-760X},
doi={10.1186/s13059-020-02055-7},
url={https://doi.org/10.1186/s13059-020-02055-7}
}

@inproceedings{Moore1990EfficientML,
  title={Efficient memory-based learning for robot control},
  author={Andrew W. Moore},
  year={1990},
  url={https://api.semanticscholar.org/CorpusID:60851166}
}

@inproceedings{hostetter2023leveraging,
  title={Leveraging Fuzzy Logic Towards More Explainable Reinforcement Learning-Induced Pedagogical Policies on Intelligent Tutoring Systems},
  author={Hostetter, John Wesley and Abdelshiheed, Mark and Barnes, Tiffany and Chi, Min},
  booktitle={2023 {IEEE} International Conference on Fuzzy Systems},
  year={2023},
  organization={IEEE}
}

@inproceedings{igraph,
  title={The igraph software package for complex network research},
  author={G{\'a}bor Cs{\'a}rdi and Tam{\'a}s Nepusz},
  year={2006}
}

@article{FREEMAN1978215,
title = {Centrality in social networks conceptual clarification},
journal = {Social Networks},
volume = {1},
number = {3},
pages = {215-239},
year = {1978},
issn = {0378-8733},
doi = {https://doi.org/10.1016/0378-8733(78)90021-7},
url = {https://www.sciencedirect.com/science/article/pii/0378873378900217},
author = {Linton C. Freeman},
abstract = {The intuitive background for measures of structural centrality in social networks is reviewed and existing measures are evaluated in terms of their consistency with intuitions and their interpretability. Three distinct intuitive conceptions of centrality are uncovered and existing measures are refined to embody these conceptions. Three measures are developed for each concept, one absolute and one relative measure of the centrality of positions in a network, and one reflecting the degree of centralization of the entire network. The implications of these measures for the experimental study of small groups is examined.}
}

@article{aric_2,
title = {A reinforcement learning—based architecture for fuzzy logic control},
journal = {International Journal of Approximate Reasoning},
volume = {6},
number = {2},
pages = {267-292},
year = {1992},
issn = {0888-613X},
doi = {https://doi.org/10.1016/0888-613X(92)90020-Z},
url = {https://www.sciencedirect.com/science/article/pii/0888613X9290020Z},
author = {Hamid R. Berenji},
keywords = {approximate reasoning, fuzzy logic control, neural networks, reinforcement learning, adaptive control},
abstract = {}
}

% https://ieeexplore.ieee.org/abstract/document/327605
@INPROCEEDINGS{garic_space_shuttle,  author={Berenji, H.R. and Lea, R.N. and Jani, Y. and Khedkar, P. and Malkani, A. and Hoblit, J.},  booktitle={[Proceedings 1993] Second IEEE International Conference on Fuzzy Systems},   title={Space shuttle attitude control by reinforcement learning and fuzzy logic},   year={1993},  volume={},  number={},  pages={1396-1401 vol.2},  doi={10.1109/FUZZY.1993.327605}}

@article{adam_optimizer,
author = {Kingma, Diederik and Ba, Jimmy},
year = {2014},
month = {12},
pages = {},
title = {Adam: A Method for Stochastic Optimization},
journal = {International Conference on Learning Representations}
}

@INPROCEEDINGS{kneedle,
  author={Satopaa, Ville and Albrecht, Jeannie and Irwin, David and Raghavan, Barath},
  booktitle={2011 31st International Conference on Distributed Computing Systems Workshops}, 
  title={Finding a "Kneedle" in a Haystack: Detecting Knee Points in System Behavior}, 
  year={2011},
  volume={},
  number={},
  pages={166-171},
  doi={10.1109/ICDCSW.2011.20}}

@ARTICLE{kosko_1994,
  author={Kosko, B.},
  journal={IEEE Transactions on Computers}, 
  title={Fuzzy systems as universal approximators}, 
  year={1994},
  volume={43},
  number={11},
  pages={1329-1333},
  doi={10.1109/12.324566}
}

@Inbook{Rutkowska2002,
author="Rutkowska, Danuta",
title="Neuro-Fuzzy Architectures Based on the Mamdani Approach",
bookTitle="Neuro-Fuzzy Architectures and Hybrid Learning",
year="2002",
publisher="Physica-Verlag HD",
address="Heidelberg",
pages="105--126",
abstract="The fuzzy inference neural networks (see Section 3.3) that realize the inference based on the Mamdani approach are the subject of this chapter. Different, multi-layer, architectures of the neuro-fuzzy systems are portrayed. The systems with various fuzzifiers (singleton, non-singleton), defuzzifiers, and inference operations, are considered. All these systems can be trained, when applied to solve practical problems, similarly to neural networks. Learning methods of neuro-fuzzy systems are presented in Chapter 6, including the architecture-based learning, proposed in Section 6.1.3. Interested readers may also be referred to [420], [434].",
isbn="978-3-7908-1802-4",
doi="10.1007/978-3-7908-1802-4_4",
url="https://doi.org/10.1007/978-3-7908-1802-4_4"
}

@article{auto_encoder,
title = {A comprehensive survey on design and application of autoencoder in deep learning},
journal = {Applied Soft Computing},
volume = {138},
pages = {110176},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110176},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623001941},
author = {Pengzhi Li and Yan Pei and Jianqiang Li},
keywords = {Deep learning, Autoencoder, Unsupervised learning, Feature extraction, Autoencoder application},
abstract = {Autoencoder is an unsupervised learning model, which can automatically learn data features from a large number of samples and can act as a dimensionality reduction method. With the development of deep learning technology, autoencoder has attracted the attention of many scholars. Researchers have proposed several improved versions of autoencoder based on different application fields. First, this paper explains the principle of a conventional autoencoder and investigates the primary development process of an autoencoder. Second, We proposed a taxonomy of autoencoders according to their structures and principles. The related autoencoder models are comprehensively analyzed and discussed. This paper introduces the application progress of autoencoders in different fields, such as image classification and natural language processing, etc. Finally, the shortcomings of the current autoencoder algorithm are summarized, and prospected for its future development directions are addressed.}
}

% https://www.sciencedirect.com/science/article/pii/S0020025507001569
@article{facrln,
title = {A fuzzy Actor–Critic reinforcement learning network},
journal = {Information Sciences},
volume = {177},
number = {18},
pages = {3764-3781},
year = {2007},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2007.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0020025507001569},
author = {Xue-Song Wang and Yu-Hu Cheng and Jian-Qiang Yi},
keywords = {Reinforcement learning, Actor–Critic learning, Fuzzy inference system, Radial basis function neural network},
abstract = {}
}

% https://ieeexplore.ieee.org/document/501728
@ARTICLE{rfalcon,  author={Cheng-Jian Lin and Chin-Teng Lin},  journal={IEEE Transactions on Neural Networks},   title={Reinforcement learning for an ART-based fuzzy adaptive learning control network},   year={1996},  volume={7},  number={3},  pages={709-731},  doi={10.1109/72.501728}}

@INPROCEEDINGS{eda,
  author={Angelov, Plamen and Gu, Xiaowei and Kangin, Dmitry and Principe, Jose},
  booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Empirical data analysis: A new tool for data analytics}, 
  year={2016},
  volume={},
  number={},
  pages={000052-000059},
  doi={10.1109/SMC.2016.7844219}}


@article{generating_rules_with_subtractive_clusters,
author = {Priyono, Agus and Ridwan, Muhammad and Alias, Ahmad and Rahmat, Riza and Hassan, Azmi and Mohd Ali, Mohd},
year = {2005},
month = {02},
pages = {143},
title = {Generation of Fuzzy Rules with Subtractive Clustering},
volume = {43},
journal = {Jurnal Teknologi},
doi = {10.11113/jt.v43.782}
}

@article{generating_rules_with_mountain_climbing,
author = {Yager, Ronald R. and Filev, Dimitar P.},
title = {Generation of Fuzzy Rules by Mountain Clustering},
year = {1994},
issue_date = {May 1994},
publisher = {IOS Press},
address = {NLD},
volume = {2},
number = {3},
issn = {1064-1246},
abstract = {We develop, based upon the mountain clustering method, a procedure for learning fuzzy systems models from data. First we discuss the mountain clustering method. We then show how it could be used to obtain the structure of fuzzy systems models. The initial estimates of this model are obtained from the cluster centers. We then use a back propagation algorithm to tune the model.},
journal = {J. Intell. Fuzzy Syst.},
month = {may},
pages = {209–219},
numpages = {11}
}

@article{imitation_learning,
author = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
title = {Imitation Learning: A Survey of Learning Methods},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3054912},
doi = {10.1145/3054912},
abstract = {Imitation learning techniques aim to mimic human behavior in a given task. An agent (a learning machine) is trained to perform a task from demonstrations by learning a mapping between observations and actions. The idea of teaching by imitation has been around for many years; however, the field is gaining attention recently due to advances in computing and sensing as well as rising demand for intelligent applications. The paradigm of learning by imitation is gaining popularity because it facilitates teaching complex tasks with minimal expert knowledge of the tasks. Generic imitation learning methods could potentially reduce the problem of teaching a task to that of providing demonstrations, without the need for explicit programming or designing reward functions specific to the task. Modern sensors are able to collect and transmit high volumes of data rapidly, and processors with high computational power allow fast processing that maps the sensory data to actions in a timely manner. This opens the door for many potential AI applications that require real-time perception and reaction such as humanoid robots, self-driving vehicles, human computer interaction, and computer games, to name a few. However, specialized algorithms are needed to effectively and robustly learn models as learning by imitation poses its own set of challenges. In this article, we survey imitation learning methods and present design options in different steps of the learning process. We introduce a background and motivation for the field as well as highlight challenges specific to the imitation problem. Methods for designing and evaluating imitation learning tasks are categorized and reviewed. Special attention is given to learning methods in robotics and games as these domains are the most popular in the literature and provide a wide array of problems and methodologies. We extensively discuss combining imitation learning approaches using different sources and methods, as well as incorporating other motion learning methods to enhance imitation. We also discuss the potential impact on industry, present major applications, and highlight current and future research directions.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {21},
numpages = {35},
keywords = {self-improvement, learning from experience, intelligent agents, feature representations, learning from demonstrations, deep learning, Imitation learning, robotics, reinforcement learning}
}

@article{rainbow, 
title={Rainbow: Combining Improvements in Deep Reinforcement Learning}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11796}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David}, year={2018}, month={Apr.} 
}

@inproceedings{g_means,
author = {Hamerly, Greg and Elkan, Charles},
title = {Learning the k in K-Means},
year = {2003},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {When clustering a dataset, the right number k of clusters to use is often not obvious, and choosing k automatically is a hard algorithmic problem. In this paper we present an improved algorithm for learning k while clustering. The G-means algorithm is based on a statistical test for the hypothesis that a subset of data follows a Gaussian distribution. G-means runs k-means with increasing k in a hierarchical fashion until the test accepts the hypothesis that the data assigned to each k-means center are Gaussian. Two key advantages are that the hypothesis test does not limit the covariance of the data and does not compute a full covariance matrix. Additionally, G-means only requires one intuitive parameter, the standard statistical significance level α. We present results from experiments showing that the algorithm works well, and better than a recent method based on the BIC penalty for model complexity. In these experiments, we show that the BIC is ineffective as a scoring function, since it does not penalize strongly enough the model's complexity.},
booktitle = {Proceedings of the 16th International Conference on Neural Information Processing Systems},
pages = {281–288},
numpages = {8},
location = {Whistler, British Columbia, Canada},
series = {NIPS'03}
}

@article{legal_and_human_rights,
title = {Legal and human rights issues of AI: Gaps, challenges and vulnerabilities},
journal = {Journal of Responsible Technology},
volume = {4},
pages = {100005},
year = {2020},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2020.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2666659620300056},
author = {Rowena Rodrigues},
keywords = {Artificial intelligence, AI, Legal issues, Human rights, Vulnerability},
abstract = {This article focusses on legal and human rights issues of artificial intelligence (AI) being discussed and debated, how they are being addressed, gaps and challenges, and affected human rights principles. Such issues include: algorithmic transparency, cybersecurity vulnerabilities, unfairness, bias and discrimination, lack of contestability, legal personhood issues, intellectual property issues, adverse effects on workers, privacy and data protection issues, liability for damage and lack of accountability. The article uses the frame of ‘vulnerability’ to consolidate the understanding of critical areas of concern and guide risk and impact mitigation efforts to protect human well-being. While recognising the good work carried out in the AI law space, and acknowledging this area needs constant evaluation and agility in approach, this article advances the discussion, which is important given the gravity of the impacts of AI technologies, particularly on vulnerable individuals and groups, and their human rights.}
}

@inproceedings{shap,
 author = {Lundberg, Scott M and Lee, Su-In},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{klir_yuan,
  title={Fuzzy sets and fuzzy logic - theory and applications},
  author={G. Klir and Bo Yuan},
  publisher={Prentice-Hall Inc.},
  address={Upper Saddle River, New Jersey},
  year={1995}
}

@inproceedings{hostetter2023latent,
  title={Latent Space Encoding for Interpretable Fuzzy Logic Rules in Continuous and Noisy High-Dimensional Spaces},
  author={Hostetter, John Wesley and Chi, Min},
  booktitle={2023 {IEEE} International Conference on Fuzzy Systems},
  year={2023},
  organization={IEEE}
}

%Abbreviated conference (AAMAS)
%Original: Proceedings of the 22nd International Conference on Autonomous Agents and Multiagent Systems
@inproceedings{hostetter2023self,
    title={A Self-Organizing Neuro-Fuzzy Q-Network: Systematic Design with Offline Hybrid Learning},
    author={Hostetter, John Wesley and Abdelshiheed, Mark and Barnes, Tiffany and Chi, Min},
    booktitle={Proceedings of the 22nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
    year={2023}
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/abstract/document/343739
@INPROCEEDINGS{fql_and_dynamic_fql,  author={Glorennec, P.Y.},  booktitle={Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference},   title={Fuzzy Q-learning and dynamical fuzzy Q-learning},   year={1994},  volume={},  number={},  pages={474-479 vol.1},  doi={10.1109/FUZZY.1994.343739}}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/622790
@INPROCEEDINGS{fql_updated,  author={Glorennec, P.Y. and Jouffe, L.},  booktitle={Proceedings of 6th International Fuzzy Systems Conference},   title={Fuzzy Q-learning},   year={1997},  volume={2},  number={},  pages={659-662 vol.2},  doi={10.1109/FUZZY.1997.622790}}

% https://arxiv.org/abs/1904.10729
@article{neural_logic_rl,
  author    = {Zhengyao Jiang and
               Shan Luo},
  title     = {Neural Logic Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1904.10729},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.10729},
  eprinttype = {arXiv},
  eprint    = {1904.10729},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-10729.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% https://arxiv.org/abs/1806.01830
@misc{relational_deep_rl,
  doi = {10.48550/ARXIV.1806.01830},
  url = {https://arxiv.org/abs/1806.01830},
  author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Relational Deep Reinforcement Learning},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% https://link.springer.com/article/10.1023/A:1007694015589#citeas
@Article{relational_rl,
author={D{\v{z}}eroski, Sa{\v{s}}o
and De Raedt, Luc
and Driessens, Kurt},
title={Relational Reinforcement Learning},
journal={Machine Learning},
year={2001},
month={Apr},
day={01},
volume={43},
number={1},
pages={7-52},
abstract={Relational reinforcement learning is presented, a learning technique that combines reinforcement learning with relational learning or inductive logic programming. Due to the use of a more expressive representation language to represent states, actions and Q-functions, relational reinforcement learning can be potentially applied to a new range of learning tasks. One such task that we investigate is planning in the blocks world, where it is assumed that the effects of the actions are unknown to the agent and the agent has to learn a policy. Within this simple domain we show that relational reinforcement learning solves some existing problems with reinforcement learning. In particular, relational reinforcement learning allows us to employ structural representations, to abstract from specific goals pursued and to exploit the results of previous learning phases when addressing new (more complex) situations.},
issn={1573-0565},
doi={10.1023/A:1007694015589},
url={https://doi.org/10.1023/A:1007694015589}
}

@InProceedings{discrete_incremental_clustering,
author="Tung, W. L.
and Quek, C.",
editor="Ishizuka, Mitsuru
and Sattar, Abdul",
title="DIC: A Novel Discrete Incremental Clustering Technique for the Derivation of Fuzzy Membership Functions",
booktitle="PRICAI 2002: Trends in Artificial Intelligence",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="178--187",
isbn="978-3-540-45683-4"
}

% https://www.tandfonline.com/doi/abs/10.1080/019697298125470
@article{pawlak,
author = {Zdzislaw Pawlak},
title = {Rough Set Theory and its Applications to Data Analysis},
journal = {Cybernetics and Systems},
volume = {29},
number = {7},
pages = {661-688},
year  = {1998},
publisher = {Taylor \& Francis},
doi = {10.1080/019697298125470},

URL = { 
        https://doi.org/10.1080/019697298125470
    
},
eprint = { 
        https://doi.org/10.1080/019697298125470
    
}

}

% https://publications.waset.org/15791/an-efficient-technique-for-extracting-fuzzy-rulesfrom-neural-networks
@article{extract_fuzzy_rules,
  title     = {{A}n {E}fficient {T}echnique for {E}xtracting {F}uzzy {R}ules from {N}eural {N}etworks},
  author    = {Besa Muslimi and  Miriam A. M. Capretz and  Jagath Samarabandu},
  country	= {},
  institution	= {},
    journal   = {International Journal of Electrical and Computer Engineering},
  volume    = {2},
  number    = {4},
  year      = {2008},
  pages     = {1231 - 1237},
  ee        = {https://publications.waset.org/pdf/15791},
  bibsource = {https://publications.waset.org/},
  issn  	= {eISSN: 1307-6892},
  publisher = {World Academy of Science, Engineering and Technology},
  index 	= {Open Science Index 16, 2008},
}

% https://www.sciencedirect.com/science/article/pii/S0165011497000778
@article{tfig,
title = {Toward a theory of fuzzy information granulation and its centrality in human reasoning and fuzzy logic},
journal = {Fuzzy Sets and Systems},
volume = {90},
number = {2},
pages = {111-127},
year = {1997},
issn = {0165-0114},
author = {Lotfi A. Zadeh},
}

@ARTICLE{lee_flc_12,  author={Lee, C.C.},  journal={IEEE Transactions on Systems, Man, and Cybernetics},   title={Fuzzy logic in control systems: fuzzy logic controller. {I \& II}},   year={1990},  volume={20},  number={2},  pages={404-435},  
}

@book{zadeh_book,
author = {Zadeh, Lotfi and Aliev, Rafik},
year = {2018},
pages = {},
title = {Fuzzy {L}ogic {T}heory and {A}pplications: {P}art {I} and {II}},
isbn = {978-981-323-817-6},
}

@book{wang_flc,
author = {Wang, Li-Xin},
year = {1997},
title = {A {C}ourse in {F}uzzy {S}ystems and {C}ontrol}
}

% https://www.sciencedirect.com/science/article/pii/S088520149380003C
@article{concept_formation_in_infancy,
title = {Concept formation in infancy},
journal = {Cognitive Development},
volume = {8},
number = {3},
pages = {291-318},
year = {1993},
issn = {0885-2014},
doi = {https://doi.org/10.1016/S0885-2014(93)80003-C},
url = {https://www.sciencedirect.com/science/article/pii/S088520149380003C},
author = {Jean M. Mandler and Laraine McDonough},
abstract = {Four experiments investigated conceptual categorization in 7- to 11-month-old infants. Experiments 1 and 2 showed that 9-and 11-month-olds differentiated the global domains of animals and vehicles. Within the animal domain no subcategorization was found: the infants did not differentiate dogs from fish or from rabbits. Within the vehicle domain infants differentiated cars from both airplanes and motorcycles. Experiment 3 showed similar, although weaker, categorization for 7-month-olds. Experiment 4 showed that categorization of animals and vehicles was unaffected by degree of between-category similarity. Birds and airplanes were treated as different even though the exemplars from both categories had similar shapes, including outstretched wings, and were of the same texture. These data, showing global differentiation of animals and vehicles, with lack of differentiation of “basic-level” categories within the animal domain, contrast with data from studies designed to assess perceptual categorization. Even younger infants differentiate various animal subcategories perceptually. However, the results presented here suggest that infants may not respond to such perceptual differences as being conceptually relevant.}
}

% https://www.sciencedirect.com/science/article/pii/001002859190011C
@article{sheep_from_goats,
title = {Separating the sheep from the goats: Differentiating global categories},
journal = {Cognitive Psychology},
volume = {23},
number = {2},
pages = {263-298},
year = {1991},
issn = {0010-0285},
doi = {https://doi.org/10.1016/0010-0285(91)90011-C},
url = {https://www.sciencedirect.com/science/article/pii/001002859190011C},
author = {Jean M Mandler and Patricia J Bauer and Laraine McDonough},
abstract = {The nature of the conceptual categories that children have developed in the second year was studied in a series of experiments using an object-manipulation task. In the first two experiments, it was shown that by 18 months children have developed global conceptual categories of animals and vehicles without yet clearly differentiating basic-level categories within these domains. The basic-level categories were tested by using a series of contrasts: a low degree of contrast was provided by presenting the children with dogs versus horses and with cars versus trucks. A moderate degree of contrast consisted of dogs versus rabbits and cars versus motorcycles. A high degree of contrast consisted of dogs versus fish (or birds) and cars versus airplanes. A domain-level contrast of animals versus vehicles was included as well. From 18 to 30 months the children tended to respond categorically only on the global domain-level contrast and on the high-contrast basic-level distinctions. Not until 30 months did the children consistently differentiate the low and moderate basic-level contrasts. Experiment 3 replicated the finding of global animal and vehicle categories, using the widest possible range of exemplars. Experiment 4 extended the study of global categorization to the domains of plants, furniture, kitchen utensils, tools, and musical instruments. Global categorization was found for plants, furniture, and kitchen utensils, but not for tools and musical instruments. Experiment 5 found little evidence for basic-level categorization of plants, and only suggestive evidence for basic-level categorization in the domains of furniture and utensils. The data demonstrate the presence of a number of global conceptual categories from an early age, and suggest that at least in some domains (animals, vehicles, and plants) such categories develop before true basic-level distinctions are made.}
}

% https://www.sciencedirect.com/science/article/pii/0885201488900111
@article{is_basic_lvl_basic,
title = {The cradle of categorization: Is the basic level basic?},
journal = {Cognitive Development},
volume = {3},
number = {3},
pages = {247-264},
year = {1988},
issn = {0885-2014},
doi = {https://doi.org/10.1016/0885-2014(88)90011-1},
url = {https://www.sciencedirect.com/science/article/pii/0885201488900111},
author = {Jean M. Mandler and Patricia J. Bauer},
abstract = {A common assumption in the developmental literature is that the earliest kind of conceptual categories to be formed are basic-level categories. A corollary assumption is that superordinate categories are formed after, and out of, previously acquired basic-level categories. Two experiments using an object-manipulation task explored these assumptions by studying response to a variety of categories in children aged from 12 to 20 months. The first experiment examined responses to basic-level categories (dogs vs. cars),superordinate categories (animals vs. vehicles), and contextual categories (kitchen things vs. bathroom things). At all ages tested, the children performed best on the basic-level categories but, even at 12 months of age, some children were responsive to the superordinate and contextual categories. By 20 months of age, approximately half of the children showed such sensitivity. The second experiment showed that 16- and 20-month-olds differentiated basic-level categories only when the categorical contrasts were taken from different superordinate classes (e.g., dogs vs. cars) and not when the categories were drawn from the same superordinate class (e.g., dogs vs. horses). The data suggest that basic-levels categories are not the first kind of conceptual categories to be formed. Instead, it appears that children may form more global categories, with basic-level differentiation occurring later.}
}

% https://www.researchgate.net/publication/13462232_On_developing_a_knowledge_base_in_infancy
@article{developing_knowledge_in_infant,
author = {Mandler, Jean and Mcdonough, Laraine},
year = {1998},
month = {12},
pages = {1274-88},
title = {On developing a knowledge base in infancy},
volume = {34},
journal = {Developmental psychology},
doi = {10.1037//0012-1649.34.6.1274}
}

@article{imitation_in_infants,
title = {Studies in Inductive Inference in Infancy},
journal = {Cognitive Psychology},
volume = {37},
number = {1},
pages = {60-96},
year = {1998},
issn = {0010-0285},
doi = {https://doi.org/10.1006/cogp.1998.0691},
url = {https://www.sciencedirect.com/science/article/pii/S0010028598906910},
author = {Jean M. Mandler and Laraine McDonough},
abstract = {Imitation of events was used to explore the inductive generalizations that 14-month-olds have made about animals, vehicles, and household artifacts. In Experiment 1 infants generalized domain-specific properties such as drinking to animals but not to vehicles, whereas they generalized domain-neutral properties such as going into a building to exemplars from both domains. The next four experiments showed that infants tend to interpret animal events very broadly, for example, construing a dog merely as a land animal rather than as a differentiated kind in its own right. Infants were somewhat more selective in their construals of vehicles. Experiment 6 showed that 14-month-olds also generalize “basic-level properties” very broadly. For example, they chose a pan to demonstrate drinking almost as often as a cup and fed a bone to a bird as often as to a dog. By 20 months, their selections narrowed appropriately for artifacts, but were still overgeneralized for natural kinds. The experiments indicate that infants tend to generalize their early experiences broadly across domains, often across exemplars that have a variety of different surface characteristics. The data suggest that it is the conceptual meaning of objects, rather than their physical features, that controls early associative learning.}
}

% https://www.semanticscholar.org/paper/On-the-Birth-and-Growth-of-Concepts-Mandler/af153f1e88cc00e00166099b11f35ce9bc9a3566
@article{birth_and_growth_concepts,
  title={On the Birth and Growth of Concepts},
  author={Jean M. Mandler},
  journal={Philosophical Psychology},
  year={2008},
  volume={21},
  pages={207 - 230}
}

@misc{benchmark_bcq,
  doi = {10.48550/ARXIV.1910.01708},
  
  url = {https://arxiv.org/abs/1910.01708},
  
  author = {Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Benchmarking Batch Deep Reinforcement Learning Algorithms},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@Article{Watkins1992,
author={Watkins, Christopher J. C. H.
and Dayan, Peter},
title={Q-learning},
journal={Machine Learning},
year={1992},
month={May},
day={01},
volume={8},
number={3},
pages={279-292},
abstract={Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
issn={1573-0565},
doi={10.1007/BF00992698},
url={https://doi.org/10.1007/BF00992698}
}

@article{popfnn_aars,  author={Quek, C. and Zhou, R.W.},  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},   title={{POPFNN-AAR(S)}: a pseudo outer-product based fuzzy neural network},   year={1999},  volume={29},  number={6},  pages={859-870},  
}

@article{fuzzy_dp,
 ISSN = {00251909, 15265501},
 abstract = {By decision-making in a fuzzy environment is meant a decision process in which the goals and/or the constraints, but not necessarily the system under control, are fuzzy in nature. This means that the goals and/or the constraints constitute classes of alternatives whose boundaries are not sharply defined. An example of a fuzzy constraint is: "The cost of A should not be substantially higher than α," where α is a specified constant. Similarly, an example of a fuzzy goal is: "x should be in the vicinity of x0," where x0 is a constant. The italicized words are the sources of fuzziness in these examples. Fuzzy goals and fuzzy constraints can be defined precisely as fuzzy sets in the space of alternatives. A fuzzy decision, then, may be viewed as an intersection of the given goals and constraints. A maximizing decision is defined as a point in the space of alternatives at which the membership function of a fuzzy decision attains its maximum value. The use of these concepts is illustrated by examples involving multistage decision processes in which the system under control is either deterministic or stochastic. By using dynamic programming, the determination of a maximizing decision is reduced to the solution of a system of functional equations. A reverse-flow technique is described for the solution of a functional equation arising in connection with a decision process in which the termination time is defined implicitly by the condition that the process stops when the system under control enters a specified set of states in its state space.},
 author = {R. E. Bellman and L. A. Zadeh},
 journal = {Management Science},
 number = {4},
 pages = {B141--B164},
 publisher = {INFORMS},
 title = {Decision-Making in a Fuzzy Environment},
 volume = {17},
 year = {1970}
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/793268
@INPROCEEDINGS{self_organizing_fql,  author={Min-Soeng Kim and Sun-Gi Hong and Ju-Jang Lee},  booktitle={FUZZ-IEEE'99. 1999 IEEE International Fuzzy Systems. Conference Proceedings (Cat. No.99CH36315)},   title={Self-organizing fuzzy inference system by Q-learning},   year={1999},  volume={1},  number={},  pages={372-377 vol.1},  doi={10.1109/FUZZY.1999.793268}}

@article{popfnn_aars,  author={Quek, C. and Zhou, R.W.},  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},   title={{POPFNN-AAR(S)}: a pseudo outer-product based fuzzy neural network},   year={1999},  volume={29},  number={6},  pages={859-870},  
}

% https://link.springer.com/article/10.1007/s00500-007-0260-1#citeas
@Article{Hedar2008,
author={Hedar, Abdel-Rahman
and Wang, Jue
and Fukushima, Masao},
title={Tabu search for attribute reduction in rough set theory},
journal={Soft Computing},
year={2008},
month={Jul},
day={01},
volume={12},
number={9},
pages={909-918},
abstract={In this paper, we consider a memory-based heuristic of tabu search to solve the attribute reduction problem in rough set theory. The proposed method, called tabu search attribute reduction (TSAR), is a high-level TS with long-term memory. Therefore, TSAR invokes diversification and intensification search schemes besides the TS neighborhood search methodology. TSAR shows promising and competitive performance compared with some other CI tools in terms of solution qualities. Moreover, TSAR shows a superior performance in saving the computational costs.},
issn={1433-7479},
doi={10.1007/s00500-007-0260-1},
url={https://doi.org/10.1007/s00500-007-0260-1}
}

@misc{cql,
  doi = {10.48550/ARXIV.2006.04779},
  
  url = {https://arxiv.org/abs/2006.04779},
  
  author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Conservative Q-Learning for Offline Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% https://arxiv.org/abs/1509.06461
@misc{ddqn,
  doi = {10.48550/ARXIV.1509.06461},
  url = {https://arxiv.org/abs/1509.06461},
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Reinforcement Learning with Double Q-learning},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% https://link.springer.com/chapter/10.1007/11564096_32#citeas
@InProceedings{nfq,
author="Riedmiller, Martin",
editor="Gama, Jo{\~a}o
and Camacho, Rui
and Brazdil, Pavel B.
and Jorge, Al{\'i}pio M{\'a}rio
and Torgo, Lu{\'i}s",
title="Neural Fitted Q Iteration -- First Experiences with a Data Efficient Neural Reinforcement Learning Method",
booktitle="Machine Learning: ECML 2005",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="317--328",
abstract="This paper introduces NFQ, an algorithm for efficient and effective training of a Q-value function represented by a multi-layer perceptron. Based on the principle of storing and reusing transition experiences, a model-free, neural network based Reinforcement Learning algorithm is proposed. The method is evaluated on three benchmark problems. It is shown empirically, that reasonably few interactions with the plant are needed to generate control policies of high quality.",
isbn="978-3-540-31692-3"
}

% https://arxiv.org/abs/1812.02900
@misc{bcq,
  doi = {10.48550/ARXIV.1812.02900},
  url = {https://arxiv.org/abs/1812.02900},
  author = {Fujimoto, Scott and Meger, David and Precup, Doina},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Off-Policy Deep Reinforcement Learning without Exploration},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% https://arxiv.org/abs/1805.01954
@misc{behavior_cloning,
  doi = {10.48550/ARXIV.1805.01954},
  url = {https://arxiv.org/abs/1805.01954},
  author = {Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Behavioral Cloning from Observation},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{andrychowicz2018learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, Marcin and Baker, Bowen and others},
  journal={arXiv:1808.00177},
  year={2018}
}

@article{mnih2015humanlevelcontrol,
  title={Human-level control through deep reinforcement learning.},
  author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A Rusu and Joel Veness and Marc G Bellemare and Alex Graves and Martin Riedmiller and Andreas K Fidjeland and Georg Ostrovski and et al.},
  journal={Nature},
  year={2015},
  number={518},
  pages={529--533}
}

@article{silver2016mastering,
    author={D. Silver and A. Huang and C. J. Maddison and A. Guez and L. Sifre and G. V. D. Driessche and others}, 
    title={Mastering the game of go with deep neural networks and tree search},
    journal={Nature},
    volume ="529",
    number="7587",
    pages="484--489",
    month={},
    year={2016}
    }

@inproceedings{klir_yuan,
  title={Fuzzy sets and fuzzy logic - theory and applications},
  author={G. Klir and Bo Yuan},
  publisher={Prentice-Hall Inc.},
  address={Upper Saddle River, New Jersey},
  year={1995}
}

@article{zadeh_fuzzy_sets,
title = {Fuzzy sets},
journal = {Information and Control},
volume = {8},
number = {3},
pages = {338-353},
year = {1965},
issn = {0019-9958},
author = {L.A. Zadeh},
}

@software{john_wesley_hostetter_2023_7668307,
  author       = {John Wesley Hostetter},
  title        = {johnHostetter/AAMAS-2023-FCQL: First release},
  month        = feb,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v1.0.0},
  doi          = {10.5281/zenodo.7668308},
  url          = {https://doi.org/10.5281/zenodo.7668308}
}

@InProceedings{abdelshiheed2022mixing,
author="Abdelshiheed, Mark
and Hostetter, John Wesley
and Yang, Xi
and Barnes, Tiffany
and Chi, Min",
title="Mixing Backward- with Forward-Chaining for Metacognitive Skill Acquisition and Transfer",
booktitle="Artificial Intelligence  in Education",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="546--552"}

@inproceedings{abdelshiheed2020metacognition,
  title={Metacognition and Motivation: The Role of Time-Awareness in Preparation for Future Learning},
  author={Abdelshiheed, Mark and Zhou, Guojing and Maniktala, Mehak and Barnes, Tiffany and Chi, Min},
  booktitle={Proceedings of the 42nd annual conference of the cognitive science society},
    pages={945--951},
  year={2020}
}

@inproceedings{abdelshiheed2021preparing,
  title={Preparing Unprepared Students For Future Learning},
  author={Abdelshiheed, Mark and Maniktala, Mehak and Ju, Song and Jain, Ayush and Barnes, Tiffany and Chi, Min},
  booktitle={Proceedings of the 43rd annual conference of the cognitive science society},
  pages={2547--2553},
  year={2021}
}

@inproceedings{abdelshiheed2022power,
    title={The Power of Nudging: Exploring Three Interventions for Metacognitive Skills Instruction across Intelligent Tutoring Systems},
    author={Abdelshiheed, Mark and Hostetter, John Wesley and Shabrina, Preya and Barnes, Tiffany and Chi, Min},
    booktitle={Proceedings of the 44th annual conference of the cognitive science society},
    pages={541--548},
    year={2022}
}

@incollection{abdelshiheed2022assessing,
  title={Assessing Competency Using Metacognition and Motivation: The Role of Time-Awareness in Preparation for Future Learning},
  author={Abdelshiheed, Mark and Maniktala, Mehak and Barnes, Tiffany and Chi, Min},
  booktitle={Design Recommendations for Intelligent Tutoring Systems},
  pages={121--131},
  volume={9},
  year={2022}
}

@InProceedings{its_chrl,
author="Ju, Song
and Zhou, Guojing
and Abdelshiheed, Mark
and Barnes, Tiffany
and Chi, Min",
editor="Roll, Ido
and McNamara, Danielle
and Sosnovsky, Sergey
and Luckin, Rose
and Dimitrova, Vania",
title="{E}valuating {C}ritical {R}einforcement {L}earning {F}ramework in the {F}ield",
booktitle="Artificial Intelligence in Education",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="215--227",
isbn="978-3-030-78292-4"
}

@article{xue_adaptive_2023,
	title = {An {Adaptive} {Neuro}-{Fuzzy} {System} {With} {Integrated} {Feature} {Selection} and {Rule} {Extraction} for {High}-{Dimensional} {Classification} {Problems}},
	volume = {31},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2022.3220950},
	abstract = {A major limitation of fuzzy or neuro-fuzzy systems is their failure to deal with high-dimensional datasets. This happens primarily due to the use of T-norm, particularly, product or minimum (or a softer version of it). Thus, there are hardly any work dealing with datasets having features more than hundred or so. Here, we propose a neuro-fuzzy framework that can handle datasets with even more than 7000 features! In this context, we propose an adaptive softmin (Ada-softmin) which effectively overcomes the drawbacks of “numeric underflow” and “fake minimum” that arise for existing fuzzy systems while dealing with high-dimensional problems. We call it an adaptive Takagi–Sugeno–Kang (AdaTSK) fuzzy system. We then equip the AdaTSK system to perform feature selection and rule extraction in an integrated manner. In this context, a novel gate function is introduced and embedded only in the consequent parts, which can determine the useful features and rules, in two successive phases of learning. Unlike conventional fuzzy rule bases, we design an enhanced fuzzy rule base, which maintains adequate rules but does not grow the number of rules exponentially with features that typically happens for fuzzy neural networks. The integrated feature selection and rule extraction AdaTSK (FSRE-AdaTSK) system consists of three sequential phases: 1) feature selection; 2) rule extraction; and 3) fine tuning. The effectiveness of the FSRE-AdaTSK is demonstrated on 19 datasets of which five are in more than 2000 dimension including two with more than 7000 features. This may be the first attempt to develop fuzzy rule-based classifiers that can directly deal with more than 7000 features without requiring separate selection of features or any other dimensionality reduction method.},
	number = {7},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Xue, Guangdong and Chang, Qin and Wang, Jian and Zhang, Kai and Pal, Nikhil Ranjan},
	month = jul,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Adaptive systems, Feature extraction, Feature selection, Fuzzy sets, Fuzzy systems, Logic gates, Petroleum, Takagi–Sugeno–Kang (TSK) fuzzy system, Training, gate function, high-dimensional classification, rule extraction},
	pages = {2167--2181},
}

@article{elkan_paradoxical_1994,
	title = {The paradoxical success of fuzzy logic},
	volume = {9},
	issn = {2374-9407},
	doi = {10.1109/64.336150},
	abstract = {Fuzzy logic methods have been used successfully in many real-world applications, but the foundations of fuzzy logic remain under attack. Taken together, these two facts constitute a paradox. A second paradox is that almost all of the successful fuzzy logic applications are embedded controllers, while most of the theoretical papers on fuzzy methods deal with knowledge representation and reasoning. I hope to resolve these paradoxes by identifying which aspects of fuzzy logic render it useful in practice, and which aspects are inessential. My conclusions are based on a mathematical result, on a survey of literature on the use of fuzzy logic in heuristic control and in expert systems, and on practical experience in developing expert systems.{\textless}{\textgreater}},
	number = {4},
	journal = {IEEE Expert},
	author = {Elkan, C. and Berenji, H.R. and Chandrasekaran, B. and de Silva, C.J.S. and Attikiouzel, Y. and Dubois, D. and Prade, H. and Smets, P. and Freksa, C. and Garcia, O.N. and Klir, G.J. and Yuan, Bo and Mamdani, E.H. and Pelletier, F.J. and Ruspini, E.H. and Turksen, B. and Vadiee, N. and Jamshidi, M. and Wang, Pei-Zhuang and Tan, Sie-Keng and Tan, Shaohua and Yager, R.R. and Zadeh, L.A.},
	month = aug,
	year = {1994},
	note = {Conference Name: IEEE Expert},
	keywords = {Control systems, Expert systems, Fuzzy control, Fuzzy logic, Fuzzy reasoning, Knowledge representation},
	pages = {3--49},
}

@misc{noauthor_research_nodate,
	title = {Research {Groups}: {APT} - {Advanced} {Processor} {Technologies} ({School} of {Computer} {Science} - {The} {University} of {Manchester})},
	url = {http://apt.cs.manchester.ac.uk/projects/SpiNNaker/},
	urldate = {2023-05-27},
}

@article{draelos_neurogenesis_2016,
	title = {Neurogenesis {Deep} {Learning}},
	abstract = {Neural machine learning methods, such as deep neural networks (DNN), have achieved remarkable success in a number of complex data processing tasks. These methods have arguably had their strongest impact on tasks such as image and audio processing - data processing domains in which humans have long held clear advantages over conventional algorithms. In contrast to biological neural systems, which are capable of learning continuously, deep artificial networks have a limited ability for incorporating new information in an already trained network. As a result, methods for continuous learning are potentially highly impactful in enabling the application of deep networks to dynamic data sets. Here, inspired by the process of adult neurogenesis in the hippocampus, we explore the potential for adding new neurons to deep layers of artificial neural networks in order to facilitate their acquisition of novel information while preserving previously trained data representations. Our results on the MNIST handwritten digit dataset and the NIST SD 19 dataset, which includes lower and upper case letters and digits, demonstrate that neurogenesis is well suited for addressing the stability-plasticity dilemma that has long challenged adaptive machine learning algorithms.},
	author = {Draelos, Timothy and Miner, Nadine and Lamb, Christopher and Vineyard, Craig and Carlson, Kristofor and James, Conrad and Aimone, James},
	month = dec,
	year = {2016},
}

@misc{wang_efficient_nodate,
	title = {Efficient {Architecture} {Search} by {Network} {Transformation}},
	url = {https://aaai.org/papers/11709-efficient-architecture-search-by-network-transformation/},
	language = {en-US},
	urldate = {2023-05-27},
	journal = {AAAI},
	author = {Wang, Han Cai{\textbar}{\textbar}Tianyao Chen{\textbar}{\textbar}Weinan Zhang{\textbar}{\textbar}Yong Yu{\textbar}{\textbar}Jun},
}

@article{chen_net2net_2015,
	title = {{Net2Net}: {Accelerating} {Learning} via {Knowledge} {Transfer}},
	shorttitle = {{Net2Net}},
	abstract = {We introduce techniques for rapidly transferring the information stored in one neural net into another neural net. The main purpose is to accelerate the training of a significantly larger neural net. During real-world workflows, one often trains very many different neural networks during the experimentation and design process. This is a wasteful process in which each new model is trained from scratch. Our Net2Net technique accelerates the experimentation process by instantaneously transferring the knowledge from a previous network to each new deeper or wider network. Our techniques are based on the concept of function-preserving transformations between neural network specifications. This differs from previous approaches to pre-training that altered the function represented by a neural net when adding layers to it. Using our knowledge transfer mechanism to add depth to Inception modules, we demonstrate a new state of the art accuracy rating on the ImageNet dataset.},
	author = {Chen, Tianqi and Goodfellow, Ian and Shlens, Jonathon},
	month = nov,
	year = {2015},
}

@misc{maile_when_2022,
	title = {When, where, and how to add new neurons to {ANNs}},
	url = {http://arxiv.org/abs/2202.08539},
	doi = {10.48550/arXiv.2202.08539},
	abstract = {Neurogenesis in ANNs is an understudied and difficult problem, even compared to other forms of structural learning like pruning. By decomposing it into triggers and initializations, we introduce a framework for studying the various facets of neurogenesis: when, where, and how to add neurons during the learning process. We present the Neural Orthogonality (NORTH*) suite of neurogenesis strategies, combining layer-wise triggers and initializations based on the orthogonality of activations or weights to dynamically grow performant networks that converge to an efficient size. We evaluate our contributions against other recent neurogenesis works across a variety of supervised learning tasks.},
	urldate = {2023-05-27},
	publisher = {arXiv},
	author = {Maile, Kaitlin and Rachelson, Emmanuel and Luga, Hervé and Wilson, Dennis G.},
	month = may,
	year = {2022},
	note = {arXiv:2202.08539 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{schwammle_simple_2010,
	title = {A simple and fast method to determine the parameters for fuzzy c–means cluster analysis},
	volume = {26},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btq534},
	doi = {10.1093/bioinformatics/btq534},
	abstract = {Motivation: Fuzzy c-means clustering is widely used to identify cluster structures in high-dimensional datasets, such as those obtained in DNA microarray and quantitative proteomics experiments. One of its main limitations is the lack of a computationally fast method to set optimal values of algorithm parameters. Wrong parameter values may either lead to the inclusion of purely random fluctuations in the results or ignore potentially important data. The optimal solution has parameter values for which the clustering does not yield any results for a purely random dataset but which detects cluster formation with maximum resolution on the edge of randomness.Results: Estimation of the optimal parameter values is achieved by evaluation of the results of the clustering procedure applied to randomized datasets. In this case, the optimal value of the fuzzifier follows common rules that depend only on the main properties of the dataset. Taking the dimension of the set and the number of objects as input values instead of evaluating the entire dataset allows us to propose a functional relationship determining the fuzzifier directly. This result speaks strongly against using a predefined fuzzifier as typically done in many previous studies. Validation indices are generally used for the estimation of the optimal number of clusters. A comparison shows that the minimum distance between the centroids provides results that are at least equivalent or better than those obtained by other computationally more expensive indices.Contact:  veits@bmb.sdu.dkSupplementary information:  Supplementary data are available at Bioinformatics online.},
	number = {22},
	urldate = {2023-05-27},
	journal = {Bioinformatics},
	author = {Schwämmle, Veit and Jensen, Ole Nørregaard},
	month = nov,
	year = {2010},
	pages = {2841--2848},
}

@article{subbalakshmi_method_2015,
	series = {Proceedings of the {International} {Conference} on {Information} and {Communication} {Technologies}, {ICICT} 2014, 3-5 {December} 2014 at {Bolgatty} {Palace} \& {Island} {Resort}, {Kochi}, {India}},
	title = {A {Method} to {Find} {Optimum} {Number} of {Clusters} {Based} on {Fuzzy} {Silhouette} on {Dynamic} {Data} {Set}},
	volume = {46},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915000940},
	doi = {10.1016/j.procs.2015.02.030},
	abstract = {Data analysis plays amajor role in innovation of new trends in many applications.In most of the current applicationdatabases is being updated day to day. In order to adopt these changes, there is a need to update the present technologies and data mining algorithms in support of changing data. In many of the clustering algorithms the user has to specify the optimum number of clusters prior to execution, for static databases this value remains constant whereas, in the case of dynamic databases the value should be changed. In this paper,we implemented a method to find optimal number of clusters based onfuzzy silhouette on dynamic data by comparing traditional clustering on synthetic data and dynamic customer segmentation.},
	language = {en},
	urldate = {2023-05-27},
	journal = {Procedia Computer Science},
	author = {Subbalakshmi, Chatti and Krishna, G. Rama and Rao, S. Krishna Mohan and Rao, P. Venketeswa},
	month = jan,
	year = {2015},
	keywords = {cluster analysis, dynamic data, fuzzy silhouette index, optimum number of clusters},
	pages = {346--353},
}

@article{samarasinghe_flow-based_2022,
	title = {Flow-{Based} {Reinforcement} {Learning}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3209260},
	abstract = {This paper presents a novel Flow-based reinforcement learning strategy to model agent systems that can adapt to complex and dynamic problem environments by incrementally mastering their skills. It is inspired by the psychological notion of Flow that describes the optimal mental state experienced by an individual when they are fully immersed in a task and find it intrinsically rewarding to engage with. The proposed model presents an algorithm to describe the Flow experience such that agents can be trained through finer distinctions to the challenges across training time to maintain them in the Flow zone. In contrast to the traditional and incremental learning approaches that suffer from limitations associated with overfitting, the Flow-based model drives agent behaviours not simply through external goals but also through intrinsic curiosity to improve their skills and thus the performance levels. Experimental evaluations are conducted across two simulation environments on a maze navigation task and a reward collection task with comparisons against a generic reinforcement learning model and an incremental reinforcement learning model. The results reveal that these two models are prone to overfit under different design decisions and loose the ability to perform in dynamic variations of the tasks in varying degrees. Conversely, the proposed Flow-based model is capable of achieving near optimal solutions with random environmental factors, appropriately utilising the previously learned knowledge to identify robust solutions to complex problems.},
	journal = {IEEE Access},
	author = {Samarasinghe, Dilini and Barlow, Michael and Lakshika, Erandi},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Adaptation models, Artificial intelligence, Complexity theory, Flow, Learning (artificial intelligence), Machine learning, Psychology, Reinforcement learning, artificial intelligence, incremental learning, machine learning, reinforcement learning},
	pages = {102247--102265},
}

@inproceedings{tscherepanow_topoart_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{TopoART}: {A} {Topology} {Learning} {Hierarchical} {ART} {Network}},
	isbn = {978-3-642-15825-4},
	shorttitle = {{TopoART}},
	doi = {10.1007/978-3-642-15825-4_21},
	abstract = {In this paper, a novel unsupervised neural network combining elements from Adaptive Resonance Theory and topology learning neural networks, in particular the Self-Organising Incremental Neural Network, is introduced. It enables stable on-line clustering of stationary and non-stationary input data. In addition, two representations reflecting different levels of detail are learnt simultaneously. Furthermore, the network is designed in such a way that its sensitivity to noise is diminished, which renders it suitable for the application to real-world problems.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} – {ICANN} 2010},
	publisher = {Springer},
	author = {Tscherepanow, Marko},
	editor = {Diamantaras, Konstantinos and Duch, Wlodek and Iliadis, Lazaros S.},
	year = {2010},
	keywords = {Adaptive Resonance Theory, Hierarchical Representation, Humanoid Robot, Input Distribution, Reference Vector},
	pages = {157--167},
}

@article{carpenter_fuzzy_1992,
	title = {Fuzzy {ARTMAP}: {A} neural network architecture for incremental supervised learning of analog multidimensional maps},
	volume = {3},
	issn = {1941-0093},
	shorttitle = {Fuzzy {ARTMAP}},
	doi = {10.1109/72.159059},
	abstract = {A neural network architecture is introduced for incremental supervised learning of recognition categories and multidimensional maps in response to arbitrary sequences of analog or binary input vectors, which may represent fuzzy or crisp sets of features. The architecture, called fuzzy ARTMAP, achieves a synthesis of fuzzy logic and adaptive resonance theory (ART) neural networks by exploiting a close formal similarity between the computations of fuzzy subsethood and ART category choice, resonance, and learning. Four classes of simulation illustrated fuzzy ARTMAP performance in relation to benchmark backpropagation and generic algorithm systems. These simulations include finding points inside versus outside a circle, learning to tell two spirals apart, incremental approximation of a piecewise-continuous function, and a letter recognition database. The fuzzy ARTMAP system is also compared with Salzberg's NGE systems and with Simpson's FMMC system.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Carpenter, G.A. and Grossberg, S. and Markuzon, N. and Reynolds, J.H. and Rosen, D.B.},
	month = sep,
	year = {1992},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Computational modeling, Fuzzy logic, Fuzzy neural networks, Fuzzy sets, Fuzzy systems, Multidimensional systems, Neural networks, Resonance, Subspace constraints, Supervised learning},
	pages = {698--713},
}

@article{williamson_gaussian_1996,
	title = {Gaussian {ARTMAP}: {A} {Neural} {Network} for {Fast} {Incremental} {Learning} of {Noisy} {Multidimensional} {Maps}},
	volume = {9},
	issn = {0893-6080},
	shorttitle = {Gaussian {ARTMAP}},
	url = {https://www.sciencedirect.com/science/article/pii/0893608095001158},
	doi = {10.1016/0893-6080(95)00115-8},
	abstract = {A new neural network architecture for incremental supervised learning of analog multidimensional maps is introduced. The architecture, called Gaussian ARTMAP, is a synthesis of a Gaussian classifier and an adaptive resonance theory (ART) neural network, achieved by defining the ART choice function as the discriminant function of a Gaussian classifier with separable distributions, and the ART match function as the same, but with the distributions normalized to a unit height. While Gaussian ARTMAP retains the attractive parallel computing and fast learning properties of fuzzy ARTMAP, it learns a more efficient internal representation of a mapping while being more resistant to noise than fuzzy ARTMAP on a number of benchmark databases. SSeveral simulations are presented which demonstrate that Gaussian ARTMAP consistently obtains a better trade-off of classification rate to number of categories than fuzzy ARTMAP. Results on a vowel classification problem are also presented which demonstrate that Gaussian ARTMAP outperforms many other classifiers. Copyright © 1996 Elsevier Science Ltd},
	language = {en},
	number = {5},
	urldate = {2023-05-27},
	journal = {Neural Networks},
	author = {Williamson, James R.},
	month = jul,
	year = {1996},
	keywords = {ARTMAP, Adaptive resonance theory, Gaussian classifier, Incremental learning, Noisy data, Pattern recognition, Radial basis function, Self-organization},
	pages = {881--897},
}

@article{chik_selective_2009,
	title = {Selective attention model with spiking elements},
	volume = {22},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608009000173},
	doi = {10.1016/j.neunet.2009.02.002},
	abstract = {A new biologically plausible model of visual selective attention is developed based on synaptically coupled Hodgkin–Huxley neurons. The model is designed according to a two-layer architecture of excitatory and inhibitory connections which comprises two central neurons and a population of peripheral neurons. Two types of inhibition from the central neurons are present: fixed inhibition which is responsible for the formation of the attention focus, and short-term plastic inhibition which is responsible for the shift of attention. The regimes of synchronous dynamics associated with the development of the attentional focus are studied. In particular, the regime of partial synchronization between spiking activity of the central and peripheral neurons is interpreted as object selection to the focus of attention. It is shown that peripheral neurons with higher firing rates are selected preferentially by the attention system. The model correctly reproduces some observations concerning the mechanisms of attentional control, such as the coherence of spikes in the population of neurons included in the focus of attention, and the inhibition of neurons outside the focus of attention. Sequential selection of stimuli simultaneously present in the visual scene is demonstrated by the model in the frequency domain in both a formal example and a real image.},
	language = {en},
	number = {7},
	urldate = {2023-05-27},
	journal = {Neural Networks},
	author = {Chik, David and Borisyuk, Roman and Kazanovich, Yakov},
	month = sep,
	year = {2009},
	keywords = {Attention model, Hodgkin–Huxley neurons, Sequential selection, Synchronization},
	pages = {890--900},
}

@article{chambers_simulated_2004,
	title = {Simulated {Apoptosis}/{Neurogenesis} {Regulates} {Learning} and {Memory} {Capabilities} of {Adaptive} {Neural} {Networks}},
	volume = {29},
	copyright = {2004 American College of Neuropsychopharmacology},
	issn = {1740-634X},
	url = {https://www.nature.com/articles/1300358},
	doi = {10.1038/sj.npp.1300358},
	abstract = {Characterization of neuronal death and neurogenesis in the adult brain of birds, humans, and other mammals raises the possibility that neuronal turnover represents a special form of neuroplasticity associated with stress responses, cognition, and the pathophysiology and treatment of psychiatric disorders. Multilayer neural network models capable of learning alphabetic character representations via incremental synaptic connection strength changes were used to assess additional learning and memory effects incurred by simulation of coordinated apoptotic and neurogenic events in the middle layer. Using a consistent incremental learning capability across all neurons and experimental conditions, increasing the number of middle layer neurons undergoing turnover increased network learning capacity for new information, and increased forgetting of old information. Simulations also showed that specific patterns of neural turnover based on individual neuronal connection characteristics, or the temporal-spatial pattern of neurons chosen for turnover during new learning impacts new learning performance. These simulations predict that apoptotic and neurogenic events could act together to produce specific learning and memory effects beyond those provided by ongoing mechanisms of connection plasticity in neuronal populations. Regulation of rates as well as patterns of neuronal turnover may serve an important function in tuning the informatic properties of plastic networks according to novel informational demands. Analogous regulation in the hippocampus may provide for adaptive cognitive and emotional responses to novel and stressful contexts, or operate suboptimally as a basis for psychiatric disorders. The implications of these elementary simulations for future biological and neural modeling research on apoptosis and neurogenesis are discussed.},
	language = {en},
	number = {4},
	urldate = {2023-05-27},
	journal = {Neuropsychopharmacology},
	author = {Chambers, R. Andrew and Potenza, Marc N. and Hoffman, Ralph E. and Miranker, Willard},
	month = apr,
	year = {2004},
	note = {Number: 4
Publisher: Nature Publishing Group},
	keywords = {Behavioral Sciences, Biological Psychology, Medicine/Public Health, Neurosciences, Pharmacotherapy, Psychiatry, general},
	pages = {747--758},
}

@misc{noauthor_making_nodate,
	title = {Making a {Science} of {Model} {Search}: {Hyperparameter} {Optimization} in {Hundreds} of {Dimensions} for {Vision} {Architectures}},
	url = {https://dash.harvard.edu/handle/1/12561000},
	urldate = {2023-05-27},
}

@inproceedings{bergstra_algorithms_2011,
	title = {Algorithms for {Hyper}-{Parameter} {Optimization}},
	volume = {24},
	url = {https://papers.nips.cc/paper_files/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html},
	abstract = {Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [Larochelle et al., 2007] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y{\textbar}x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.},
	urldate = {2023-05-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bergstra, James and Bardenet, Rémi and Bengio, Yoshua and Kégl, Balázs},
	year = {2011},
}

@article{hein_particle_2017,
	title = {Particle swarm optimization for generating interpretable fuzzy reinforcement learning policies},
	volume = {65},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197617301537},
	doi = {10.1016/j.engappai.2017.07.005},
	abstract = {Fuzzy controllers are efficient and interpretable system controllers for continuous state and action spaces. To date, such controllers have been constructed manually or trained automatically either using expert-generated problem-specific cost functions or incorporating detailed knowledge about the optimal control strategy. Both requirements for automatic training processes are not found in most real-world reinforcement learning (RL) problems. In such applications, online learning is often prohibited for safety reasons because it requires exploration of the problem’s dynamics during policy training. We introduce a fuzzy particle swarm reinforcement learning (FPSRL) approach that can construct fuzzy RL policies solely by training parameters on world models that simulate real system dynamics. These world models are created by employing an autonomous machine learning technique that uses previously generated transition samples of a real system. To the best of our knowledge, this approach is the first to relate self-organizing fuzzy controllers to model-based batch RL. FPSRL is intended to solve problems in domains where online learning is prohibited, system dynamics are relatively easy to model from previously generated default policy transition samples, and it is expected that a relatively easily interpretable control policy exists. The efficiency of the proposed approach with problems from such domains is demonstrated using three standard RL benchmarks, i.e., mountain car, cart-pole balancing, and cart-pole swing-up. Our experimental results demonstrate high-performing, interpretable fuzzy policies.},
	language = {en},
	urldate = {2023-05-27},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Hein, Daniel and Hentschel, Alexander and Runkler, Thomas and Udluft, Steffen},
	month = oct,
	year = {2017},
	keywords = {Fuzzy controller, Fuzzy policy, Interpretable, Particle swarm optimization, Reinforcement learning},
	pages = {87--98},
}

@article{takefuji_artificial_1991,
	title = {An artificial hysteresis binary neuron: a model suppressing the oscillatory behaviors of neural dynamics},
	volume = {64},
	issn = {1432-0770},
	shorttitle = {An artificial hysteresis binary neuron},
	url = {https://doi.org/10.1007/BF00224701},
	doi = {10.1007/BF00224701},
	abstract = {A hysteresis binary McCulloch-Pitts neuron model is proposed in order to suppress the complicated oscillatory behaviors of neural dynamics. The artificial hysteresis binary neural network is used for scheduling time-multiplex crossbar switches in order to demonstrate the effects of hysteresis. Time-multiplex crossbar switching systems must control traffic on demand such that packet blocking probability and packet waiting time are minimized. The system using n×n processing elements solves an n×n crossbar-control problem with O(1) time, while the best existing parallel algorithm requires O(n) time. The hysteresis binary neural network maximizes the throughput of packets through a crossbar switch. The solution quality of our system does not degrade with the problem size.},
	language = {en},
	number = {5},
	urldate = {2023-05-27},
	journal = {Biological Cybernetics},
	author = {Takefuji, Y. and Lee, K. C.},
	month = mar,
	year = {1991},
	keywords = {Neural Network, Parallel Algorithm, Problem Size, Processing Element, Wait Time},
	pages = {353--356},
}

@article{novikov_pyclustering_2019,
	title = {{PyClustering}: {Data} {Mining} {Library}},
	volume = {4},
	issn = {2475-9066},
	shorttitle = {{PyClustering}},
	url = {https://joss.theoj.org/papers/10.21105/joss.01230},
	doi = {10.21105/joss.01230},
	abstract = {Novikov, (2019). PyClustering: Data Mining Library. Journal of Open Source Software, 4(36), 1230, https://doi.org/10.21105/joss.01230},
	language = {en},
	number = {36},
	urldate = {2023-05-27},
	journal = {Journal of Open Source Software},
	author = {Novikov, Andrei V.},
	month = apr,
	year = {2019},
	pages = {1230},
}

@article{novikov_oscillatory_2014,
	title = {Oscillatory neural networks based on the {Kuramoto} model for cluster analysis},
	volume = {24},
	issn = {1555-6212},
	url = {https://doi.org/10.1134/S1054661814030146},
	doi = {10.1134/S1054661814030146},
	abstract = {This paper presents the results of a study of synchronization processes in oscillatory neural networks of various structures based on the Kuramoto model. The estimates of synchronization processes occurring in the oscillatory networks are examined. The results of studying the practical application of oscillatory networks for solving cluster analysis problems are presented.},
	language = {en},
	number = {3},
	urldate = {2023-05-27},
	journal = {Pattern Recognition and Image Analysis},
	author = {Novikov, A. V. and Benderskaya, E. N.},
	month = sep,
	year = {2014},
	keywords = {Coupling Strength, Global Synchronization, Graph Coloring Problem, Graph Label, Synchronization Process},
	pages = {365--371},
}

@article{pelleg_x-means_2002,
	title = {X-means: {Extending} {K}-means with {Efficient} {Estimation} of the {Number} of {Clusters}},
	shorttitle = {X-means},
	abstract = {Despite its popularity for general clustering, K-means suffers three major shortcomings; it scales poorly computationally, the number of clusters K has to be supplied by the user, and the search is prone to local minima. We propose solutions for the first two problems, and a partial remedy for the third. Building on prior work for algorithmic acceleration that is not based on approximation, we introduce a new algorithm that efficiently, searches the space of cluster locations and number of clusters to optimize the Bayesian Information Criterion (BIC) or the Akaike Information Criterion (AIC) measure. The innovations include two new ways of exploiting cached sufficient statistics and a new very efficient test that in one K-means sweep selects the most promising subset of classes for refinement. This gives rise to a fast, statistically founded algorithm that outputs both the number of classes and their parameters. Experiments show this technique reveals the true number of classes in the underlying distribution, and that it is much faster than repeatedly using accelerated K-means for different values of K.},
	journal = {Machine Learning, p},
	author = {Pelleg, Dan and Moore, Andrew},
	month = jan,
	year = {2002},
}

@misc{noauthor_theory_nodate,
	title = {Theory and {Use} of the {EM} {Algorithm}},
	url = {https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/8186784},
	abstract = {Theory and Use of the EM Algorithm introduces the expectation-maximization (EM) algorithm and provides an intuitive and mathematically rigorous understanding of this method. It describes in detail two of the most popular applications of EM: estimating Gaussian mixture models (GMMs), and estimating hidden Markov models (HMMs). It also covers the use of EM for learning an optimal mixture of fixed models, for estimating the parameters of a compound Dirichlet distribution, and for disentangling superimposed signals. It discusses problems that arise in practice with EM, and variants of the algorithm that help deal with these challenges. Theory and Use of the EM Algorithm is designed to be useful to both the EM novice and the experienced EM user looking to better understand the method and its use.},
	language = {en-US},
	urldate = {2023-05-27},
}

@article{boutalbi_tensorclus_2022,
	title = {{TensorClus}: {A} python library for tensor ({Co})-clustering},
	volume = {468},
	issn = {0925-2312},
	shorttitle = {{TensorClus}},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231221013941},
	doi = {10.1016/j.neucom.2021.09.036},
	abstract = {Tensor data analysis is the evolutionary step of data analysis to more than two dimensions. Dealing with tensor data is often based on tensor decomposition methods. The present paper focuses on unsupervised learning and provides a python package referred to as TensorClus including novel co-clustering algorithms of three-way data. All proposed algorithms are based on the latent block models and suitable to different types of data, sparse or not. They are successfully evaluated on challenges in text mining, recommender systems, and hyperspectral image clustering. TensorClus is an open-source Python package that allows easy interaction with other python packages such as NumPy and TensorFlow; it also offers an interface with some tensor decomposition packages namely Tensorly and TensorD on the one hand, and on the other, the co-clustering package Coclust. Finally, it provides CPU and GPU compatibility. The TensorClus library is available at https://pypi.org/project/TensorClus/.},
	language = {en},
	urldate = {2023-05-27},
	journal = {Neurocomputing},
	author = {Boutalbi, Rafika and Labiod, Lazhar and Nadif, Mohamed},
	month = jan,
	year = {2022},
	keywords = {(Co)-clustering, Multiple graphs, Tensor decomposition, Tensors},
	pages = {464--468},
}

@article{guney_comparison_2009,
	title = {{COMPARISON} {OF} {MAMDANI} {AND} {SUGENO} {FUZZY} {INFERENCE} {SYSTEM} {MODELS} {FOR} {RESONANT} {FREQUENCY} {CALCULATION} {OF} {RECTANGULAR} {MICROSTRIP} {ANTENNAS}},
	volume = {12},
	issn = {1937-6472},
	url = {http://www.jpier.org/PIERB/pier.php?paper=08121302},
	doi = {10.2528/PIERB08121302},
	abstract = {Models based on fuzzy inference systems (FISs) for calculating the resonant frequency of rectangular microstrip antennas (MSAs) with thin and thick substrates are presented. Two types of FIS models, Mamdani FIS model and Sugeno FIS model, are used to compute the resonant frequency. The parameters of FIS models are determined by using various optimization algorithms. The resonant frequency results predicted by FIS models are in very good agreement with the experimental results available in the literature. When the performances of FIS models are compared with each other, the best result is obtained from the Sugeno FIS model trained by the leastsquares algorithm.},
	language = {en},
	urldate = {2023-05-27},
	journal = {Progress In Electromagnetics Research B},
	author = {Guney, Kerim and Sarikaya, Nurcan},
	year = {2009},
	pages = {81--104},
}

@article{antonelli_influence_2016,
	series = {Special issue on {Discovery} {Science}},
	title = {On the influence of feature selection in fuzzy rule-based regression model generation},
	volume = {329},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025515007008},
	doi = {10.1016/j.ins.2015.09.045},
	abstract = {Fuzzy rule-based models have been extensively used in regression problems. Besides high accuracy, one of the most appreciated characteristics of these models is their interpretability, which is generally measured in terms of complexity. Complexity is affected by the number of features used for generating the model: the lower the number of features, the lower the complexity. Feature selection can therefore considerably contribute not only to speed up the learning process, but also to improve the interpretability of the final model. Nevertheless, a very few methods for selecting features before learning regression models have been proposed in the literature. In this paper, we focus on these methods, which perform feature selection as pre-processing step. In particular, we have adapted two state-of-the-art feature selection algorithms, namely NMIFS and CFS, originally proposed for classification, to deal with regression. Further, we have proposed FMIFS, a novel forward sequential feature selection approach, based on the minimal-redundancy-maximal-relevance criterion, which can manage directly fuzzy partitions. The relevance and the redundancy of a feature are measured in terms of, respectively, the fuzzy mutual information between the feature and the output variable, and the average fuzzy mutual information between the feature and the just selected features. The stopping criterion for the sequential selection is based on the average values of relevance and redundancy of the just selected features. We have performed two experiments on twenty regression datasets. In the first experiment, we aimed to show the effectiveness of feature selection in fuzzy rule-based regression model generation by comparing the mean square errors achieved by the fuzzy rule-based models generated using all the features, and the features selected by FMIFS, NMIFS and CFS. In order to avoid possible biases related to the specific algorithm, we adopted the well-known Wang and Mendel algorithm for generating the fuzzy rule-based models. We present that the mean square errors obtained by models generated by using the features selected by FMIFS are on average similar to the values achieved by using all the features and lower than the ones obtained by employing the subset of features selected by NMIFS and CFS. In the second experiment, we intended to evaluate how feature selection can reduce the convergence time of the evolutionary fuzzy systems, which are probably the most effective fuzzy techniques for tackling regression problems. By using a state-of-the-art multi-objective evolutionary fuzzy system based on rule learning and membership function tuning, we show that the number of evaluations can be considerably reduced when pre-processing the dataset by feature selection.},
	language = {en},
	urldate = {2023-05-26},
	journal = {Information Sciences},
	author = {Antonelli, Michela and Ducange, Pietro and Marcelloni, Francesco and Segatori, Armando},
	month = feb,
	year = {2016},
	keywords = {Feature selection, Fuzzy mutual information, Fuzzy rule-based systems, High dimensional datasets, Multi-objective evolutionary fuzzy rule-based systems, Regression problems},
	pages = {649--669},
}

@inproceedings{antonelli_feature_2013,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Feature {Selection} {Based} on {Fuzzy} {Mutual} {Information}},
	isbn = {978-3-319-03200-9},
	doi = {10.1007/978-3-319-03200-9_4},
	abstract = {In the framework of fuzzy rule-based models for regression problems, we propose a novel approach to feature selection based on the minimal-redundancy-maximal-relevance criterion. The relevance of a feature is measured in terms of a novel definition of fuzzy mutual information between the feature and the output variable. The redundancy is computed as the average fuzzy mutual information between the feature and the just selected features. The approach results to be particularly suitable for selecting features before designing fuzzy rule-based systems (FRBSs). We tested our approach on twelve regression problems using Mamdani FRBSs built by applying the Wang and Mendel algorithm. We show that our approach is particularly effective in selecting features by comparing the mean square errors achieved by the Mamdani FRBSs generated using the features selected by a state of the art feature selection algorithm and by our approach.},
	language = {en},
	booktitle = {Fuzzy {Logic} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Antonelli, Michela and Ducange, Pietro and Marcelloni, Francesco},
	editor = {Masulli, Francesco and Pasi, Gabriella and Yager, Ronald},
	year = {2013},
	keywords = {Feature Selection, Fuzzy Mutual Information, High Dimensional Datasets, Regression Problems},
	pages = {36--43},
}

@article{jimenez_multi-objective_2017,
	title = {Multi-objective evolutionary feature selection for online sales forecasting},
	volume = {234},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231216315612},
	doi = {10.1016/j.neucom.2016.12.045},
	abstract = {Sales forecasting uses historical sales figures, in association with products characteristics and peculiarities, to predict short-term or long-term future performance in a business, and it can be used to derive sound financial and business plans. By using publicly available data, we build an accurate regression model for online sales forecasting obtained via a novel feature selection methodology composed by the application of the multi-objective evolutionary algorithm ENORA (Evolutionary NOn-dominated Radial slots based Algorithm) as search strategy in a wrapper method driven by the well-known regression model learner Random Forest. Our proposal integrates feature selection for regression, model evaluation, and decision making, in order to choose the most satisfactory model according to an a posteriori process in a multi-objective context. We test and compare the performances of ENORA as multi-objective evolutionary search strategy against a standard multi-objective evolutionary search strategy such as NSGA-II (Non-dominated Sorted Genetic Algorithm), against a classical backward search strategy such as RFE (Recursive Feature Elimination), and against the original data set.},
	language = {en},
	urldate = {2023-05-26},
	journal = {Neurocomputing},
	author = {Jiménez, F. and Sánchez, G. and García, J. M. and Sciavicco, G. and Miralles, L.},
	month = apr,
	year = {2017},
	keywords = {Feature selection, Multi-objective evolutionary algorithms, Online sales forecasting, Random forest, Regression model},
	pages = {75--92},
}

@article{alcala_fast_2011,
	title = {A {Fast} and {Scalable} {Multiobjective} {Genetic} {Fuzzy} {System} for {Linguistic} {Fuzzy} {Modeling} in {High}-{Dimensional} {Regression} {Problems}},
	volume = {19},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2011.2131657},
	abstract = {Linguistic fuzzy modeling in high-dimensional regression problems poses the challenge of exponential-rule explosion when the number of variables and/or instances becomes high. One way to address this problem is by determining the used variables, the linguistic partitioning and the rule set together, in order to only evolve very simple, but still accurate models. However, evolving these components together is a difficult task, which involves a complex search space. In this study, we propose an effective multiobjective evolutionary algorithm that, based on embedded genetic database (DB) learning (involved variables, granularities, and slight fuzzy-partition displacements), allows the fast learning of simple and quite-accurate linguistic models. Some efficient mechanisms have been designed to ensure a very fast, but not premature, convergence in problems with a high number of variables. Further, since additional problems could arise for datasets with a large number of instances, we also propose a general mechanism for the estimation of the model error when using evolutionary algorithms, by only considering a reduced subset of the examples. By doing so, we can also apply a fast postprocessing stage for further refining the learned solutions. We tested our approach on 17 real-world datasets with different numbers of variables and instances. Three well-known methods based on embedded genetic DB learning have been executed as references. We compared the different approaches by applying nonparametric statistical tests for multiple comparisons. The results confirm the effectiveness of the proposed method not only in terms of scalability but in terms of the simplicity and generalizability of the obtained models as well.},
	number = {4},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Alcala, Rafael and Gacto, María José and Herrera, Francisco},
	month = aug,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Convergence, Embedded genetic database learning, Encoding, Fuzzy systems, Genetics, Input variables, Pragmatics, Scalability, high-dimensional regression problems, linguistic fuzzy modeling, multiobjective genetic fuzzy systems, scalability},
	pages = {666--681},
}

@misc{noauthor_keel_nodate,
	title = {{KEEL}: {A} software tool to assess evolutionary algorithms for {Data} {Mining} problems (regression, classification, clustering, pattern mining and so on)},
	url = {http://www.keel.es/},
	urldate = {2023-05-26},
}

@article{gacto_metsk-hde_2014,
	title = {{METSK}-{HDe}: {A} multiobjective evolutionary algorithm to learn accurate {TSK}-fuzzy systems in high-dimensional and large-scale regression problems},
	volume = {276},
	issn = {0020-0255},
	shorttitle = {{METSK}-{HDe}},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025514001534},
	doi = {10.1016/j.ins.2014.02.047},
	abstract = {In this contribution, we propose a two-stage method for Accurate Fuzzy Modeling in High-Dimensional Regression Problems using Approximate Takagi–Sugeno–Kang Fuzzy Rule-Based Systems. In the first stage, an evolutionary data base learning is performed (involving variables, granularities and slight fuzzy partition displacements) together with an inductive rule base learning within the same process. The second stage is a post-processing process to perform a rule selection and a scatter-based tuning of the membership functions for further refinement of the learned solutions. Moreover, the second stage incorporates an efficient Kalman filter to learn the coefficients of the consequent polynomial function in the Takagi–Sugeno–Kang rules. Both stages include mechanisms that significantly improve the accuracy of the model and ensure a fast convergence in high-dimensional and large-scale regression datasets. We tested our approach on 28 real-world datasets with different numbers of variables and instances. Five well-known methods have been executed as references. We compared the different approaches by applying non-parametric statistical tests for pair-wise and multiple comparisons. The results confirm the effectiveness of the proposed method, showing better results in accuracy within a reasonable computing time.},
	language = {en},
	urldate = {2023-05-26},
	journal = {Information Sciences},
	author = {Gacto, M. J. and Galende, M. and Alcalá, R. and Herrera, F.},
	month = aug,
	year = {2014},
	keywords = {Accurate fuzzy modeling, Embedded genetic data base learning, High-dimensional and large-scale problems, Multi-objective genetic algorithms, Regression, Takagi–Sugeno–Kang rules},
	pages = {63--79},
}

@inproceedings{sevakula_fuzzy_2015,
	title = {Fuzzy {Rule} {Reduction} using {Sparse} {Auto}-{Encoders}},
	doi = {10.1109/FUZZ-IEEE.2015.7338118},
	abstract = {Fuzzy Rule based regression, classification and control have found great use in modern applications due to its simplicity, flexibility and capability. A key issue in all such methods is the computation time. Computational complexity of training and testing is linearly dependent on the size of fuzzy rule base and the respective fuzzy rule space is exponentially dependent on data dimensionality. Sparse Auto-Encoders (SAs) have become popular in giving compact feature representations for image, audio and speech data and have helped in giving state of the art pattern recognition performances in most of the domains. These feature representation are learnt in an unsupervised fashion and are found to give higher order building blocks with which the data is seemingly made of. This paper proposes a method where SAs are used for getting compact feature representation of input data and if needed with reduced dimensionality. The regular fuzzy rule based models are then learnt from data in the new feature space. The method was tested for Regression and Classification problems, giving impressive results in both. The method with Regression problem gave comparable performance with almost half the number of rules and with Classification problem it gave improvement in classification accuracy by 2.67\% while reducing the size of fuzzy rule base by 11.25 times and 7.5 times by number.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	author = {Sevakula, Rahul K. and Verma, Nishchal K.},
	month = aug,
	year = {2015},
	keywords = {Artificial neural networks, Computational complexity, Cost function, Data models, Knowledge based systems, Speech, Training, deep belief networks, deep learning, dimensionality reduction, fuzzy rule reduction, sparse autoencoder},
	pages = {1--7},
}

@inproceedings{bolat_interpreting_2020,
	title = {Interpreting {Variational} {Autoencoders} with {Fuzzy} {Logic}: {A} step towards interpretable deep learning based fuzzy classifiers},
	shorttitle = {Interpreting {Variational} {Autoencoders} with {Fuzzy} {Logic}},
	doi = {10.1109/FUZZ48607.2020.9177631},
	abstract = {The emerging success of Deep Learning (DL) in various application areas comes also with the questions starting with "How"s and "Why"s. These questions can be answered if the DL methods are interpretable and thus provide a certain a degree of explanation. In this paper, we propose a DL framework that leverages the advantages of β-Variational Autoencoder (VAE) and Fuzzy Sets (FSs), which are disentanglement and linguistic representation, for the design of a novel DL based Fuzzy Classifier (FC). We first present a step-by-step design approach to construct the DL-FC which is composed of the encoder layer of β-VAE and a Fuzzy Logic System (FLS) followed by a softmax layer. The β-VAE is trained so that the semantic information of the high dimensional data is captured. The latent space of the β-VAE is clustered to extract FSs. The FSs are then used to define antecedents of the FLS that is trained with DL methods. We present results conducted on the MNIST dataset and showed that DL-FC is quite competitive with its deep neural network counterpart. We then try to provide an interpretation to the antecedents of FLS by examining the FSs, the latent traversals and heat-maps of each latent dimension. The results show that the antecedents of FLS can be defined with linguistic interpretations. Thus, for the first time in the literature, we showed that linguistic interpretations can be defined for the latent space of β-VAE with FSs.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	author = {Bölat, Kutay and Kumbasar, Tufan},
	month = jul,
	year = {2020},
	note = {ISSN: 1558-4739},
	keywords = {Clustering algorithms, Feature extraction, Frequency selective surfaces, Fuzzy logic, Linguistics, Machine learning, Training, Variational autoencoder, classification, fuzzy cmeans clustering, fuzzy sets, interpretation},
	pages = {1--7},
}

@article{zhao_self-organized_2022,
	title = {A {Self}-{Organized} {Method} for a {Hierarchical} {Fuzzy} {Logic} {System} {Based} on a {Fuzzy} {Autoencoder}},
	volume = {30},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2022.3165690},
	abstract = {In this article, a novel design of a hierarchicalfuzzy system (HFS) based on a self-organized fuzzy partition and fuzzy autoencoder is proposed. The initial rule set of the system is empty, and all the fuzzy sets and fuzzy rules are generated by a self-organized fuzzy partition algorithm. By adopting an improved box plot data standardization method, the processed data can more accurately represent the distribution characteristics of the input data, which improve the accuracy and the rationality. A fuzzy autoencoder is used to train the HFS layer by layer, which can not only ensure the effectiveness of the fuzzy system's hidden layer variables but also provide interpretability. Compared with the traditional fuzzy logic system, the HFS reduces the total number of rules and the complexity. The proposed HFS is tested on three different regression datasets. The experimental results illustrate that the hierarchical self-organized fuzzy system still performs better in terms of regression accuracy indicators than the self-organized fuzzy system.},
	number = {12},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Zhao, Tao and Cao, Hongyi and Dian, Songyi},
	month = dec,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Complexity theory, Fuzzy autoencoder, Fuzzy logic, Fuzzy sets, Fuzzy systems, Input variables, Interoperability, Optimization, Predictive models, hierarchical fuzzy system (HFS), interpretability, regression prediction},
	pages = {5104--5115},
}

@article{aghaeipoor_mokblmoms_2019,
	title = {{MOKBL}+{MOMs}: {An} interpretable multi-objective evolutionary fuzzy system for learning high-dimensional regression data},
	volume = {496},
	issn = {0020-0255},
	shorttitle = {{MOKBL}+{MOMs}},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025519303494},
	doi = {10.1016/j.ins.2019.04.035},
	abstract = {This work presents a multi-objective evolutionary linguistic fuzzy system that addresses regression problems, especially those that are dimensional and scalable. A multi-objective knowledge base learning (MOKBL) is developed in the first stage of this model. MOKBL learns the most relevant and least redundant features by considering the desirability of the components of the fuzzy system. At the same time as feature selection, MOKBL slightly tunes the membership functions to provide greater initial adaptation of the fuzzy rule-based system components. In the second stage, multi-objective modifications (MOMs) are organized to modify the generated fuzzy system and to perform post-processing tasks. MOMs more finely tune the membership functions and prune additional rules. The newly proposed rule pruning method can eliminate weak rules from the rule base using the concepts of support and confidence. The membership functions tuning process is accomplished using the tasks of core displacement and width alteration of the symmetric functions. MOKBL+MOMs and its stages were validated using 28 real-world datasets and compared with two state-of-the-art regression solutions through non-parametric statistical tests. The experimental results confirmed the effectiveness of MOKBL+MOMs in terms of interpretability (complexity), accuracy, and time.},
	language = {en},
	urldate = {2023-05-25},
	journal = {Information Sciences},
	author = {Aghaeipoor, Fatemeh and Javidi, Mohammad Masoud},
	month = sep,
	year = {2019},
	keywords = {Fuzzy feature selection, Fuzzy mutual information, Fuzzy rule-based systems, High-dimensional regression problems, Multi-objective evolutionary algorithms, Rule pruning},
	pages = {1--24},
}

@article{freeman_centrality_1978,
	title = {Centrality in social networks conceptual clarification},
	volume = {1},
	issn = {0378-8733},
	url = {https://www.sciencedirect.com/science/article/pii/0378873378900217},
	doi = {10.1016/0378-8733(78)90021-7},
	abstract = {The intuitive background for measures of structural centrality in social networks is reviewed and existing measures are evaluated in terms of their consistency with intuitions and their interpretability. Three distinct intuitive conceptions of centrality are uncovered and existing measures are refined to embody these conceptions. Three measures are developed for each concept, one absolute and one relative measure of the centrality of positions in a network, and one reflecting the degree of centralization of the entire network. The implications of these measures for the experimental study of small groups is examined.},
	language = {en},
	number = {3},
	urldate = {2023-05-17},
	journal = {Social Networks},
	author = {Freeman, Linton C.},
	month = jan,
	year = {1978},
	pages = {215--239},
}

@inproceedings{qu_modified_2013,
	title = {A modified possibilistic fuzzy c-means clustering algorithm},
	doi = {10.1109/ICNC.2013.6818096},
	abstract = {Possibilistic clustering algorithm can give the fuzzy and possibilistic partition of the data set. This paper analyzes the mean shift clustering algorithm (MSC) and the possibilistic fuzzy c-means clustering algorithm (PFCM) in detail, base on which a modified possibilistic fuzzy c-means clustering algorithm (MPFCM) is proposed. The analysis shows that PFCM has the initialization sensitivity problems, while MSC can determine the cluster number in different scales and it is independent to the initializations. MPFCM not only inherits the merit of both the PFCM and MSC, but also avoids the problems from them. The experimental results show the relatively better performance of the proposed algorithm on computation and initialization.},
	booktitle = {2013 {Ninth} {International} {Conference} on {Natural} {Computation} ({ICNC})},
	author = {Qu, Fuheng and Hu, Yating and Xue, Yaohong and Yang, Yong},
	month = jul,
	year = {2013},
	note = {ISSN: 2157-9563},
	keywords = {Algorithm design and analysis, Bandwidth, Clustering algorithms, Complexity theory, Partitioning algorithms, Phase change materials, Sensitivity, fuzzy clustering, mean shift, multiscale structure, possibilistic clustering},
	pages = {858--862},
}

@article{carpenter_fuzzy_1992-1,
	title = {Fuzzy {ARTMAP}: {A} neural network architecture for incremental supervised learning of analog multidimensional maps},
	volume = {3},
	issn = {1941-0093},
	shorttitle = {Fuzzy {ARTMAP}},
	doi = {10.1109/72.159059},
	abstract = {A neural network architecture is introduced for incremental supervised learning of recognition categories and multidimensional maps in response to arbitrary sequences of analog or binary input vectors, which may represent fuzzy or crisp sets of features. The architecture, called fuzzy ARTMAP, achieves a synthesis of fuzzy logic and adaptive resonance theory (ART) neural networks by exploiting a close formal similarity between the computations of fuzzy subsethood and ART category choice, resonance, and learning. Four classes of simulation illustrated fuzzy ARTMAP performance in relation to benchmark backpropagation and generic algorithm systems. These simulations include finding points inside versus outside a circle, learning to tell two spirals apart, incremental approximation of a piecewise-continuous function, and a letter recognition database. The fuzzy ARTMAP system is also compared with Salzberg's NGE systems and with Simpson's FMMC system.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Carpenter, G.A. and Grossberg, S. and Markuzon, N. and Reynolds, J.H. and Rosen, D.B.},
	month = sep,
	year = {1992},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Computational modeling, Fuzzy logic, Fuzzy neural networks, Fuzzy sets, Fuzzy systems, Multidimensional systems, Neural networks, Resonance, Subspace constraints, Supervised learning},
	pages = {698--713},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: 0893-6080(95)00115-8 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/0893608095001158?token=C8D2346DAA583BCA0AFFCEEEE373D2A986A504AA90153DB419665345EB02366F439727346EED7635F22667AB7FDA2ADC&originRegion=us-east-1&originCreation=20230512214122},
	language = {en},
	urldate = {2023-05-12},
	doi = {10.1016/0893-6080(95)00115-8},
	note = {ISSN: 0893-6080},
}

@article{bazhenov_how_2023,
	title = {How to approximate fuzzy sets: mind-changes and the {Ershov} {Hierarchy}},
	volume = {201},
	shorttitle = {How to approximate fuzzy sets},
	doi = {10.1007/s11229-023-04056-y},
	abstract = {Computability theorists have introduced multiple hierarchies to measure the complexity of sets of natural numbers. The Kleene Hierarchy classifies sets according to the first-order complexity of their defining formulas. The Ershov Hierarchy classifies limit computable sets with respect to the number of mistakes that are needed to approximate them. Biacino and Gerla extended the Kleene Hierarchy to the realm of fuzzy sets, whose membership functions range in a complete lattice. In this paper, we combine the Ershov Hierarchy and fuzzy set theory, by introducing and investigating the Fuzzy Ershov Hierarchy.},
	journal = {Synthese},
	author = {Bazhenov, Nikolay and Mustafa, Manat and Ospichev, Sergey and San Mauro, Luca},
	month = feb,
	year = {2023},
}

@misc{park_generative_2023,
	title = {Generative {Agents}: {Interactive} {Simulacra} of {Human} {Behavior}},
	shorttitle = {Generative {Agents}},
	url = {http://arxiv.org/abs/2304.03442},
	doi = {10.48550/arXiv.2304.03442},
	abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
	urldate = {2023-04-17},
	publisher = {arXiv},
	author = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	month = apr,
	year = {2023},
	note = {arXiv:2304.03442 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@article{anand_unsupervised_nodate,
	title = {Unsupervised {State} {Representation} {Learning} in {Atari}},
	language = {en},
	author = {Anand, Ankesh and Racah, Evan and Ozair, Sherjil},
}

@misc{mazumder2023dataperf,
      title={DataPerf: Benchmarks for Data-Centric AI Development}, 
      author={Mark Mazumder and Colby Banbury and Xiaozhe Yao and Bojan Karlaš and William Gaviria Rojas and Sudnya Diamos and Greg Diamos and Lynn He and Alicia Parrish and Hannah Rose Kirk and Jessica Quaye and Charvi Rastogi and Douwe Kiela and David Jurado and David Kanter and Rafael Mosquera and Juan Ciro and Lora Aroyo and Bilge Acun and Lingjiao Chen and Mehul Smriti Raje and Max Bartolo and Sabri Eyuboglu and Amirata Ghorbani and Emmett Goodman and Oana Inel and Tariq Kane and Christine R. Kirkpatrick and Tzu-Sheng Kuo and Jonas Mueller and Tristan Thrush and Joaquin Vanschoren and Margaret Warren and Adina Williams and Serena Yeung and Newsha Ardalani and Praveen Paritosh and Lilith Bat-Leah and Ce Zhang and James Zou and Carole-Jean Wu and Cody Coleman and Andrew Ng and Peter Mattson and Vijay Janapa Reddi},
      year={2023},
      eprint={2207.10062},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ye_mastering_2021,
	title = {Mastering {Atari} {Games} with {Limited} {Data}},
	url = {http://arxiv.org/abs/2111.00210},
	doi = {10.48550/arXiv.2111.00210},
	abstract = {Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3\% mean human performance and 109.0\% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
	month = dec,
	year = {2021},
	note = {arXiv:2111.00210 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{zadeh_fuzzy_1996,
	title = {Fuzzy logic = computing with words},
	volume = {4},
	issn = {1941-0034},
	doi = {10.1109/91.493904},
	abstract = {As its name suggests, computing with words (CW) is a methodology in which words are used in place of numbers for computing and reasoning. The point of this note is that fuzzy logic plays a pivotal role in CW and vice-versa. Thus, as an approximation, fuzzy logic may be equated to CW. There are two major imperatives for computing with words. First, computing with words is a necessity when the available information is too imprecise to justify the use of numbers, and second, when there is a tolerance for imprecision which can be exploited to achieve tractability, robustness, low solution cost, and better rapport with reality. Exploitation of the tolerance for imprecision is an issue of central importance in CW. In CW, a word is viewed as a label of a granule; that is, a fuzzy set of points drawn together by similarity, with the fuzzy set playing the role of a fuzzy constraint on a variable. The premises are assumed to be expressed as propositions in a natural language. In coming years, computing with words is likely to evolve into a basic methodology in its own right with wide-ranging ramifications on both basic and applied levels.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Zadeh, L.A.},
	month = may,
	year = {1996},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Bayesian methods, Costs, Fuzzy logic, Fuzzy sets, Humans, NASA, Natural languages, Neural networks, Probabilistic logic, Robustness},
	pages = {103--111},
}

@article{yao_comparative_1998,
	title = {A comparative study of fuzzy sets and rough sets},
	volume = {109},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025598100233},
	doi = {10.1016/S0020-0255(98)10023-3},
	abstract = {This paper reviews and compares theories of fuzzy sets and rough sets. Two approaches for the formulation of fuzzy sets are reviewed, one is based on many-valued logic and the other is based on modal logic. Two views of rough sets are presented, set-oriented view and operator-oriented view. Rough sets under set-oriented view are closely related to fuzzy sets, which leads to non-truth-functional fuzzy set operators. Both of them may be considered as deviations of classical set algebra. In contrast, rough sets under operator-oriented view are different from fuzzy sets, and may be regarded as an extension of classical set algebra.},
	language = {en},
	number = {1},
	urldate = {2023-04-11},
	journal = {Information Sciences},
	author = {Yao, Y. Y.},
	month = aug,
	year = {1998},
	keywords = {Approximation operators, Fuzzy sets, Many-valued logic, Modal logic, Rough sets},
	pages = {227--242},
}

@incollection{lin_granular_1999,
	address = {Heidelberg},
	series = {Studies in {Fuzziness} and {Soft} {Computing}},
	title = {Granular {Computing}: {Fuzzy} {Logic} and {Rough} {Sets}},
	isbn = {978-3-7908-1873-4},
	shorttitle = {Granular {Computing}},
	url = {https://doi.org/10.1007/978-3-7908-1873-4_9},
	abstract = {The primary goal of granular computing is to elevate the lower level data processing to a high level knowledge processing. Such an elevation is achieved by granulating the data space into a concept space. Each granule represents certain primitive concept, and the granulation as a whole represents a knowledge. In this paper, such an intuitive idea is formalized into a mathematical theory: Zadeh’s informal words are taken literally as a formal definition of granulation. Such a mathematical notion is a mild generalization of the “old” notion of crisp/fuzzy neighborhood systems of (pre-)topological spaces. A crisp/fuzzy neighborhood is a granule and is assigned a meaningful name to represent certain primitive concept or to summarize the information content. The set of all linear combinations of these names, called formal words, mathematically forms a vector space over real numbers. Each vector is intuitively an advanced concept represented by some “weighted averaged” of primitive concepts. In terms of these concepts, the universe can be represented by a formal word table; this is one form of Zadeh’s veristic constraints. Such a representation is useful; fuzzy logic designs can be formulated as series of table transformations. So table processing techniques of rough set theory may be used to simplify these tables and their transformations. Therefore the complexity of large scaled fuzzy systems may be reduced; details will be reported in future papers.},
	language = {en},
	urldate = {2023-04-11},
	booktitle = {Computing with {Words} in {Information}/{Intelligent} {Systems} 1: {Foundations}},
	publisher = {Physica-Verlag HD},
	author = {Lin, T. Y.},
	editor = {Zadeh, Lotfi A. and Kacprzyk, Janusz},
	year = {1999},
	doi = {10.1007/978-3-7908-1873-4_9},
	keywords = {Binary Relation, Formal Word, Fuzzy Logic, Information Granulation, Neighborhood System},
	pages = {183--200},
}

@article{yao_comparative_nodate,
	title = {A {Comparative} {Study} of {Fuzzy} {Sets} and {Rough} {Sets}},
	volume = {109},
	abstract = {This paper reviews and compares theories of fuzzy sets and rough sets. Two approaches for the formulation of fuzzy sets are reviewed, one is based on many-valued logic and the other is based on modal logic. Two views of rough sets are presented, set-oriented view and operator-oriented view. Rough sets under set-oriented view are closely related to fuzzy sets, which leads to non-truth-functional fuzzy set operators. Both of them may be considered as deviations of classical set algebra. In contrast, rough sets under operator-oriented view are diﬀerent from fuzzy sets, and may be regarded as an extension of classical set algebra.},
	language = {en},
	number = {1},
	journal = {Information Sciences},
	author = {Yao, Y Y},
}

@incollection{rutkowska_neuro-fuzzy_2002,
	address = {Heidelberg},
	series = {Studies in {Fuzziness} and {Soft} {Computing}},
	title = {Neuro-{Fuzzy} {Architectures} {Based} on the {Mamdani} {Approach}},
	isbn = {978-3-7908-1802-4},
	url = {https://doi.org/10.1007/978-3-7908-1802-4_4},
	abstract = {The fuzzy inference neural networks (see Section 3.3) that realize the inference based on the Mamdani approach are the subject of this chapter. Different, multi-layer, architectures of the neuro-fuzzy systems are portrayed. The systems with various fuzzifiers (singleton, non-singleton), defuzzifiers, and inference operations, are considered. All these systems can be trained, when applied to solve practical problems, similarly to neural networks. Learning methods of neuro-fuzzy systems are presented in Chapter 6, including the architecture-based learning, proposed in Section 6.1.3. Interested readers may also be referred to [420], [434].},
	language = {en},
	urldate = {2023-04-11},
	booktitle = {Neuro-{Fuzzy} {Architectures} and {Hybrid} {Learning}},
	publisher = {Physica-Verlag HD},
	author = {Rutkowska, Danuta},
	editor = {Rutkowska, Danuta},
	year = {2002},
	doi = {10.1007/978-3-7908-1802-4_4},
	pages = {105--126},
}

@incollection{bouchon-meunier_xai_2022,
	address = {Cham},
	series = {Women in {Engineering} and {Science}},
	title = {{XAI}: {A} {Natural} {Application} {Domain} for {Fuzzy} {Set} {Theory}},
	isbn = {978-3-030-79092-9},
	shorttitle = {{XAI}},
	url = {https://doi.org/10.1007/978-3-030-79092-9_2},
	abstract = {As digital systems cover all personal and professional activities, artificial intelligence is now everywhere. In this context, it is crucial for systems and decisions to be understandable for humans, in a human-in-the-loop process. This global objective is known as eXplainable Artificial Intelligence (XAI). In this chapter, we argue that fuzzy logic is a key concept for XAI as it offers a theoretical framework that is closer than many others to human cognition, human reasoning and human intuitions. We exemplify the many advantages fuzzy logic offers to the XAI domain.},
	language = {en},
	urldate = {2023-04-11},
	booktitle = {Women in {Computational} {Intelligence}: {Key} {Advances} and {Perspectives} on {Emerging} {Topics}},
	publisher = {Springer International Publishing},
	author = {Bouchon-Meunier, Bernadette and Laurent, Anne and Lesot, Marie-Jeanne},
	editor = {Smith, Alice E.},
	year = {2022},
	doi = {10.1007/978-3-030-79092-9_2},
	keywords = {Approximate reasoning, Artificial intelligence, Computing with words, Explainable AI (XAI), Fuzzy logic, Machine learning},
	pages = {23--49},
}

@article{bouchon-meunier_lotfi_2021,
	title = {{Lotfi} {A}. {Zadeh}, {The} {Visionary} {In} {Explainable} {Artificial} {Intelligence}},
	abstract = {In this paper, we describe various aspects of Explainable Artiﬁcial Intelligence (XAI) and we show that fuzzy systems can help to approach several of these aspects. We focus on the pioneering works of L.A. Zadeh that oﬀer precious tools for the current XAI challenges. We show that they are not limited to approaches of natural language, but they also help to assist the user in understanding the meaning of the decisions made by artiﬁcial intelligencebased systems and to provide explanations about the way these decisions are made.},
	language = {en},
	author = {Bouchon-Meunier, B and Lesot, M J and Marsala, C},
	year = {2021},
}

@article{etz_innovative_2019,
	title = {An {Innovative} {Three}-{Step} {Method} for {Identifying} {Exemplars}},
	volume = {18},
	issn = {1609-4069},
	url = {https://doi.org/10.1177/1609406919867794},
	doi = {10.1177/1609406919867794},
	abstract = {Purpose:To improve practices in rapidly changing environments, it is helpful to learn from relevant innovators. This article describes a well-defined and adaptable method for discovering innovative cases that inform best practices or positive/negative deviant research.Methods:As part of a national study of innovation in primary care settings, we developed a three-step method for identifying exemplar practices and applied that method to finding a sample of relevant innovators for in-depth case studies from which to draw transportable lessons about improving primary care practice.Results:Relevant, information-rich cases are uncovered using cycles of identification, sampling, and assessment. This cycle is repeated at each step of the defined three-step method. Step 1, a scan of the published literature, assesses both the state-of-the-art and the baseline characteristics of relevant cases; Step 2, a scan of practice settings, draws upon the expert knowledge of key informants to identify additional potentially relevant cases; and Step 3, sample refinement, evaluates potential cases for eligibility, purposeful diversity, and information-rich expressions of defined key domains. Using this three-step method, we identified a national cohort of primary care practice innovators. We found the method to be feasible, practical, and highly successful at identifying information-rich practices from which to draw transportable lessons about practice innovation.Conclusions:The three-step method outlines an effective sampling strategy for identifying innovation exemplars and information-rich cases that exceed measures of central tendency. By leveraging the collective knowledge of innovators, this method can support dynamic research and foster rapid cycle learning.},
	language = {en},
	urldate = {2023-04-11},
	journal = {International Journal of Qualitative Methods},
	author = {Etz, Rebecca S. and Gonzalez, Martha M. and Crabtree, Benjamin F. and Reves, Sarah R. and Stange, Kurt C.},
	month = jan,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	pages = {1609406919867794},
}

@article{guo_concise_2022,
	title = {A {Concise} {TSK} {Fuzzy} {Ensemble} {Classifier} {Integrating} {Dropout} and {Bagging} for {High}-{Dimensional} {Problems}},
	volume = {30},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2021.3106330},
	abstract = {Improving the tradeoff between accuracy and interpretability is essential for the problem of handling high-dimensional data in Takagi–Sugeno–Kang (TSK) fuzzy systems and providing insights into real-world tasks. However, the TSK fuzzy system becomes complex and challenging to interpret as the data dimension increases. Here, we report an ensemble classifier, which is an enhanced adaptive network-based fuzzy inference system (ANFIS) integrating improved bagging and dropout to build concise fuzzy rule sets. First, the high-dimensional feature space is decomposed into a series of low-dimensional feature subsets using the bagging and random subspace method to train multiple ANFISs. An improved dropout strategy is then applied in training ANFISs by temporarily disabling rules in each training epoch and deleting rules after training to obtain sparse rulesets with high-quality rules. These sub-models are subsequently aggregated to perform the fuzzy inference. Results on high-dimensional benchmark datasets confirm that both the bagging and dropout strategies are effective, providing high interpretability by reducing the co-firing degrees and rules of sub-models while guaranteeing accuracy at the same time.},
	number = {8},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Guo, Fei and Liu, Jiahuan and Li, Maoyuan and Huang, Tianlun and Zhang, Yun and Li, Dequn and Zhou, Huamin},
	month = aug,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Adaptive network-based fuzzy inference system (ANFIS), Bagging, Complexity theory, Firing, Fuzzy sets, Fuzzy systems, Task analysis, Training, bagging, dropout, ensemble learning, interpretability},
	pages = {3176--3190},
}

@inproceedings{chai_mamdani_2009,
	title = {Mamdani {Model} {Based} {Adaptive} {Neural} {Fuzzy} {Inference} {System} and its {Application} in {Traffic} {Level} of {Service} {Evaluation}},
	volume = {4},
	doi = {10.1109/FSKD.2009.76},
	abstract = {Hybrid algorithm is the hot issue in Computational Intelligence (CI) study. From in-depth discussion on Simulation Mechanism Based (SMB) classification method and composite patterns, this paper presents the Mamdani model based Adaptive Neural Fuzzy Inference System (M-ANFIS) and weight updating formula in consideration with qualitative representation of inference consequent parts in fuzzy neural networks. M-ANFIS model adopts Mamdani fuzzy inference system which has advantages in consequent part. Experiment results of applying M-ANFIS to evaluate traffic Level of service show that M-ANFIS, as a new hybrid algorithm in computational intelligence, has great advantages in non-linear modeling, membership functions in consequent parts, scale of training data and amount of adjusted parameters.},
	booktitle = {2009 {Sixth} {International} {Conference} on {Fuzzy} {Systems} and {Knowledge} {Discovery}},
	author = {Chai, Yuanyuan and Jia, Limin and Zhang, Zundong},
	month = aug,
	year = {2009},
	keywords = {Artificial neural networks, Computational intelligence, Computational modeling, Fuzzy control, Fuzzy logic, Fuzzy neural networks, Fuzzy systems, Inference algorithms, Mamdani model based Adaptive Neural Fuzzy Inference System, Neural networks, Traffic control, fuzzy neural network, level of service evaluation model},
	pages = {555--559},
}

@article{navarro-almanza_interpretable_2022,
	title = {Interpretable {Mamdani} neuro-fuzzy model through context awareness and linguistic adaptation},
	volume = {189},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417421014317},
	doi = {10.1016/j.eswa.2021.116098},
	abstract = {Interpretable machine learning is trending as it aims to build a human-understandable decision process. There are two main types of machine learning systems: white-box and black-box models. White-box models are inherently interpretable but commonly suffer from under-fitting phenomena; on the other hand, black-box models perform quite well in a wide range of application domain problems, but their reasoning behind a decision is hard or even impossible to understand. In the soft-computing area, fuzzy inference systems are rule-based systems that use fuzzy reasoning, bringing human perception modeling and computing with word capability. These rule-based systems are designed either manually or automatically but are commonly optimized to fit better some phenomena’ data (in a supervised learning task). After the optimization process, the initial semantic meaning of fuzzy sets is modified (slightly, in the best cases), creating a gray-box model. The principal objective of the proposed methodology in this paper is to extract a high-quality rule in terms of comprehensibility, accuracy and fidelity. This is accomplished by using a fuzzy linguistic interpretable model from an optimized neuro-fuzzy model, considering the initial knowledge context with which it was built. A grammar-guided genetic algorithm is used as the optimization process to find the interpretable description of the model. A collection of 16 datasets for classification tasks were used to evaluate our proposal, obtaining an f1-score of 0.814 with 0.026 standard deviation in the optimized model; the obtained fidelity, in terms of similarity from the interpretable model to the optimized one, was 0.93 of mean with 0.018 standard deviation. Obtained results show that neuro-fuzzy systems could play an important role in interpretable machine learning, providing natural language explanations from previous knowledge.},
	language = {en},
	urldate = {2023-04-11},
	journal = {Expert Systems with Applications},
	author = {Navarro-Almanza, Raul and Sanchez, Mauricio A. and Castro, Juan R. and Mendoza, Olivia and Licea, Guillermo},
	month = mar,
	year = {2022},
	keywords = {Automatic fuzzy rule generation, Fuzzy knowledge base, Grammar-Guide Genetic Algorithms, Interpretable machine learning},
	pages = {116098},
}

@article{sanz_wrapper_2021,
	title = {A wrapper methodology to learn interval-valued fuzzy rule-based classification systems},
	volume = {104},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494621001721},
	doi = {10.1016/j.asoc.2021.107249},
	abstract = {Learning an interval-valued fuzzy rule-based classification system is a challenge as its success directly depends on the interval-valued fuzzy partition used. In fact, the learning of an interval-valued fuzzy system usually starts by creating a partition composed of numerical fuzzy sets, which are used to build an initial fuzzy classifier. Then, it is augmented with interval-valued fuzzy sets whose shape is subsequently optimized to improve the system’s performance. However, as in this methodology the fuzzy rules are learned using numerical fuzzy sets, the benefits of the interval-valued fuzzy sets may not be fully exploited. In this paper we define a new learning methodology that avoids building the initial fuzzy classifier but directly learns interval-valued fuzzy rules. To do so, we define a wrapper methodology to learn the interval-valued fuzzy partitions such that they lead to an interval-valued fuzzy rule-based classification system as accurate as possible. Moreover, our new method allows one to represent each membership function using the most proper type of fuzzy set for the sake of modeling the uncertainty in the best possible manner. Consequently, the antecedents of the rules can be formed of only numerical fuzzy sets, only interval-valued fuzzy sets or a mixture of both. The quality of the proposal is compared versus four state-of-the-art fuzzy classifiers like FARC-HD, IVTURS, FURIA and FARC-HD using an inference based on a generalization of the Choquet integral. We also compare our new approach besides its numerical fuzzy counterpart to clearly show the benefits of the usage of interval-valued fuzzy sets. Specifically, the average accuracy rate of our new method is 81.17\%, which is at least 0.66\% better than the remainder state-of-the-art fuzzy classifiers.},
	language = {en},
	urldate = {2023-04-11},
	journal = {Applied Soft Computing},
	author = {Sanz, Jose Antonio and Bustince, Humberto},
	month = jun,
	year = {2021},
	keywords = {Classification problems, Evolutionary fuzzy systems, Fuzzy rule-based classification systems, Interval type-2 fuzzy sets, Interval-valued fuzzy sets},
	pages = {107249},
}

@misc{cui_curse_2021,
	title = {Curse of {Dimensionality} for {TSK} {Fuzzy} {Neural} {Networks}: {Explanation} and {Solutions}},
	shorttitle = {Curse of {Dimensionality} for {TSK} {Fuzzy} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2102.04271},
	abstract = {Takagi-Sugeno-Kang (TSK) fuzzy system with Gaussian membership functions (MFs) is one of the most widely used fuzzy systems in machine learning. However, it usually has difficulty handling high-dimensional datasets. This paper explores why TSK fuzzy systems with Gaussian MFs may fail on high-dimensional inputs. After transforming defuzzification to an equivalent form of softmax function, we find that the poor performance is due to the saturation of softmax. We show that two defuzzification operations, LogTSK and HTSK, the latter of which is first proposed in this paper, can avoid the saturation. Experimental results on datasets with various dimensionalities validated our analysis and demonstrated the effectiveness of LogTSK and HTSK.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Cui, Yuqi and Wu, Dongrui and Xu, Yifan},
	month = feb,
	year = {2021},
	note = {arXiv:2102.04271 [cs]},
	keywords = {Computer Science - Machine Learning, Curse of dimensionality, Fuzzy neural network, TSK},
}

@inproceedings{chen_towards_2002,
	title = {Towards {Automatic} {Generation} of {Natural} {Language} {Generation} {Systems}},
	url = {https://aclanthology.org/C02-1138},
	urldate = {2023-04-11},
	booktitle = {{COLING} 2002: {The} 19th {International} {Conference} on {Computational} {Linguistics}},
	author = {Chen, John and Bangalore, Srinivas and Rambow, Owen and Walker, Marilyn A.},
	year = {2002},
}

@inproceedings{zia_neuro-fuzzy_1994,
	title = {Neuro-fuzzy control using self-organizing neural nets},
	doi = {10.1109/FUZZY.1994.343715},
	abstract = {This paper discusses a new approach to design a fuzzy logic control system, based on the self-organizing map (SOM) neural network. SOM is used to generate multivariate fuzzy state space from system's input-output data through unsupervised training. The trained SOM is then used as a part of an inference mechanism for a fuzzy logic controller. The proposed method is compared with other fuzzy neural network approaches. Sample data from a chemical plant is used to demonstrate the technique.{\textless}{\textgreater}},
	booktitle = {Proceedings of 1994 {IEEE} 3rd {International} {Fuzzy} {Systems} {Conference}},
	author = {Zia, F. and Isik, C.},
	month = jun,
	year = {1994},
	keywords = {Clustering, Clustering algorithms, Control systems, Fuzzy control, Fuzzy logic, Fuzzy neural network, Fuzzy neural networks, Fuzzy system, Fuzzy systems, Humans, Inference algorithms, Neural network, Neural networks, Organizing, Self-organizing},
	pages = {70--75 vol.1},
}

@article{alimi_beta_2003,
	title = {Beta fuzzy logic systems: approximation {Properties} in the {MIMO} {Case}},
	volume = {13},
	shorttitle = {Beta fuzzy logic systems},
	abstract = {Many researches have been interested in the approximation properties of Fuzzy Logic Systems (FLS), which, like neural networks, can be seen as approximation schemes. Almost all of them tackled the Mamdani fuzzy model, which was shown to have many interesting approximation features. However, only in few cases the Sugeno fuzzy model was considered. In this paper, we are interested in the zero-order Multi-Input–Multi-Output (MIMO) Sugeno fuzzy model with Beta membership functions. This leads to Beta Fuzzy Logic Systems (BFLS). We show that BFLSs are universal approximators. We also prove that they possess the best approximation property and the interpolation characteristic.},
	journal = {Int. J. Appl. Math. Comput. Sci},
	author = {Alimi, Adel and Hassine, Radhia and Selmi, Mohamed},
	month = jan,
	year = {2003},
	pages = {225--238},
}

@inproceedings{chai_mamdani_2009-1,
	title = {Mamdani {Model} {Based} {Adaptive} {Neural} {Fuzzy} {Inference} {System} and its {Application} in {Traffic} {Level} of {Service} {Evaluation}},
	volume = {4},
	doi = {10.1109/FSKD.2009.76},
	abstract = {Hybrid algorithm is the hot issue in Computational Intelligence (CI) study. From in-depth discussion on Simulation Mechanism Based (SMB) classification method and composite patterns, this paper presents the Mamdani model based Adaptive Neural Fuzzy Inference System (M-ANFIS) and weight updating formula in consideration with qualitative representation of inference consequent parts in fuzzy neural networks. M-ANFIS model adopts Mamdani fuzzy inference system which has advantages in consequent part. Experiment results of applying M-ANFIS to evaluate traffic Level of service show that M-ANFIS, as a new hybrid algorithm in computational intelligence, has great advantages in non-linear modeling, membership functions in consequent parts, scale of training data and amount of adjusted parameters.},
	booktitle = {2009 {Sixth} {International} {Conference} on {Fuzzy} {Systems} and {Knowledge} {Discovery}},
	author = {Chai, Yuanyuan and Jia, Limin and Zhang, Zundong},
	month = aug,
	year = {2009},
	keywords = {Artificial neural networks, Computational intelligence, Computational modeling, Fuzzy control, Fuzzy logic, Fuzzy neural networks, Fuzzy systems, Inference algorithms, Mamdani model based Adaptive Neural Fuzzy Inference System, Neural networks, Traffic control, fuzzy neural network, level of service evaluation model},
	pages = {555--559},
}

@incollection{rutkowska_neuro-fuzzy_2002-1,
	address = {Heidelberg},
	series = {Studies in {Fuzziness} and {Soft} {Computing}},
	title = {Neuro-{Fuzzy} {Architectures} {Based} on the {Mamdani} {Approach}},
	isbn = {978-3-7908-1802-4},
	url = {https://doi.org/10.1007/978-3-7908-1802-4_4},
	abstract = {The fuzzy inference neural networks (see Section 3.3) that realize the inference based on the Mamdani approach are the subject of this chapter. Different, multi-layer, architectures of the neuro-fuzzy systems are portrayed. The systems with various fuzzifiers (singleton, non-singleton), defuzzifiers, and inference operations, are considered. All these systems can be trained, when applied to solve practical problems, similarly to neural networks. Learning methods of neuro-fuzzy systems are presented in Chapter 6, including the architecture-based learning, proposed in Section 6.1.3. Interested readers may also be referred to [420], [434].},
	language = {en},
	urldate = {2023-02-21},
	booktitle = {Neuro-{Fuzzy} {Architectures} and {Hybrid} {Learning}},
	publisher = {Physica-Verlag HD},
	author = {Rutkowska, Danuta},
	editor = {Rutkowska, Danuta},
	year = {2002},
	doi = {10.1007/978-3-7908-1802-4_4},
	pages = {105--126},
}

@article{bezdek_fcm_1984,
	title = {{FCM}: {The} fuzzy c-means clustering algorithm},
	volume = {10},
	issn = {0098-3004},
	shorttitle = {{FCM}},
	url = {https://www.sciencedirect.com/science/article/pii/0098300484900207},
	doi = {10.1016/0098-3004(84)90020-7},
	abstract = {This paper transmits a FORTRAN-IV coding of the fuzzy c-means (FCM) clustering program. The FCM program is applicable to a wide variety of geostatistical data analysis problems. This program generates fuzzy partitions and prototypes for any set of numerical data. These partitions are useful for corroborating known substructures or suggesting substructure in unexplored data. The clustering criterion used to aggregate subsets is a generalized least-squares objective function. Features of this program include a choice of three norms (Euclidean, Diagonal, or Mahalonobis), an adjustable weighting factor that essentially controls sensitivity to noise, acceptance of variable numbers of clusters, and outputs that include several measures of cluster validity.},
	language = {en},
	number = {2},
	urldate = {2023-02-15},
	journal = {Computers \& Geosciences},
	author = {Bezdek, James C. and Ehrlich, Robert and Full, William},
	month = jan,
	year = {1984},
	keywords = {Cluster analysis, Cluster validity, Fuzzy QMODEL, Fuzzy clustering, Least-squared errors},
	pages = {191--203},
}

@article{navarro-almanza_interpretable_2022-1,
	title = {Interpretable {Mamdani} neuro-fuzzy model through context awareness and linguistic adaptation},
	volume = {189},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417421014317},
	doi = {10.1016/j.eswa.2021.116098},
	abstract = {Interpretable machine learning is trending as it aims to build a human-understandable decision process. There are two main types of machine learning systems: white-box and black-box models. White-box models are inherently interpretable but commonly suffer from under-fitting phenomena; on the other hand, black-box models perform quite well in a wide range of application domain problems, but their reasoning behind a decision is hard or even impossible to understand. In the soft-computing area, fuzzy inference systems are rule-based systems that use fuzzy reasoning, bringing human perception modeling and computing with word capability. These rule-based systems are designed either manually or automatically but are commonly optimized to fit better some phenomena’ data (in a supervised learning task). After the optimization process, the initial semantic meaning of fuzzy sets is modified (slightly, in the best cases), creating a gray-box model. The principal objective of the proposed methodology in this paper is to extract a high-quality rule in terms of comprehensibility, accuracy and fidelity. This is accomplished by using a fuzzy linguistic interpretable model from an optimized neuro-fuzzy model, considering the initial knowledge context with which it was built. A grammar-guided genetic algorithm is used as the optimization process to find the interpretable description of the model. A collection of 16 datasets for classification tasks were used to evaluate our proposal, obtaining an f1-score of 0.814 with 0.026 standard deviation in the optimized model; the obtained fidelity, in terms of similarity from the interpretable model to the optimized one, was 0.93 of mean with 0.018 standard deviation. Obtained results show that neuro-fuzzy systems could play an important role in interpretable machine learning, providing natural language explanations from previous knowledge.},
	language = {en},
	urldate = {2023-02-21},
	journal = {Expert Systems with Applications},
	author = {Navarro-Almanza, Raul and Sanchez, Mauricio A. and Castro, Juan R. and Mendoza, Olivia and Licea, Guillermo},
	month = mar,
	year = {2022},
	keywords = {Automatic fuzzy rule generation, Fuzzy knowledge base, Grammar-Guide Genetic Algorithms, Interpretable machine learning},
	pages = {116098},
}

@article{ibarra_spiking_2010,
	title = {On spiking neural {P} systems},
	volume = {9},
	issn = {1572-9796},
	url = {https://doi.org/10.1007/s11047-009-9159-3},
	doi = {10.1007/s11047-009-9159-3},
	abstract = {This work deals with several aspects concerning the formal verification of SN P systems and the computing power of some variants. A methodology based on the information given by the transition diagram associated with an SN P system is presented. The analysis of the diagram cycles codifies invariants formulae which enable us to establish the soundness and completeness of the system with respect to the problem it tries to resolve. We also study the universality of asynchronous and sequential SN P systems and the capability these models have to generate certain classes of languages. Further, by making a slight modification to the standard SN P systems, we introduce a new variant of SN P systems with a special I/O mode, called SN P modules, and study their computing power. It is demonstrated that, as string language acceptors and transducers, SN P modules can simulate several types of computing devices such as finite automata, a-finite transducers, and systolic trellis automata.},
	language = {en},
	number = {2},
	urldate = {2023-02-21},
	journal = {Natural Computing},
	author = {Ibarra, Oscar H. and Pérez-Jiménez, Mario J. and Yokomori, Takashi},
	month = jun,
	year = {2010},
	pages = {475--491},
}

@incollection{hutchison_flow_2005,
	address = {Berlin, Heidelberg},
	title = {Flow {Graphs} and {Data} {Mining}},
	volume = {3400},
	isbn = {978-3-540-25998-5 978-3-540-31850-7},
	url = {http://link.springer.com/10.1007/11427834_1},
	abstract = {In this paper we propose a new approach to data mining and knowledge discovery based on information ﬂow distribution in a ﬂow graph. Flow graphs introduced in this paper are diﬀerent from those proposed by Ford and Fulkerson for optimal ﬂow analysis and they model ﬂow distribution in a network rather than the optimal ﬂow which is used for information ﬂow examination in decision algorithms. It is revealed that ﬂow in a ﬂow graph is governed by Bayes’ rule, but the rule has an entirely deterministic interpretation without referring to its probabilistic roots. Besides, a decision algorithm induced by a ﬂow graph and dependency between conditions and decisions of decision rules is introduced and studied, which is used next to simplify decision algorithms.},
	language = {en},
	urldate = {2023-02-15},
	booktitle = {Transactions on {Rough} {Sets} {III}},
	publisher = {Springer Berlin Heidelberg},
	author = {Pawlak, Zdzisław},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Peters, James F. and Skowron, Andrzej},
	year = {2005},
	doi = {10.1007/11427834_1},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {1--36},
}

@misc{noauthor_opencv_nodate,
	title = {{OpenCV}: {Introduction} to {SIFT} ({Scale}-{Invariant} {Feature} {Transform})},
	url = {https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html},
	urldate = {2023-02-15},
}

@article{lowe_distinctive_2004,
	title = {Distinctive {Image} {Features} from {Scale}-{Invariant} {Keypoints}},
	volume = {60},
	issn = {0920-5691},
	url = {http://link.springer.com/10.1023/B:VISI.0000029664.99615.94},
	doi = {10.1023/B:VISI.0000029664.99615.94},
	abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a a substantial range of afﬁne distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and ﬁnally performing veriﬁcation through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
	language = {en},
	number = {2},
	urldate = {2023-02-15},
	journal = {International Journal of Computer Vision},
	author = {Lowe, David G.},
	month = nov,
	year = {2004},
	pages = {91--110},
}

@inproceedings{rumelhart_learning_1988,
	title = {Learning {Internal} {Representations} by {Error} {Propagation}},
	isbn = {978-1-4832-1446-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9781483214467500352},
	doi = {10.1016/B978-1-4832-1446-7.50035-2},
	abstract = {Semantic Scholar extracted view of "Learning internal representations by error propagation" by D. Rumelhart et al.},
	language = {en},
	urldate = {2023-02-15},
	publisher = {Elsevier},
	author = {Rumelhart, D.E. and Hinton, G.E. and Williams, R.J.},
	year = {1988},
	doi = {10.1016/B978-1-4832-1446-7.50035-2},
	note = {Book Title: Readings in Cognitive Science},
	pages = {399--421},
}

@misc{noauthor_fcm_nodate,
	title = {{FCM}: {The} fuzzy c-means clustering algorithm - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/0098300484900207},
	urldate = {2023-02-15},
}

@article{corke_robotics_1996,
	title = {A robotics toolbox for {MATLAB}},
	volume = {3},
	issn = {1558-223X},
	doi = {10.1109/100.486658},
	abstract = {The Robotics Toolbox is a software package that allows a MATLAB user to readily create and manipulate datatypes fundamental to robotics such as homogeneous transformations, quaternions and trajectories. Functions provided, for arbitrary serial-link manipulators, include forward and inverse kinematics, Jacobians, and forward and inverse dynamics. This article introduces the Toolbox in tutorial form, with examples chosen to demonstrate a range of capabilities. The complete Toolbox and documentation is freely available via anonymous ftp.},
	number = {1},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Corke, P.I.},
	month = mar,
	year = {1996},
	note = {Conference Name: IEEE Robotics \& Automation Magazine},
	keywords = {Computer languages, Documentation, Jacobian matrices, MATLAB, Manipulator dynamics, Orbital robotics, Quaternions, Robot kinematics, Robotics and automation, Software packages},
	pages = {24--32},
}

@article{nakanishi_review_1993,
	title = {A review and comparison of six reasoning methods},
	volume = {57},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/016501149390024C},
	doi = {10.1016/0165-0114(93)90024-C},
	abstract = {Five fuzzy reasoning methods are reviewed and their performance is compared with respect to a fuzzy control system model developed by an objective method based on three sets of real-life data. It is found from the investigation that: the reasoning precision, the calculation time and the number of possible input states to which a given reasoning method responds differ according to each reasoning method. Generally, the point-valued reasoning methods which are based on the assumption that connectives are crisp give better precision and shorter calculation time. When the connectives are assumed to be linguistic, reasoning with interval-valued fuzzy sets are more appropriate to represent linguistic uncertainty. For this reason, type II fuzziness generated with interval-valued fuzzy sets are better handled with interval-valued reasoning methods.},
	language = {en},
	number = {3},
	urldate = {2023-02-15},
	journal = {Fuzzy Sets and Systems},
	author = {Nakanishi, H. and Turksen, I. B. and Sugeno, M.},
	month = aug,
	year = {1993},
	keywords = {Reasoning methods, approximate analogical reasoning, compositional rule of inference, fuzzy models},
	pages = {257--294},
}

@misc{noauthor_delve_nodate,
	title = {delve kin family},
	url = {https://www.cs.toronto.edu/~delve/data/kin/desc.html},
	urldate = {2023-02-15},
}

@misc{noauthor_pii_nodate-1,
	title = {{PII}: 0165-0114(93)90024-{C} {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/016501149390024C?token=3489A2EB230EBD53FBF3871D28D33B4B543F9E1D7D7C82D9E68DFD397AFEB2891985C4A7AECD4BF179F04E23E0328D21&originRegion=us-east-1&originCreation=20230214063158},
	language = {en},
	urldate = {2023-02-14},
	doi = {10.1016/0165-0114(93)90024-C},
	note = {ISSN: 0165-0114},
}

@article{iyer_pie-rspop_2018,
	title = {{PIE}-{RSPOP}: {A} brain-inspired pseudo-incremental ensemble rough set pseudo-outer product fuzzy neural network},
	volume = {95},
	issn = {0957-4174},
	shorttitle = {{PIE}-{RSPOP}},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417417307832},
	doi = {10.1016/j.eswa.2017.11.027},
	abstract = {A novel pseudo-incremental ensemble rough set pseudo-outer product (PIE-RSPOP) fuzzy neural network is proposed for learning and prediction of trends in complex temporal series. It incorporates four theories pertaining to the learning and memorizing mechanisms in human beings. BCM theory of synaptic metaplasticity replaces Hebbian learning of weights of fuzzy rules and allows for a more natural associative–dissociative learning of weights. Short term forgetting of weights of the fuzzy rules is integrated for rules that are recalled and rules that are not recalled by an instance of data through Ebbinghaus theory of forgetting due to decay and displacement. The long term forgetting of networks in the ensemble is also incorporated through exponential decay of weights based on the age and strengths of the networks. Lastly, a hippocampal mechanism for caching the memories for subsequent recall is proposed. Another contribution of PIE-RSPOP is its ability to deal with concept drift and less storage of historical data. Lastly, despite the usually uninterpretable nature of incremental ensembles of fuzzy networks, a scheme to derive simple interpretable single knowledge base is also proposed. Variety of numerical results on standard datasets are used to demonstrate the advantages of PIE-RSPOP over other incremental learning methods.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Expert Systems with Applications},
	author = {Iyer, Aparna Ramesh and Prasad, Dilip K. and Quek, Chai Hiok},
	month = apr,
	year = {2018},
	keywords = {Fuzzy neural networks, Incremental learning},
	pages = {172--189},
}

@article{yao_generalization_1996,
	title = {Generalization of {Rough} {Sets} using {Modal} {Logics}},
	volume = {2},
	issn = {1079-8587},
	url = {https://doi.org/10.1080/10798587.1996.10750660},
	doi = {10.1080/10798587.1996.10750660},
	abstract = {The theory of rough sets is an extension of set theory with two additional unary set-theoretic operators defined based on a binary relation on the universe. These two operators are related to the modal operators in modal logics. By exploring the relationship between rough sets and modal logics, this paper proposes and examines a number of extended rough set models. By the properties satisfied by a binary relation, such as serial, reflexive, symmetric, transitive, and Euclidean, various classes of algebraic rough set models can be derived. They correspond to different modal logic systems. With respect to graded and probabilistic modal logics, graded and probabilistic rough set models are also discussed.},
	number = {2},
	urldate = {2023-02-09},
	journal = {Intelligent Automation \& Soft Computing},
	author = {Yao, Y.Y. and Lin, T.Y.},
	month = jan,
	year = {1996},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10798587.1996.10750660},
	keywords = {graded rough sets, modal logic, probabilistic rough sets, rough set operators, rough sets},
	pages = {103--119},
}

@article{michalski_aq_1991,
	title = {The {AQ} {Family} of {Learning} {Programs}: {A} {Review} of {Recent} {Developments} and an {Exemplary} {Application}},
	shorttitle = {The {AQ} {Family} of {Learning} {Programs}},
	url = {http://mars.gmu.edu/handle/1920/1686},
	language = {en\_US},
	urldate = {2023-02-09},
	author = {Michalski, Ryszard S. and Kaufman, Kenneth A. and Wnek, Janusz},
	month = dec,
	year = {1991},
	note = {Accepted: 2006-11-14T22:52:01Z},
}

@inproceedings{owuor_mining_2019,
	title = {Mining {Fuzzy}-{Temporal} {Gradual} {Patterns}},
	doi = {10.1109/FUZZ-IEEE.2019.8858883},
	abstract = {Gradual patterns allow for retrieval of the correlations between attributes through rules such as "the more exercise, the less stress". However, it is possible that a temporal lag may exist between changes in some attributes and their impact on others, current methods do not take this into account. In this paper, we extend GRAANK approach using fuzzy temporal constraints to handle these situations and retrieve patterns such as: "the more exercise, the less stress almost 1 month later". For this kind of patterns, we designed three algorithms that were implemented and tested on real data.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	author = {Owuor, Dickson and Laurent, Anne and Orero, Joseph},
	month = jun,
	year = {2019},
	note = {ISSN: 1558-4739},
	keywords = {Correlation, Data mining, Databases, Legged locomotion, Market research, Stress, Time factors, fuzzy time lags, temporal tendencies},
	pages = {1--6},
}

@article{moudani_optimistic_nodate,
	title = {Optimistic {Rough} {Sets} {Attribute} {Reduction} using {Dynamic} {Programming}},
	volume = {1},
	abstract = {Nowadays, and with the current progress in technologies and business sales, databases with large amount of data exist especially in Retail Companies. The main objective of this study is to reduce the complexity of the classification problems while maintaining the prediction classification quality. We propose to apply the promising technique Rough set theory which is a new mathematical approach to data analysis based on classification of objects of interest into similarity classes, which are indiscernible with respect to some features. Since some features are of high interest, this leads to the fundamental concept of “Attribute Reduction”. The goal of Rough set is to enumerate good attribute subsets that have high dependence, discriminating index and significance. The naïve way of is to generate all possible subsets of attribute but in high dimension cases, this approach is very inefficient while it will require 2d 1 iterations. Therefore, we propose the Dynamic programming technique in order to enumerate dynamically the optimal subsets of the reduced attributes of high interest by reducing the degree of complexity. Implementation has been developed, applied, and tested over a 3 years historical business data in Retail Business (RB). Simulations and visual analysis are shown and discussed in order to validate the accuracy of the proposed tool.},
	language = {en},
	number = {2},
	journal = {Engineering Technology},
	author = {Moudani, Walid and Shahin, Ahmad and Chakik, Fadi and Mora-Camino, Felix},
}

@article{abbas_skin_2012,
	title = {Skin tumor area extraction using an improved dynamic programming approach},
	volume = {18},
	issn = {1600-0846},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0846.2011.00544.x},
	doi = {10.1111/j.1600-0846.2011.00544.x},
	abstract = {Background/purpose: Border (B) description of melanoma and other pigmented skin lesions is one of the most important tasks for the clinical diagnosis of dermoscopy images using the ABCD rule. For an accurate description of the border, there must be an effective skin tumor area extraction (STAE) method. However, this task is complicated due to uneven illumination, artifacts present in the lesions and smooth areas or fuzzy borders of the desired regions. Methods: In this paper, a novel STAE algorithm based on improved dynamic programming (IDP) is presented. The STAE technique consists of the following four steps: color space transform, pre-processing, rough tumor area detection and refinement of the segmented area. The procedure is performed in the CIE L*a*b* color space, which is approximately uniform and is therefore related to dermatologist's perception. After pre-processing the skin lesions to reduce artifacts, the DP algorithm is improved by introducing a local cost function, which is based on color and texture weights. Results: The STAE method is tested on a total of 100 dermoscopic images. In order to compare the performance of STAE with other state-of-the-art algorithms, various statistical measures based on dermatologist-drawn borders are utilized as a ground truth. The proposed method outperforms the others with a sensitivity of 96.64\%, a specificity of 98.14\% and an error probability of 5.23\%. Conclusion: The results demonstrate that this STAE method by IDP is an effective solution when compared with other state-of-the-art segmentation techniques. The proposed method can accurately extract tumor borders in dermoscopy images.},
	language = {en},
	number = {2},
	urldate = {2023-02-08},
	journal = {Skin Research and Technology},
	author = {Abbas, Qaisar and Celebi, M. E. and García, Irene Fondón},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1600-0846.2011.00544.x},
	keywords = {artifact removal, borer detection, computer-aided diagnosis, dermoscopy, dynamic programming, skin cancer},
	pages = {133--142},
}

@article{ayub_linear_2022,
	title = {Linear {Diophantine} {Fuzzy} {Rough} {Sets}: {A} {New} {Rough} {Set} {Approach} with {Decision} {Making}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-8994},
	shorttitle = {Linear {Diophantine} {Fuzzy} {Rough} {Sets}},
	url = {https://www.mdpi.com/2073-8994/14/3/525},
	doi = {10.3390/sym14030525},
	abstract = {In this article, a new hybrid model named linear Diophantine fuzzy rough set (LDFRS) is proposed to magnify the notion of rough set (RS) and linear Diophantine fuzzy set (LDFS). Concerning the proposed model of LDFRS, it is more efficient to discuss the fuzziness and roughness in terms of linear Diophantine fuzzy approximation spaces (LDFA spaces); it plays a vital role in information analysis, data analysis, and computational intelligence. The concept of ({\textless}p,p′{\textgreater},{\textless}q,q′{\textgreater})-indiscernibility of a linear Diophantine fuzzy relation (LDF relation) is used for the construction of an LDFRS. Certain properties of LDFA spaces are explored and related results are developed. Moreover, a decision-making technique is developed for modeling uncertainties in decision-making (DM) problems and a practical application of fuzziness and roughness of the proposed model is established for medical diagnosis.},
	language = {en},
	number = {3},
	urldate = {2023-02-08},
	journal = {Symmetry},
	author = {Ayub, Saba and Shabir, Muhammad and Riaz, Muhammad and Mahmood, Waqas and Bozanic, Darko and Marinkovic, Dragan},
	month = mar,
	year = {2022},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {level cut relations of linear Diophantine fuzzy relations, linear Diophantine fuzzy relations, linear Diophantine fuzzy sets, rough approximations, symmetry of optimal decision},
	pages = {525},
}

@article{ji_fuzzy_2021,
	title = {Fuzzy rough sets and fuzzy rough neural networks for feature selection: {A} review},
	volume = {11},
	issn = {1942-4795},
	shorttitle = {Fuzzy rough sets and fuzzy rough neural networks for feature selection},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1402},
	doi = {10.1002/widm.1402},
	abstract = {Feature selection aims to select a feature subset from an original feature set based on a certain evaluation criterion. Since feature selection can achieve efficient feature reduction, it has become a key method for data preprocessing in many data mining tasks. Recently, many feature selection strategies have been developed since in most cases it is infeasible to obtain an optimal/reduced feature subset by using exhaustive search. Among these strategies, fuzzy rough set theory has proved to be an ideal candidate for dealing with uncertain information. This article provides a comprehensive review on the fuzzy rough set theory and two fuzzy rough set theory based feature selection methods, that is, fuzzy rough set based feature selection methods and fuzzy rough neural network based feature selection methods. We review the publications related to the fuzzy rough theory and its applications in feature selection. In addition, the challenges in the two types of feature selection methods are also discussed. This article is categorized under: Technologies {\textgreater} Machine Learning},
	language = {en},
	number = {3},
	urldate = {2023-02-08},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Ji, Wanting and Pang, Yan and Jia, Xiaoyun and Wang, Zhongwei and Hou, Feng and Song, Baoyan and Liu, Mingzhe and Wang, Ruili},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1402},
	keywords = {fuzzy rough neural network, fuzzy rough set theory, fuzzy set theory, rough set theory},
	pages = {e1402},
}

@article{kumar_fuzzy_2015,
	title = {Fuzzy {Rough} {Sets} and {Its} {Application} in {Data} {Mining} {Field}},
	volume = {2},
	abstract = {Rough set theory is a new method that deals with vagueness and uncertainty emphasized in decision making. The theory provides a practical approach for extraction of valid rules fromdata.This paper discusses about rough sets and fuzzy rough sets with its applications in data mining that can handle uncertain and vague data so as to reach at meaningful conclusions.},
	language = {en},
	number = {3},
	journal = {Advances in Computer Science and Information Technology},
	author = {Kumar, Megha and Yadav, Nidhika},
	year = {2015},
}

@incollection{pedrycz_fuzzy_2008,
	address = {Chichester, UK},
	title = {Fuzzy {Rough} {Sets}: {From} {Theory} into {Practice}},
	isbn = {978-0-470-72416-3 978-0-470-03554-2},
	shorttitle = {Fuzzy {Rough} {Sets}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9780470724163.ch24},
	abstract = {Fuzzy sets and rough sets address two important, and mutually orthogonal, characteristics of imperfect data and knowledge: while the former allow that objects belong to a set or relation to a given degree, the latter provide approximations of concepts in the presence of incomplete information. In this chapter, we demonstrate how these notions can be combined into a hybrid theory that is able to capture the best of diﬀerent worlds. In particular, we review various alternatives for deﬁning lower and upper approximations of a fuzzy set under a fuzzy relation, and also explore their application in query reﬁnement.},
	language = {en},
	urldate = {2023-02-08},
	booktitle = {Handbook of {Granular} {Computing}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Cornelis, Chris and De Cock, Martine and Radzikowska, Anna Maria},
	editor = {Pedrycz, Witold and Skowron, Andrzej and Kreinovich, Vladik},
	month = jul,
	year = {2008},
	doi = {10.1002/9780470724163.ch24},
	pages = {533--552},
}

@article{dubois_rough_1990,
	title = {Rough {Fuzzy} {Sets} and {Fuzzy} {Rough} {Sets}*},
	volume = {17},
	issn = {0308-1079},
	url = {https://doi.org/10.1080/03081079008935107},
	doi = {10.1080/03081079008935107},
	abstract = {The notion of a rough set introduced by Pawlak has often been compared to that of a fuzzy set, sometimes with a view to prove that one is more general, or, more useful than the other. In this paper we argue that both notions aim to different purposes. Seen this way, it is more natural to try to combine the two models of uncertainty (vagueness and coarseness) rather than to have them compete on the same problems. First, one may think of deriving the upper and lower approximations of a fuzzy set, when a reference scale is coarsened by means of an equivalence relation. We then come close to Caianiello's C-calculus. Shafer's concept of coarsened belief functions also belongs to the same line of thought. Another idea is to turn the equivalence relation into a fuzzy similarity relation, for the modeling of coarseness, as already proposed by Farinas del Cerro and Prade. Instead of using a similarity relation, we can start with fuzzy granules which make a fuzzy partition of the reference scale. The main contribution of the paper is to clarify the difference between fuzzy sets and rough sets, and unify several independent works which deal with similar ideas in different settings or notations.},
	number = {2-3},
	urldate = {2023-02-08},
	journal = {International Journal of General Systems},
	author = {DUBOIS, DIDIER and PRADE, HENRI},
	month = jun,
	year = {1990},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03081079008935107},
	keywords = {C-calculus, Fuzzy sets, belief functions, random sets, rough sets, similarity relations},
	pages = {191--209},
}

@article{bellman_decision-making_nodate,
	title = {{DECISION}-{MAKING} {I} {N} {A} {FUZZY} {ENVIRONMENT}},
	language = {en},
	author = {Bellman, R E and Zudeh, L A},
}

@article{xie_embedded_2022,
	title = {An embedded deep fuzzy association model for learning and explanation},
	volume = {131},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494622007876},
	doi = {10.1016/j.asoc.2022.109738},
	abstract = {This paper explores the complementary benefits of embedding a deep learning model as a fully data-driven fuzzy implication operator of a five-layer neuro-fuzzy system for learning and explanations for the predictions of both steady-state and dynamically changing data. In traditional Mandani-type neuro-fuzzy systems, the entailment performed by the implication is realized using the fuzzy implication operator based on the fuzzy rules formed in the rule base during encoding and recall. Given the presence of a group of test data that are significantly different from the training data, the realization of entailments through the use of the implication operator based on the fuzzy rules formed in traditional neuro-fuzzy systems may not be adequate. This paper attempts to adopt a more direct approach by embedding a deep learning model in the neuro-fuzzy system to serve as a fuzzy implication operator, thereby allowing the data-driven learning of fuzzy implication using the deep structure to provide a close correspondence to the real-world entailment of data. In addition, embedding the neuro-fuzzy architecture within the deep learning model allows the comprehension of the learning and explanation of the reasoning of the deep network. The induced fuzzy association rules impart transparency to the deep learning based implication using a common set of semantic meanings, which are amenable to human interpretability. The effectiveness of the proposed model is evaluated on a continuously stirred tank reactor dataset and three financial stock prediction datasets. Experimental results showed that the proposed model outperformed other state-of-the-art techniques based on the four datasets, which contain high levels of uncertainties.},
	language = {en},
	urldate = {2023-02-01},
	journal = {Applied Soft Computing},
	author = {Xie, Chen and Rajan, Deepu and Prasad, Dilip K. and Quek, Chai},
	month = dec,
	year = {2022},
	keywords = {Data-driven learning of deep implication operation, Deep learning network, Embedded deep fuzzy neural network, Interpretable model, Neuro-fuzzy systems},
	pages = {109738},
}

@article{arulprakasam_rough_2018,
	title = {Rough {Finite} {State} {Automata} and {Rough} {Languages}},
	volume = {1000},
	doi = {10.1088/1742-6596/1000/1/012155},
	abstract = {Sumita Basu [1, 2] recently introduced the concept of a rough finite state (semi)automaton, rough grammar and rough languages. Motivated by the work of [1, 2], in this paper, we investigate some closure properties of rough regular languages and establish the equivalence between the classes of rough languages generated by rough grammar and the classes of rough regular languages accepted by rough finite automaton.},
	journal = {Journal of Physics: Conference Series},
	author = {Arulprakasam, R. and Perumal, Rajendran and Mohanraj, Radhakrishnan and Dare, V.},
	month = apr,
	year = {2018},
	pages = {012155},
}

@inproceedings{fiot_gradual_2008,
	title = {Gradual {Trends} in {Fuzzy} {Sequential} {Patterns}},
	url = {https://hal-lirmm.ccsd.cnrs.fr/lirmm-00273910},
	doi = {10/document},
	abstract = {Fuzzy sequential pattern mining is a relevant approach when dealing with temporally annotated numerical data since it allows discovering frequent sequences embedded in the records. However, such patterns, in their current form, do not allow extracting another kind of knowledge that is typical of sequential data: temporal tendencies. Thanks to a relevant use of fuzzy sequential patterns, we propose the GraSP algorithm that discovers gradual trends in sequences. Our proposal is validated through experiments on web access logs.},
	language = {en},
	urldate = {2023-01-25},
	author = {Fiot, Céline and Masseglia, Florent and Laurent, Anne and Teisseire, Maguelonne},
	month = jun,
	year = {2008},
	pages = {456},
}

@article{fiot_crispness_2007,
	title = {From {Crispness} to {Fuzziness}: {Three} {Algorithms} for {Soft} {Sequential} {Pattern} {Mining}},
	volume = {15},
	issn = {1063-6706, 1941-0034},
	shorttitle = {From {Crispness} to {Fuzziness}},
	url = {http://ieeexplore.ieee.org/document/4358797/},
	doi = {10.1109/TFUZZ.2007.894976},
	abstract = {Most real world databases consist of historical and numerical data such as sensor, scientiﬁc or even demographic data. In this context, classical algorithms extracting sequential patterns, which are well adapted to the temporal aspect of data, do not allow numerical information processing. Therefore the data are pre-processed to be transformed into a binary representation, which leads to a loss of information. Fuzzy algorithms have been proposed to process numerical data using intervals, particularly fuzzy intervals, but none of these methods is satisfactory. Therefore this paper completely deﬁnes the concepts linked to fuzzy sequential pattern mining. Using different fuzziﬁcation levels, we propose three methods to mine fuzzy sequential patterns and detail the resulting algorithms (SPEEDYFUZZY, MINIFUZZY and TOTALLYFUZZY). Finally, we assess them through different experiments, thus revealing the robustness and the relevancy of this work.},
	language = {en},
	number = {6},
	urldate = {2023-01-25},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Fiot, C. and Laurent, A. and Teisseire, M.},
	month = dec,
	year = {2007},
	pages = {1263--1277},
}

@article{hu_deriving_2004,
	title = {Deriving two-stage learning sequences from knowledge in fuzzy sequential pattern mining},
	volume = {159},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025503001907},
	doi = {10.1016/S0020-0255(03)00190-7},
	abstract = {A fuzzy sequential pattern consisting of several fuzzy sets represents a frequently occurring behavior related to time and can be discovered from transaction bases. An example is that large purchase amounts of one product were bought by customers after these consumers had bought small purchase amounts of another product. Recently, Hu et al. (2003) proposed a fuzzy data mining method to discover fuzzy sequential patterns. In this method, consumers’ products preferences and consumers’ product buying orders related to purchase behaviors can be found in the fuzzy sequential pattern mining. Since for each decision problem, there is a competence set consisting of ideas, knowledge, information, and skills for solving that problem, we consider knowledge found in fuzzy sequential pattern mining as a needed competence set for solving one decision problem. This paper uses a known competence set expansion method, the minimum spanning table method, to find appropriate two-stage learning sequences that can effectively acquire individual fuzzy knowledge sets found in the fuzzy sequential pattern mining. A numerical example is used to show the usefulness of the proposed method.},
	language = {en},
	number = {1},
	urldate = {2023-01-25},
	journal = {Information Sciences},
	author = {Hu, Yi-Chung and Tzeng, Gwo-Hshiung and Chen, Chin-Mi},
	month = jan,
	year = {2004},
	keywords = {Competence sets, Data mining, Fuzzy sets, Sequential patterns},
	pages = {69--86},
}

@inproceedings{hong_mining_2001,
	title = {Mining fuzzy sequential patterns from multiple-item transactions},
	volume = {3},
	doi = {10.1109/NAFIPS.2001.943738},
	abstract = {Transaction data in real-world applications usually consist of quantitative values, so designing a sophisticated data-mining algorithm that is able to deal with various types of data presents a challenge to workers in this research field. Since sequential patterns are also very important for real-world applications, this paper focuses on finding fuzzy sequential patterns from quantitative data. A new mining algorithm is proposed, which integrates the fuzzy-set concepts and the AprioriAll algorithm. It first transforms quantitative values in transactions into linguistic terms, then filters them to find sequential patterns by modifying the AprioriAll mining algorithm. Each quantitative item uses only the linguistic term with the maximum cardinality in later mining processes, thus making the number of fuzzy regions to be processed the same as the number of the original items. The patterns mined out thus exhibit the sequential quantitative regularity in databases and can be used to provide some Suggestions to appropriate supervisors.},
	booktitle = {Proceedings {Joint} 9th {IFSA} {World} {Congress} and 20th {NAFIPS} {International} {Conference} ({Cat}. {No}. {01TH8569})},
	author = {Hong, Tzung-Pei and Lin, Kuie-Ying and Wang, Shyue-Liang},
	month = jul,
	year = {2001},
	keywords = {Algorithm design and analysis, Association rules, Data mining, Filters, Fuzzy set theory, Fuzzy sets, Information management, Itemsets, Transaction databases},
	pages = {1317--1321 vol.3},
}

@inproceedings{zabihi_fuzzy_2010,
	title = {Fuzzy sequential pattern mining with sliding window constraint},
	volume = {5},
	doi = {10.1109/ICETC.2010.5530044},
	abstract = {Sequential pattern mining is to discover all subsequences that are frequent. The classical sequential pattern mining algorithms do not allow processing of numerical data and require preprocessing of these data into a binary representation, which necessarily leads to a loss of information. Fuzzy sets are used to overcome this problem. In present fuzzy sequential pattern mining algorithms, there isn't any matter of itemset time and sequences are only found based on sequence of happening. In this paper, a novel fuzzy sequential pattern algorithm is proposed with sliding window constraint which permits elements of a pattern to span a set of transactions within a user-specified window. Therefore, loss of useful sequences is prevented in the search process. The proposed algorithm searches for a goal sequence within the defined fuzzy sliding window and the membership degree of sliding window is returned if the goal sequence is found.},
	booktitle = {2010 2nd {International} {Conference} on {Education} {Technology} and {Computer}},
	author = {Zabihi, Fatemeh and Ramezan, Mojtaba and Pedram, Mir Mohsen and Memariani, Azizollah},
	month = jun,
	year = {2010},
	note = {ISSN: 2155-1812},
	keywords = {Computer science education, Data mining, Educational technology, Fuzzy sets, Industrial engineering, Itemsets, Lattices, Technology planning, Time factors, Transaction databases, constraint, fuzzy sequential pattern mining, sliding window},
	pages = {V5--396--V5--400},
}

@inproceedings{shakeri_fuzzy_2014,
	title = {A fuzzy constrained stream sequential pattern mining algorithm},
	doi = {10.1109/IS℡.2014.7000663},
	abstract = {Sequential pattern mining is an interesting data mining problem with many real-world applications. Though, new applications introduce a new form of data called data stream, no study has been reported on mining sequential patterns from quantitative data stream. This paper presents a novel algorithm, for mining quantitative streams. The proposed algorithm can mine exact set of fuzzy sequential patterns in fuzzy sliding window and gap constraints entailing the most recent transactions in a data stream. In addition, the proposed algorithm can also mine non-quantitative or transaction-based sequential patterns over a data stream. Numerical results show the running time and the memory usage of proposed algorithm in the case of quantitative and customer-transaction-based sequence counting are proportional to the size of the fuzzy sliding window and gap constraints.},
	booktitle = {7'th {International} {Symposium} on {Telecommunications} ({IST}'2014)},
	author = {Shakeri, Omid and Pedram, Mir Mohsen and Kelarestaghi, Manoochehr},
	month = sep,
	year = {2014},
	keywords = {Batch production systems, Conferences, Data mining, Face, Itemsets, Memory management, data stream, fuzzy constraint, fuzzy sequential pattern mining, sliding window},
	pages = {20--24},
}

@inproceedings{mendel_using_2005,
	title = {On using type-1 fuzzy set mathematics to derive interval type-2 fuzzy logic systems},
	doi = {10.1109/NAFIPS.2005.1548592},
	abstract = {In this paper, we demonstrate that it is unnecessary to take the route from general type-2 fuzzy set to interval type-2 fuzzy set, and that all of the results that are needed to implement an interval type-2 fuzzy logic system can be obtained using type-1 fuzzy set mathematics. As such, this paper makes an interval type-2 fuzzy logic system much more accessible to the fuzzy logic community, and we can now develop an interval type-2 fuzzy logic system in a much more straightforward way.},
	booktitle = {{NAFIPS} 2005 - 2005 {Annual} {Meeting} of the {North} {American} {Fuzzy} {Information} {Processing} {Society}},
	author = {Mendel, J.M. and John, R.I. and Liu, Feilong},
	month = jun,
	year = {2005},
	keywords = {Computational intelligence, Computer science, Frequency selective surfaces, Fuzzy logic, Fuzzy sets, Fuzzy systems, Image processing, Mathematics, Signal processing, Uncertainty},
	pages = {528--533},
}

@article{mendel_fuzzy_nodate,
	title = {Fuzzy {Sets} for {Words}: {Why} {Type}-2 {Fuzzy} {Sets} {Should} be {Used} and {How} {They} {Can} be {Used}},
	language = {en},
	author = {Mendel, Jerry M},
}

@article{mendel_type-2_2002,
	title = {Type-2 {Fuzzy} {Sets} {Made} {Simple}},
	volume = {10},
	doi = {10.1109/91.995115},
	abstract = {Type-2 fuzzy sets let us model and minimize the effects of
uncertainties in rule-base fuzzy logic systems. However, they are difficult to understand for a variety of reasons which we enunciate. In this paper, we strive to overcome the difficulties by: (1) establishing a small set of terms that let us easily communicate about type-2 fuzzy sets and also let us define such sets very precisely, (2) presenting a new representation for type-2 fuzzy sets, and (3) using this new
representation to derive formulas for union, intersection and complement of type-2 fuzzy sets without having to use the Extension Principle},
	journal = {Fuzzy Systems, IEEE Transactions on},
	author = {Mendel, Jerry and John, Robert},
	month = may,
	year = {2002},
	pages = {117--127},
}

@article{yu_op-knn_2010,
	title = {{OP}-{KNN}: {Method} and {Applications}},
	volume = {2010},
	issn = {1687-7594},
	shorttitle = {{OP}-{KNN}},
	url = {https://www.academia.edu/22435549/OP_KNN_Method_and_Applications},
	abstract = {OP-KNN: Method and Applications},
	language = {en},
	urldate = {2023-01-10},
	journal = {Advances in Artificial Neural Systems},
	author = {Yu, Qi and Miche, Yoan and Sorjamaa, Antti and Guillen, Alberto and Lendasse, Amaury and Séverin, Eric},
	year = {2010},
	pages = {1},
}

@article{nguyen_recurrent_2018,
	title = {Recurrent {Mechanism} and {Impulse} {Noise} {Filter} for {Establishing} {ANFIS}},
	volume = {26},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2017.2701313},
	abstract = {In many real applications, building and updating adaptive neuro-fuzzy inference system (ANFIS) based on noisy measuring data sources need to be performed such that the filtering impulse noise (IN) from the initial datasets (IDSs) and establishing the ANFIS via the filtered IDS are carried out simultaneously. Focused on this purpose, in this paper, a novel recurrent mechanism as well as a solution for filtering IN based on Lyapunov stability theory is proposed to establish an adaptive online IN filter (AOINF). Using the AOINF, kernel fuzzy-C-means clustering method, and the least mean squares method, a cluster data space deriving from the filtered IDS is created to which the ANFIS is then formed. The recurrent mechanism executes filtering IN to build ANFIS and using the ANFIS as an updated-filter to filter IN synchronously until either the ANFIS converges to the desired accuracy or a stop condition is satisfied. Surveys, including identifying dynamic response of a magnetorheological damper via measuring datasets, are performed to evaluate the proposed method.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Nguyen, Sy Dzung and Choi, Seung-Bok and Seo, Tae-Il},
	month = apr,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {ANFIS, Databases, Filtering algorithms, Filtering theory, Fuzzy C-means (FCM) clustering, Kernel, Noise measurement, data-driven model, filtering impulse noise (IN), kernel fuzzy C-means clustering, neuro-fuzzy system},
	pages = {985--997},
}

@article{halgamuge_trainable_1998,
	title = {A trainable transparent universal approximator for defuzzification in {Mamdani}-type neuro-fuzzy controllers},
	volume = {6},
	issn = {1941-0034},
	doi = {10.1109/91.669031},
	abstract = {A novel technique of designing application specific defuzzification strategies with neural learning is presented. The proposed neural architecture considered as a universal defuzzification approximator is validated by showing the convergence when approximating several existing defuzzification strategies. The method is successfully tested with fuzzy controlled reverse driving of a model truck. The transparent structure of the universal defuzzification approximator allows us to analyze the generated customized defuzzification method using the existing theories of defuzzification. The integration of universal defuzzification approximator instead of traditional methods in Mamdani-type fuzzy controllers can also be considered as an addition of trainable nonlinear noise to the output of the fuzzy rule inference before calculating the defuzzified crisp output. Therefore, nonlinear noise trained specifically for a given application shows a grade of confidence on the rule base, providing an additional opportunity to measure the quality of the fuzzy rule base. The possibility of modeling a Mamdani-type fuzzy controller as a feedforward neural network with the ability of gradient descent training of the universal defuzzification approximator and antecedent membership functions fulfil the requirement known from multilayer preceptrons in finding solutions to nonlinear separable problems.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Halgamuge, S.K.},
	month = may,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Convergence, Function approximation, Fuzzy control, Fuzzy neural network, Fuzzy system, Multi-layer neural network, Neural network},
	pages = {304--314},
}

@article{li_self-organizing_2003,
	title = {Self-organizing neuro-fuzzy system for control of unknown plants},
	volume = {11},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2002.805898},
	abstract = {A cluster-based self-organizing neuro-fuzzy system (SO-NFS) is proposed for control of unknown plants. The neuro-fuzzy system can learn its knowledge base from input-output training data. A plant model is not required for training, that is, the plant is unknown to the SO-NFS. Using new data types, the vectors and matrices, a construction theory is developed for the organization process and the inference activities of the cluster-based SO-NFS. With the construction theory, a compact equation for describing the relation between the input base variables and inference results is established. This equation not only gives the inference relation between inputs and outputs but also specifies the linguistic meanings in the process. New pseudo-error learning control is proposed for closed-loop control applications. Using a cluster-based algorithm, the neuro-fuzzy system in its genesis can be generated by the stimulation of input/output training data to have its initial control policy (IF-THEN rules) for application. With the well-known random optimization method, the generated neuro-fuzzy system can learn its data base for specific applications. The proposed approach can be applied on control of unknown plants, and can levitate the curse of dimensionality in traditional fuzzy systems. Two examples are demonstrated.},
	number = {1},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Li, Chunshien and Lee, Chun-Yi},
	month = feb,
	year = {2003},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Backpropagation, Clustering, Fuzzy neural network, Fuzzy system, Neural network, Neuro-fuzzy network, Partitioning algorithms},
	pages = {135--150},
}

@inproceedings{lin_real-time_1992,
	title = {Real-time supervised structure/parameter learning for fuzzy neural network},
	doi = {10.1109/FUZZY.1992.258596},
	abstract = {The authors propose a real-time supervised structure and parameter learning algorithm for constructing fuzzy neural networks (FNNs) automatically and dynamically. This algorithm combines the backpropagation learning scheme for the parameter learning and a novel fuzzy similarity measure for the structure learning. The fuzzy similarity measure is a new tool to determine the degree to which two fuzzy sets are equal. The FNN is a feedforward multilayered network which integrates the basic elements and functions of a traditional fuzzy logic controller into a connectionist structure which has distributed learning abilities. The structure learning decides the proper connection types and the number of hidden units which represent fuzzy logic rules and the number of fuzzy partitions. The parameter learning adjusts the node and link parameters which represent the membership functions. The proposed supervised learning algorithm provides an efficient way of constructing a FNN in real time. Simulation results are presented to illustrate the performance and applicability of the proposed learning algorithm.{\textless}{\textgreater}},
	booktitle = {[1992 {Proceedings}] {IEEE} {International} {Conference} on {Fuzzy} {Systems}},
	author = {Lin, C.T. and Lee, C.S.G.},
	month = mar,
	year = {1992},
	keywords = {Backpropagation, Fuzzy control, Fuzzy logic, Fuzzy neural network, Fuzzy similarity measure, Heuristic algorithm, Partitioning algorithm, Supervised learning},
	pages = {1283--1291},
}

@inproceedings{zhao_neuro-fuzzy_2006,
	title = {Neuro-{Fuzzy} {Decision} {Tree} by {Fuzzy} {ID3} {Algorithm} and {Its} {Application} to {Anti}-{Dumping} {Early}-{Warning} {System}},
	doi = {10.1109/ICIA.2006.305939},
	abstract = {Fuzzy decision trees (FDT) are one of the most popular choices for learning and reasoning from dataset. They have undergone a number of alterations to language and measurement uncertainties. However, they are poor in classification accuracy. In this paper, we proposed neuro-fuzzy decision tree. Neuro-fuzzy decision tree (a fuzzy decision tree structure with neural like parameter adaptation strategy) improves FDT's classification accuracy and extracts more accuracy human interpretable classification rules. In the forward cycle, we construct fuzzy decision trees using fuzzy ID3. In the feedback cycle, parameters of fuzzy decision trees have been adapted using stochastic gradient descent algorithm by traversing back from leaf to root nodes. In this paper, we proposed a new anti-dumping early-warning system. The early-warning system based on neuro-fuzzy decision tree modeling method is different from traditional modeling methods. The other new attempt is the setting of early-warning intervals. The result of the positive research indicated that this system is very valid for anti-dumping prediction and it will have a good application prospect in this area},
	booktitle = {2006 {IEEE} {International} {Conference} on {Information} {Acquisition}},
	author = {Zhao, Jianna and Chang, Zhipeng},
	month = aug,
	year = {2006},
	keywords = {Anti-Dumping, Backpropagation, Classification tree analysis, Decision trees, Early-warning, Fuzzy ID3, Fuzzy sets, Fuzzy system, Neuro-fuzzy decision tree, Neurofeedback, Stochastic processes},
	pages = {1300--1304},
}

@article{kacprzyk_linguistic_2001,
	title = {Linguistic {Summaries} of {Data} {Using} {Fuzzy} {Logic}},
	volume = {30},
	issn = {0308-1079},
	url = {https://doi.org/10.1080/03081070108960702},
	doi = {10.1080/03081070108960702},
	abstract = {We present basic ideas and perspectives related to the use of fuzzy logic for the derivation of linguistic summaries of data sets (databases in practice). We concentrate on the issue of how to measure the goodness of a linguistic summary. We advocate the use of an interactive approach in which the user indicates first the class of linguistic summaries of interest (basically, by specifying attributes relation between which he or she is interested in) by using a fuzzy querying interface to a database. Finally, we present an implementation for deriving linguistic summaries of a sales database at a computer retailer, and show how the linguistic summaries obtained can be useful for supporting decisions by the business owner.},
	number = {2},
	urldate = {2023-01-04},
	journal = {International Journal of General Systems},
	author = {KACPRZYK, JANUSZ and YAGER, RONALD R.},
	month = jan,
	year = {2001},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03081070108960702},
	keywords = {Fuzzy logic, Fuzzy query, Linguistic summarization},
	pages = {133--154},
}

@article{lin_reinforcement_1994,
	title = {Reinforcement structure/parameter learning for neural-network-based fuzzy logic control systems},
	volume = {2},
	issn = {1941-0034},
	doi = {10.1109/91.273126},
	abstract = {This paper proposes a reinforcement neural-network-based fuzzy logic control system (RNN-FLCS) for solving various reinforcement learning problems. The proposed RNN-FLCS is constructed by integrating two neural-network-based fuzzy logic controllers (NN-FLC's), each of which is a connectionist model with a feedforward multilayered network developed for the realization of a fuzzy logic controller. One NN-FLC performs as a fuzzy predictor, and the other as a fuzzy controller. Using the temporal difference prediction method, the fuzzy predictor can predict the external reinforcement signal and provide a more informative internal reinforcement signal to the fuzzy controller. The fuzzy controller performs a stochastic exploratory algorithm to adapt itself according to the internal reinforcement signal. During the learning process, both structure learning and parameter learning are performed simultaneously in the two NN-FLC's using the fuzzy similarity measure. The proposed RNN-FLCS can construct a fuzzy logic control and decision-making system automatically and dynamically through a reward/penalty signal or through very simple fuzzy information feedback such as "high," "too high," "low," and "too low." The proposed RNN-FLCS is best applied to the learning environment, where obtaining exact training data is expensive. It also preserves the advantages of the original NN-FLC, such as the ability to find proper network structure and parameters simultaneously and dynamically and to avoid the rule-matching time of the inference engine. Computer simulations were conducted to illustrate its performance and applicability.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Lin, Chin-Teng and Lee, C.S.G.},
	month = feb,
	year = {1994},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Automatic control, Decision making, Fuzzy control, Fuzzy logic, Fuzzy system, Parameter estimation, Stochastic processes, Structure estimation},
	pages = {46--63},
}

@article{zeng_approximation_1995,
	title = {Approximation theory of fuzzy systems-{MIMO} case},
	volume = {3},
	issn = {1941-0034},
	doi = {10.1109/91.388175},
	abstract = {In this paper, the approximation properties of MIMO fuzzy systems generated by the product inference are discussed. We first give an analysis of fuzzy basic functions (FBF's) and present several properties of FBF's. Based on these properties of FBF's, we obtain several basic approximation properties of fuzzy systems: 1) basic approximation property which reveals the basic approximation mechanism of fuzzy systems; 2) uniform approximation bounds which give the uniform approximation bounds between the desired (control or decision) functions and fuzzy systems; 3) uniform convergent property which shows that fuzzy systems with defined approximation accuracy can always be obtained by dividing the input space into finer fuzzy regions; and 4) universal approximation property which shows that fuzzy systems are universal approximators and extends some previous results on this aspect. The similarity between fuzzy systems and mathematical approximation is discussed and an idea to improve approximation accuracy is suggested based on uniform approximation bounds.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Zeng, Xiao-Jun and Singh, M.G.},
	month = may,
	year = {1995},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Approximation methods, Computer aided software engineering, Fuzzy control, Fuzzy systems, MIMO, Mechanical factors, Shape, Universal approximation},
	pages = {219--235},
}

@incollection{garcia-gutierrez_cuckoo_2021,
	address = {Singapore},
	series = {Springer {Tracts} in {Nature}-{Inspired} {Computing}},
	title = {The {Cuckoo} {Search} {Algorithm} {Applied} to {Fuzzy} {Logic} {Control} {Parameter} {Optimization}},
	isbn = {9789811551635},
	url = {https://doi.org/10.1007/978-981-15-5163-5_8},
	abstract = {In the design of control systems, the tuning of controller parameters has a fundamental role in the performance of both transient and steady-state regimes. From this perspective, the tuning of controller parameters has been carried out using perturbation and observation methods, computational tools based on optimization algorithms for low-complexity systems, and more recently, using metaheuristic algorithms for highly complex systems with improved tuning procedures that guarantee the operation and stability of the systems. Thus, avant-garde optimization algorithms that mimic the evolution of self-organizing biological systems, also called metaheuristic nature-inspired algorithms, have gained high relevance due to their great potential for solving optimization problems. Hence, the Cuckoo Search (CS) algorithm, a very promising and nearly recent developed nature-inspired algorithm, has been used in the design and optimization of Fuzzy Logic Control (FLC) systems due to its great potentiality. In particular, this chapter studies the application of the CS algorithm for tuning controller parameters in two different case studies. The first one is associated with the FLC parameter tuning of a nonlinear magnetic levitation system, and the second case study is related to the FLC optimization of the energy management system of a residential microgrid. Simulation results are provided to emphasize and analyze the features of the optimized controllers for the two cases and compared against other more conventional techniques. Obtained outcomes show that the adjustment of FLC parameters, performed through the CS algorithm, is efficient and improves the performance of the two FLC, which makes the CS algorithm becomes a powerful alternative for performing the controller parameter tuning in modern control systems.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Applications of {Cuckoo} {Search} {Algorithm} and its {Variants}},
	publisher = {Springer},
	author = {García-Gutiérrez, G. and Arcos-Aviles, D. and Carrera, E. V. and Guinjoan, F. and Ibarra, A. and Ayala, P.},
	editor = {Dey, Nilanjan},
	year = {2021},
	doi = {10.1007/978-981-15-5163-5_8},
	keywords = {Cuckoo search algorithm, Energy management system, Fuzzy control, Nature-inspired algorithms, Parameter optimization},
	pages = {175--206},
}

@article{chen_self-organizing_1993,
	title = {Self-organizing fuzzy logic controller design},
	volume = {22},
	issn = {0166-3615},
	url = {https://www.sciencedirect.com/science/article/pii/016636159390092F},
	doi = {10.1016/0166-3615(93)90092-F},
	abstract = {The fuzzy logic controller based on the fuzzy set theory provides a useful tool for converting the linguistic control strategy from the expert knowledge into automatic control rules. However, proper control rules cannot always be obtained easily for a complex plant. The self-organizing fuzzy logic controller is a heuristic controller where control rules are generated and improved automatically. Its basic functions are: (1) to generate appropriate control action according to the evaluation of the system's behaviour; and (2) to modify the control action based on system performance evaluation. In this paper, the behaviour of the system with respect to the performance index is investigated. A systematic method to modify the performance index table such that the required system time response is achieved is proposed. A ball and beam apparatus has been used to illustrate the effectiveness of the proposed control structure.},
	language = {en},
	number = {3},
	urldate = {2023-01-03},
	journal = {Computers in Industry},
	author = {Chen, Chieh-Li and Chen, Yaw-Min},
	month = oct,
	year = {1993},
	keywords = {Fuzzy control, Self-organizing},
	pages = {249--261},
}

@article{filev_analysis_1994,
	title = {On the analysis of fuzzy logic controllers},
	volume = {68},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/0165011494902720},
	doi = {10.1016/0165-0114(94)90272-0},
	abstract = {In this paper we address the issue of analyzing the properties of the fuzzy logic controller (FLC). We introduce two basic models of the FLC. The first representation uses the concept of the quasilinear fuzzy model — the FLC is approximated by a virtual PID controller, consisting of linear controller connected in parallel. The second interpretation of the FLC is from the point of view of nonlinear control — the FLC is analyzed as a sliding mode — like controller. Based on these two alternative representations are derived rules for designing and tuning fuzzy logic controllers.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Filev, Dimitar P. and Yager, Ronald R.},
	month = nov,
	year = {1994},
	keywords = {Fuzzy control, Fuzzy logic, Fuzzy modeling, Tuning},
	pages = {39--66},
}

@article{buckley_neural_1995,
	series = {Fuzzy {Neural} {Control}},
	title = {Neural nets for fuzzy systems},
	volume = {71},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/016501149400282C},
	doi = {10.1016/0165-0114(94)00282-C},
	abstract = {We show how to represent fuzzy expert systems and fuzzy controllers as neural nets and as fuzzy neural nets. We show that fuzzy neural nets produce a more compact representation of fuzzy systems.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Buckley, James J. and Yoichi, Hayashi},
	month = may,
	year = {1995},
	keywords = {Expert systems, Neural network},
	pages = {265--276},
}

@article{lin_neural-network-based_1991,
	title = {Neural-network-based fuzzy logic control and decision system},
	volume = {40},
	issn = {1557-9956},
	doi = {10.1109/12.106218},
	abstract = {A general neural-network (connectionist) model for fuzzy logic control and decision systems is proposed. This connectionist model, in the form of feedforward multilayer net, combines the idea of fuzzy logic controller and neural-network structure and learning abilities into an integrated neural-network-based fuzzy logic control and decision system. A fuzzy logic control decision network is constructed automatically by learning the training examples itself. By combining both unsupervised (self-organized) and supervised learning schemes, the learning speed converges much faster than the original backpropagation learning algorithm. The connectionist structure avoids the rule-matching time of the inference engine in the traditional fuzzy logic system. Two examples are presented to illustrate the performance and applicability of the proposed model.{\textless}{\textgreater}},
	number = {12},
	journal = {IEEE Transactions on Computers},
	author = {Lin, C.-T. and Lee, C.S.G.},
	month = dec,
	year = {1991},
	note = {Conference Name: IEEE Transactions on Computers},
	keywords = {Fuzzy control, Fuzzy logic, Multi-layer neural network, Neural networks, Nonlinear control, Robot control, Supervised learning},
	pages = {1320--1336},
}

@article{wang_generating_1992,
	title = {Generating fuzzy rules by learning from examples},
	volume = {22},
	issn = {2168-2909},
	doi = {10.1109/21.199466},
	abstract = {A general method is developed to generate fuzzy rules from numerical data. The method consists of five steps: divide the input and output spaces of the given numerical data into fuzzy regions; generate fuzzy rules from the given data; assign a degree of each of the generated rules for the purpose of resolving conflicts among the generated rules; create a combined fuzzy rule base based on both the generated rules and linguistic rules of human experts; and determine a mapping from input space to output space based on the combined fuzzy rule base using a defuzzifying procedure. The mapping is proved to be capable of approximating any real continuous function on a compact set to arbitrary accuracy. Applications to truck backer-upper control and time series prediction problems are presented.{\textless}{\textgreater}},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Wang, L.-X. and Mendel, J.M.},
	month = nov,
	year = {1992},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {Fuzzy control, Image processing, Mathematical model, Neural networks, Nonlinear control, Wang-Mendel method},
	pages = {1414--1427},
}

@article{jang_anfis_1993,
	title = {{ANFIS}: adaptive-network-based fuzzy inference system},
	volume = {23},
	issn = {2168-2909},
	shorttitle = {{ANFIS}},
	doi = {10.1109/21.256541},
	abstract = {The architecture and learning procedure underlying ANFIS (adaptive-network-based fuzzy inference system) is presented, which is a fuzzy inference system implemented in the framework of adaptive networks. By using a hybrid learning procedure, the proposed ANFIS can construct an input-output mapping based on both human knowledge (in the form of fuzzy if-then rules) and stipulated input-output data pairs. In the simulation, the ANFIS architecture is employed to model nonlinear functions, identify nonlinear components on-line in a control system, and predict a chaotic time series, all yielding remarkable results. Comparisons with artificial neural networks and earlier work on fuzzy modeling are listed and discussed. Other extensions of the proposed ANFIS and promising applications to automatic control and signal processing are also suggested.{\textless}{\textgreater}},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Jang, J.-S.R.},
	month = may,
	year = {1993},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {Adaptive systems, Artificial neural network, Chaos, Control system synthesis, Fuzzy neural network, Fuzzy system, Neuro-fuzzy network, Nonlinear control},
	pages = {665--685},
}

@inproceedings{shi_learning_1999,
	title = {A learning algorithm for tuning fuzzy inference rules},
	volume = {1},
	doi = {10.1109/FUZZY.1999.793269},
	abstract = {In this paper, by using the gradient descent method we propose a tuning approach to obtain optimal fuzzy inference rules in which the membership functions are nonsymmetrical triangular-type membership functions. In the tuning approach, the representation of the fuzzy rule table does not change even after the learning which shows that it is intuitive and convenient for practical fuzzy applications. Moreover the efficiency of the presented method is also demonstrated by means of identifying nonlinear systems.},
	booktitle = {{FUZZ}-{IEEE}'99. 1999 {IEEE} {International} {Fuzzy} {Systems}. {Conference} {Proceedings} ({Cat}. {No}.{99CH36315})},
	author = {Shi, Y. and Mizumoto, M.},
	month = aug,
	year = {1999},
	note = {ISSN: 1098-7584},
	keywords = {Fuzzy reasoning, Inference algorithms, Nonlinear control},
	pages = {378--382 vol.1},
}

@inproceedings{marquez_efficient_2012,
	title = {An efficient multi-objective evolutionary adaptive conjunction for high dimensional problems in linguistic fuzzy modelling},
	doi = {10.1109/FUZZ-IEEE.2012.6251181},
	abstract = {Adaptive connectors as conjunction operators of the inference system is one of the methodologies to improve the accuracy of fuzzy rule based systems by means of local adaptation of the inference process to each rule of the rule base. They are usually implemented through the classic adaptive t-norms, but when dealing with high-dimensional problems (several variables and/or instances) the adaptation of their parameters becomes problematic. In this paper, we propose a new adaptive conjunction connector and an associated multi-objective evolutionary learning algorithm which is more efficient and thus suitable for using adaptive connectors in high dimensional problems. The proposal is compared in an experimental study with the use of a well known efficient adaptive t-norm from the literature as conjunction operator. The results obtained on five regression problems confirm the effectiveness of the presented proposal in terms of efficiency, but also in terms of simplicity and compactness of the obtained models.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Fuzzy} {Systems}},
	author = {Márquez, Antonio A. and Márquez, Francisco A. and Peregrín, Antonio},
	month = jun,
	year = {2012},
	note = {ISSN: 1098-7584},
	keywords = {Accuracy, Adaptive, Complexity theory, Computational modeling, Genetic algorithm, High-dimensional, Linguistic fuzzy modelling, Multi-objective, Pragmatics, Regression},
	pages = {1--8},
}

@article{cordon_ten_2004,
	series = {Genetic {Fuzzy} {Systems}: {New} {Developments}},
	title = {Ten years of genetic fuzzy systems: current framework and new trends},
	volume = {141},
	issn = {0165-0114},
	shorttitle = {Ten years of genetic fuzzy systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011403001118},
	doi = {10.1016/S0165-0114(03)00111-8},
	abstract = {Fuzzy systems have demonstrated their ability to solve different kinds of problems in various application domains. Currently, there is an increasing interest to augment fuzzy systems with learning and adaptation capabilities. Two of the most successful approaches to hybridise fuzzy systems with learning and adaptation methods have been made in the realm of soft computing. Neural fuzzy systems and genetic fuzzy systems hybridise the approximate reasoning method of fuzzy systems with the learning capabilities of neural networks and evolutionary algorithms. The objective of this paper is to provide an account of genetic fuzzy systems, with special attention to genetic fuzzy rule-based systems. After a brief introduction to models and applications of genetic fuzzy systems, the field is overviewed, new trends are identified, a critical evaluation of genetic fuzzy systems for fuzzy knowledge extraction is elaborated, and open questions that remain to be addressed in the future are raised. The paper also includes some of the key references required to quickly access implementation details of genetic fuzzy systems.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Cordón, O. and Gomide, F. and Herrera, F. and Hoffmann, F. and Magdalena, L.},
	month = jan,
	year = {2004},
	keywords = {Fuzzy rule based systems, Genetic algorithm, Learning, Tuning},
	pages = {5--31},
}

@article{mitra_neuro-fuzzy_2000,
	title = {Neuro-fuzzy rule generation: survey in soft computing framework},
	volume = {11},
	issn = {1941-0093},
	shorttitle = {Neuro-fuzzy rule generation},
	doi = {10.1109/72.846746},
	abstract = {The present article is a novel attempt in providing an exhaustive survey of neuro-fuzzy rule generation algorithms. Rule generation from artificial neural networks is gaining in popularity in recent times due to its capability of providing some insight to the user about the symbolic knowledge embedded within the network. Fuzzy sets are an aid in providing this information in a more human comprehensible or natural form, and can handle uncertainties at various levels. The neuro-fuzzy approach, symbiotically combining the merits of connectionist and fuzzy approaches, constitutes a key component of soft computing at this stage. To date, there has been no detailed and integrated categorization of the various neuro-fuzzy models used for rule generation. We propose to bring these together under a unified soft computing framework. Moreover, we include both rule extraction and rule refinement in the broader perspective of rule generation. Rules learned and generated for fuzzy reasoning and fuzzy control are also considered from this wider viewpoint. Models are grouped on the basis of their level of neuro-fuzzy synthesis. Use of other soft computing tools like genetic algorithms and rough sets are emphasized. Rule generation from fuzzy knowledge-based networks, which initially encode some crude domain knowledge, are found to result in more refined rules. Finally, real-life application to medical diagnosis is provided.},
	number = {3},
	journal = {IEEE Transactions on Neural Networks},
	author = {Mitra, S. and Hayashi, Y.},
	month = may,
	year = {2000},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Artificial neural network, Fuzzy control, Fuzzy reasoning, Fuzzy sets, Genetic algorithm, Network synthesis, Neuro-fuzzy network, Rough sets, Symbiosis, Uncertainty},
	pages = {748--768},
}

@inproceedings{gacto_handling_2009,
	title = {Handling {High}-{Dimensional} {Regression} {Problems} by {Means} of an {Efficient} {Multi}-{Objective} {Evolutionary} {Algorithm}},
	doi = {10.1109/ISDA.2009.214},
	abstract = {Linguistic fuzzy modeling in high dimensional regression problems is a challenging topic since conventional linguistic fuzzy rule-based systems suffer from exponential rule explosion when the number of variables and/or data examples becomes high. A good way to face this problem is by searching for a good and simple global structure within the same process, in order to consider the relationships among the different components defining the final linguistic model. In this contribution, we propose an effective multi-objective evolutionary algorithm that based on the data base learning a priori (involved variables, granularities and slight uniform displacements of the fuzzy partitions) allows a fast derivation of simple and quite accurate linguistic models, making use of some effective mechanisms in order to ensure a fast convergence. The good results obtained in several large-scale regression problems demonstrate the effectiveness of the proposed approach.},
	booktitle = {2009 {Ninth} {International} {Conference} on {Intelligent} {Systems} {Design} and {Applications}},
	author = {Gacto, María José and Alcalá, Rafael and Herrera, Francisco},
	month = nov,
	year = {2009},
	note = {ISSN: 2164-7151},
	keywords = {Application software, Complexity reduction, Convergence, Evolutionary computation, Explosions, Fuzzy systems, Genetic algorithm, High-dimensional regression problems, Knowledge based systems, Large-scale systems, Linguistic fuzzy modeling, Multi-objective},
	pages = {109--114},
}

@article{berthold_constructing_1999,
	title = {Constructing fuzzy graphs from examples},
	volume = {3},
	issn = {1088-467X},
	url = {https://www.sciencedirect.com/science/article/pii/S1088467X99000049},
	doi = {10.1016/S1088-467X(99)00004-9},
	abstract = {Methods to build function approximators from example data have gained considerable interest in the past. Especially methodologies that build models that allow an interpretation have attracted attention. Most existing algorithms, however, are either complicated to use or infeasible for high-dimensional problems. This article presents an efficient and easy to use algorithm to construct fuzzy graphs from example data. The resulting fuzzy graphs are based on locally independent fuzzy rules that operate solely on selected, important attributes. This enables the application of these fuzzy graphs also to problems in high dimensional spaces. Using illustrative examples and a real world data set it is demonstrated how the resulting fuzzy graphs offer quick insights into the structure of the example data, that is, the underlying model. The underlying algorithm is demonstrated using several Java applets, which can be found under ‘Electronic annexes’ on www.elsevier.com/locate/ida.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Intelligent Data Analysis},
	author = {Berthold, Michael R. and Huber, Klaus-Peter},
	month = may,
	year = {1999},
	keywords = {Function approximation, Fuzzy Graph, Interpretability, Learning, Rule Extraction},
	pages = {37--53},
}

@article{cheu_arpop_2012,
	title = {{ARPOP}: {An} {Appetitive} {Reward}-{Based} {Pseudo}-{Outer}-{Product} {Neural} {Fuzzy} {Inference} {System} {Inspired} {From} the {Operant} {Conditioning} of {Feeding} {Behavior} in {Aplysia}},
	volume = {23},
	issn = {2162-2388},
	shorttitle = {{ARPOP}},
	doi = {10.1109/TNNLS.2011.2178529},
	abstract = {Appetitive operant conditioning in Aplysia for feeding behavior via the electrical stimulation of the esophageal nerve contingently reinforces each spontaneous bite during the feeding process. This results in the acquisition of operant memory by the contingently reinforced animals. Analysis of the cellular and molecular mechanisms of the feeding motor circuitry revealed that activity-dependent neuronal modulation occurs at the interneurons that mediate feeding behaviors. This provides evidence that interneurons are possible loci of plasticity and constitute another mechanism for memory storage in addition to memory storage attributed to activity-dependent synaptic plasticity. In this paper, an associative ambiguity correction-based neuro-fuzzy network, called appetitive reward-based pseudo-outer-product-compositional rule of inference [ARPOP-CRI(S)], is trained based on an appetitive reward-based learning algorithm which is biologically inspired by the appetitive operant conditioning of the feeding behavior in Aplysia. A variant of the Hebbian learning rule called Hebbian concomitant learning is proposed as the building block in the neuro-fuzzy network learning algorithm. The proposed algorithm possesses the distinguishing features of the sequential learning algorithm. In addition, the proposed ARPOP-CRI(S) neuro-fuzzy system encodes fuzzy knowledge in the form of linguistic rules that satisfies the semantic criteria for low-level fuzzy model interpretability. ARPOP-CRI(S) is evaluated and compared against other modeling techniques using benchmark time-series datasets. Experimental results are encouraging and show that ARPOP-CRI(S) is a viable modeling technique for time-variant problem domains.},
	number = {2},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Cheu, Eng Yeow and Quek, Chai and Ng, See Kiong},
	month = feb,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Actuators, Appetitive reward, Cognition, Fuzzy systems, Generators, Hebbian concomitant learning, Inference algorithms, Intrinsic neuronal excitability, Neural network, Neuro-fuzzy network, Pragmatics, Pseudo outer-product, Synaptic plasticity},
	pages = {317--329},
}

@article{binaghi_slope_1998,
	title = {Slope {Instability} {Zonation}: a {Comparison} {Between} {Certainty} {Factor} and {Fuzzy} {Dempster}–{Shafer} {Approaches}},
	volume = {17},
	issn = {1573-0840},
	shorttitle = {Slope {Instability} {Zonation}},
	url = {https://doi.org/10.1023/A:1008001724538},
	doi = {10.1023/A:1008001724538},
	abstract = {This paper presents a comparison between two methodologies for the evaluation of slope instability and the production of instability maps, using a probabilistic approach and a hybrid possibilistic and credibilistic approach. The first is the Certainty Factor method, and the second is based on Fuzzy Logic integrated with the Dempster–Shafer theory. These methodologies are applied to the 1 : 50,000 scale Fabriano (Marche, Italy) geological map sheet. The results are represented as histograms where the accuracy of the prediction is shown, and the comparison of the results of the methods is discussed.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Natural Hazards},
	author = {Binaghi, E. and Luzi, L. and Madella, P. and Pergalani, F. and Rampini, A.},
	month = jan,
	year = {1998},
	keywords = {Certainty factor, Dempster-Shafer theory, Fuzzy logic},
	pages = {77--97},
}

@article{chen_large_2012,
	title = {A large population size can be unhelpful in evolutionary algorithms},
	volume = {436},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397511001368},
	doi = {10.1016/j.tcs.2011.02.016},
	abstract = {The utilization of populations is one of the most important features of evolutionary algorithms (EAs). There have been many studies analyzing the impact of different population sizes on the performance of EAs. However, most of such studies are based on computational experiments, except for a few cases. The common wisdom so far appears to be that a large population would increase the population diversity and thus help an EA. Indeed, increasing the population size has been a commonly used strategy in tuning an EA when it did not perform as well as expected for a given problem. He and Yao (2002) [8] showed theoretically that for some problem instance classes, a population can help to reduce the runtime of an EA from exponential to polynomial time. This paper analyzes the role of population further in EAs and shows rigorously that large populations may not always be useful. Conditions, under which large populations can be harmful, are discussed in this paper. Although the theoretical analysis was carried out on one multimodal problem using a specific type of EAs, it has much wider implications. The analysis has revealed certain problem characteristics, which can be either the problem considered here or other problems, that lead to the disadvantages of large population sizes. The analytical approach developed in this paper can also be applied to analyzing EAs on other problems.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Theoretical Computer Science},
	author = {Chen, Tianshi and Tang, Ke and Chen, Guoliang and Yao, Xin},
	month = jun,
	year = {2012},
	keywords = {Combinatorial optimization, Computational time complexity, Evolutionary algorithm},
	pages = {54--70},
}

@inproceedings{shunmuga_velayutham_applications_2003,
	title = {Some applications of an asymmetric subsethood product fuzzy neural inference system},
	volume = {1},
	doi = {10.1109/FUZZ.2003.1209362},
	abstract = {This paper presents some applications of an asymmetric subsethood product fuzzy neural inference system (ASuP-FuNIS). The ASuPFuNIS model extends SuPFuNIS by permitting signal and weight fuzzy sets to be modeled by asymmetric Gaussian membership functions. The asymmetric subsethood product network admits both numeric as well as linguistic inputs. Numeric inputs are fuzzified prior to their application to the network; linguistic inputs are presented without modification. The network architecture directly embeds fuzzy if-then rules, and connections represent antecedent and consequent fuzzy sets. The model uses mutual subsethood based activation spread and a product aggregation operator that works in conjunction with volume defuzzification in a gradient descent learning framework. The model is economical in terms of the number of rules required to solve difficult problems and is robust against random variations in data sets. Simulation results on three benchmark problems-the Hepatitis diagnosis, Iris data classification and the Narazaki-Ralescu function approximation problem-show that the subsethood based model performs excellently with minimal number of rules.},
	booktitle = {The 12th {IEEE} {International} {Conference} on {Fuzzy} {Systems}, 2003. {FUZZ} '03.},
	author = {Shunmuga Velayutham, C. and Kumar, S.},
	month = may,
	year = {2003},
	keywords = {Application software, Function approximation, Fuzzy control, Fuzzy neural network, Fuzzy sets, Fuzzy system},
	pages = {202--207 vol.1},
}

@article{tung_safin_2011,
	title = {{SaFIN}: {A} {Self}-{Adaptive} {Fuzzy} {Inference} {Network}},
	volume = {22},
	issn = {1941-0093},
	shorttitle = {{SaFIN}},
	doi = {10.1109/TNN.2011.2167720},
	abstract = {There are generally two approaches to the design of a neural fuzzy system: (1) design by human experts, and (2) design through a self-organization of the numerical training data. While the former approach is highly subjective, the latter is commonly plagued by one or more of the following major problems: (1) an inconsistent rulebase; (2) the need for prior knowledge such as the number of clusters to be computed; (3) heuristically designed knowledge acquisition methodologies; and (4) the stability-plasticity tradeoff of the system. This paper presents a novel self-organizing neural fuzzy system, named Self-Adaptive Fuzzy Inference Network (SaFIN), to address the aforementioned deficiencies. The proposed SaFIN model employs a new clustering technique referred to as categorical learning-induced partitioning (CLIP), which draws inspiration from the behavioral category learning process demonstrated by humans. By employing the one-pass CLIP, SaFIN is able to incorporate new clusters in each input-output dimension when the existing clusters are not able to give a satisfactory representation of the incoming training data. This not only avoids the need for prior knowledge regarding the number of clusters needed for each input-output dimension, but also allows SaFIN the flexibility to incorporate new knowledge with old knowledge in the system. In addition, the self-automated rule formation mechanism proposed within SaFIN ensures that it obtains a consistent resultant rulebase. Subsequently, the proposed SaFIN model is employed in a series of benchmark simulations to demonstrate its efficiency as a self-organizing neural fuzzy system, and excellent performances have been achieved.},
	number = {12},
	journal = {IEEE Transactions on Neural Networks},
	author = {Tung, Sau Wai and Quek, Chai and Guan, Cuntai},
	month = dec,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Categorical learning-induced partitioning, Computational modeling, Fuzzy neural network, Fuzzy system, Hybrid learning, Learning systems, Neuro-fuzzy network, Self-organizing},
	pages = {1928--1940},
}

@article{pal_rule_1999,
	title = {On rule pruning using fuzzy neural networks},
	volume = {106},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011497002893},
	doi = {10.1016/S0165-0114(97)00289-3},
	abstract = {Shann and Fu (SF) proposed a fuzzy neural network (FNN) for rule pruning in a fuzzy controller. In this paper we first analyze the FNN of SF and discuss some of its limitations. SF attempted to eliminate redundant rules interpreting some of the connection weights as certainty factors of rules. In their strategy the connection weights are unrestricted in sign and hence their interpretation as certainty factors introduces some inconsistencies into the scheme. We propose a modification of this FNN, which eliminates these inconsistencies. Moreover, we also propose a pruning scheme which, unlike the scheme of SF, always produces a compatible rule set. Superiority of the modified FNN is established using the inverted pendulum problem.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Pal, Nikhil R. and Pal, Tandra},
	month = sep,
	year = {1999},
	keywords = {Certainty factors, Fuzzy control, Fuzzy neural network, Rule reduction},
	pages = {335--347},
}

@inproceedings{stathacopoulou_neural_1999,
	title = {Neural network-based fuzzy modeling of the student in intelligent tutoring systems},
	volume = {5},
	doi = {10.1109/IJCNN.1999.836233},
	abstract = {An empirical approach that makes use of neuro-fuzzy synergism to evaluate the students in the context of an intelligent tutoring system is presented. In this way, a qualitative model of the student is generated, which is able to evaluate information regarding student's knowledge and cognitive abilities in a domain area. The neuro-fuzzy model has been tested on a prototype tutoring system in the physics domain of the vertical projectory motions and the results have been very satisfactory.},
	booktitle = {{IJCNN}'99. {International} {Joint} {Conference} on {Neural} {Networks}. {Proceedings} ({Cat}. {No}.{99CH36339})},
	author = {Stathacopoulou, R. and Magoulas, G.D. and Grigoriadou, M.},
	month = jul,
	year = {1999},
	note = {ISSN: 1098-7576},
	keywords = {Computer aided instruction, Fuzzy logic, Fuzzy neural network, Fuzzy system, Intelligent tutoring system, Neural network},
	pages = {3517--3521 vol.5},
}

@article{simpson_fuzzy_1992,
	title = {Fuzzy min-max neural networks. {I}. {Classification}},
	volume = {3},
	issn = {1941-0093},
	doi = {10.1109/72.159066},
	abstract = {A supervised learning neural network classifier that utilizes fuzzy sets as pattern classes is described. Each fuzzy set is an aggregate (union) of fuzzy set hyperboxes. A fuzzy set hyperbox is an n-dimensional box defined by a min point and a max point with a corresponding membership function. The min-max points are determined using the fuzzy min-max learning algorithm, an expansion-contraction process that can learn nonlinear class boundaries in a single pass through the data and provides the ability to incorporate new and refine existing classes without retraining. The use of a fuzzy set approach to pattern classification inherently provides a degree of membership information that is extremely useful in higher-level decision making. The relationship between fuzzy sets and pattern classification is described. The fuzzy min-max classifier neural network implementation is explained, the learning and recall algorithms are outlined, and several examples of operation demonstrate the strong qualities of this new neural network classifier.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Simpson, P.K.},
	month = sep,
	year = {1992},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Classification, Fuzzy neural network, Fuzzy sets, Fuzzy system, Neural network, Pattern classification, Supervised learning},
	pages = {776--786},
}

@article{han_design_2018,
	title = {Design of {Self}-{Organizing} {Intelligent} {Controller} {Using} {Fuzzy} {Neural} {Network}},
	volume = {26},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2017.2785812},
	abstract = {In this paper, a self-organizing intelligent controller (SOIC) is proposed for a class of nonlinear systems. The basic idea of this study is to use a self-organizing fuzzy neural network to imitate control law directly, and then, appeal to obtain a compact structure of controller to further reduce the computational burden and enhance the control performance. First, an effective criterion, using the tracking performance and structure risk of controller, is developed to self-organize the control rules online for SOIC to improve the tracking performance. Second, the structure and parameters of SOIC are updated by an adaptive projection-type algorithm to reduce the heavy computational burden to speed up the control response. Third, the stability of SOIC is proved in the sense of Lyapunov and the guidelines for selecting the control parameters are given. Finally, the effectiveness of SOIC is illustrated with three nonlinear systems. It is shown that the proposed SOIC can achieve better control performance in comparison with some other control schemes.},
	number = {5},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Han, Hong-Gui and Wu, Xiao-Long and Liu, Zheng and Qiao, Jun-Fei},
	month = oct,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Fuzzy control, Fuzzy neural network, Nonlinear control, Robustness, Self-organizing, Stability analysis, Structural risk model (SRM)},
	pages = {3097--3111},
}

@article{singh_dct-yager_2008,
	title = {{DCT}-{Yager} {FNN}: {A} {Novel} {Yager}-{Based} {Fuzzy} {Neural} {Network} {With} the {Discrete} {Clustering} {Technique}},
	volume = {19},
	issn = {1941-0093},
	shorttitle = {{DCT}-{Yager} {FNN}},
	doi = {10.1109/TNN.2007.911709},
	abstract = {Earlier clustering techniques such as the modified learning vector quantization (MLVQ) and the fuzzy Kohonen partitioning (FKP) techniques have focused on the derivation of a certain set of parameters so as to define the fuzzy sets in terms of an algebraic function. The fuzzy membership functions thus generated are uniform, normal, and convex. Since any irregular training data is clustered into uniform fuzzy sets (Gaussian, triangular, or trapezoidal), the clustering may not be exact and some amount of information may be lost. In this paper, two clustering techniques using a Kohonen-like self-organizing neural network architecture, namely, the unsupervised discrete clustering technique (UDCT) and the supervised discrete clustering technique (SDCT), are proposed. The UDCT and SDCT algorithms reduce this data loss by introducing nonuniform, normal fuzzy sets that are not necessarily convex. The training data range is divided into discrete points at equal intervals, and the membership value corresponding to each discrete point is generated. Hence, the fuzzy sets obtained contain pairs of values, each pair corresponding to a discrete point and its membership grade. Thus, it can be argued that fuzzy membership functions generated using this kind of a discrete methodology provide a more accurate representation of the actual input data. This fact has been demonstrated by comparing the membership functions generated by the UDCT and SDCT algorithms against those generated by the MLVQ, FKP, and pseudofuzzy Kohonen partitioning (PFKP) algorithms. In addition to these clustering techniques, a novel pattern classifying network called the Yager fuzzy neural network (FNN) is proposed in this paper. This network corresponds completely to the Yager inference rule and exhibits remarkable generalization abilities. A modified version of the pseudo-outer product (POP)-Yager FNN called the modified Yager FNN is introduced that eliminates the drawbacks of the earlier network and yields superior performance. Extensive experiments have been conducted to test the effectiveness of these two networks, using various clustering algorithms. It follows that the SDCT and UDCT clustering algorithms are particularly suited to networks based on the Yager inference rule.},
	number = {4},
	journal = {IEEE Transactions on Neural Networks},
	author = {Singh, A. and Quek, C. and Cho, S.-Y.},
	month = apr,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Clustering, Fuzzy Kohonen partitioning (FKP), Fuzzy clustering, Fuzzy neural network, Fuzzy partitioning, Fuzzy sets, Hybrid learning, Modified learning vector quantization (MLVQ), Neural networks, Neuro-fuzzy network, Noise modeling and cancellation, Normal and convex fuzzy sets, Pattern recognition, Predictive models, Pseudofuzzy partition, Self-organizing feature maps, Supervised learning, Triangular and trapezoidal fuzzy sets, Unsupervised learning, Vector quantization, Yager inference rule, Yager rule network},
	pages = {625--644},
}

@article{han_efficient_2019,
	title = {An {Efficient} {Optimization} {Method} for {Improving} {Generalization} {Performance} of {Fuzzy} {Neural} {Networks}},
	volume = {27},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2018.2878156},
	abstract = {Fuzzy neural networks (FNNs), with suitable structures, have been demonstrated to be an effective tool in approximating nonlinearity between input and output variables. However, it is time-consuming to construct an FNN with appropriate number of fuzzy rules to ensure its generalization ability. To solve this problem, an efficient optimization technique is introduced in this paper. First, a self-adaptive structural optimal algorithm (SASOA) is developed to minimize the structural risk of an FNN, leading to an improved generalization performance. Second, with the proposed SASOA, the fuzzy rules of SASOA-based FNN (SASOA-FNN) are generated or pruned systematically. This SASOA-FNN is able to organize the structure and adjust the parameters simultaneously in the learning process. Third, the convergence of SASOA-FNN is proved in the cases with fixed and updated structures, and the guidelines for selecting the parameters are given. Finally, experimental studies of the proposed SASOA-FNN have been performed on several nonlinear systems to verify the effectiveness. The comparison with other existing methods has been made, and it demonstrates that the proposed SASOA-FNN is of better performance.},
	number = {7},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Han, Honggui and Wu, Xiaolong and Liu, Hongxu and Qiao, Junfei},
	month = jul,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Adaptive, Complexity theory, Estimation error, Fuzzy neural network, Generalization performance, Nonlinear control, Optimization, Self-adaptive structural optimal algorithm (SASOA), Self-organizing, Structural risk model (SRM)},
	pages = {1347--1361},
}

@article{han_efficient_2019-1,
	title = {An {Efficient} {Second}-{Order} {Algorithm} for {Self}-{Organizing} {Fuzzy} {Neural} {Networks}},
	volume = {49},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2017.2762521},
	abstract = {Intelligent computing technologies are useful and important for online data modeling, where system dynamics may be nonstationary with some uncertainties. In this paper, an efficient learning mechanism is developed for building self-organizing fuzzy neural networks (SOFNNs), where a second-order algorithm (SOA) with adaptive learning rate is employed, the network size and the parameters can be determined simultaneously in the learning process. First, all parameters of SOFNN are adjusted by using the SOA strategy to achieve fast convergence through a powerful search scheme. Second, the structure of SOFNN can be self-organized using the relative importance index of each rule. The fuzzy rules used in SOFNN with SOA (SOA-SOFNN) are generated or pruned automatically to reduce the computational complexity and potentially improve the generalization power. Finally, a theoretical analysis on the learning convergence of the proposed SOA-SOFNN is given to show the computational efficiency. To demonstrate the merits of our proposed approach for data modeling, several benchmark datasets, and a real world application associated with nonlinear systems modeling problems are examined with comparisons against other existing methods. The results indicate that our proposed SOA-SOFNN performs favorably in terms of both learning speed and prediction accuracy for online data modeling.},
	number = {1},
	journal = {IEEE Transactions on Cybernetics},
	author = {Han, Honggui and Zhang, Lu and Wu, Xiaolong and Qiao, Junfei},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Cybernetics},
	keywords = {Adaptive learning rate strategy, Algorithm design and analysis, Approximation algorithms, Convergence, Data models, Fuzzy neural network, Nonlinear systems modeling, Second-order algorithm, Self-organizing, Self-organizing fuzzy neural networks (SOFNNs), Semiconductor optical amplifiers},
	pages = {14--26},
}

@article{qiao_self-organizing_2008,
	series = {Neural {Networks}: {Algorithms} and {Applications}},
	title = {A self-organizing fuzzy neural network and its applications to function approximation and forecast modeling},
	volume = {71},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231207002901},
	doi = {10.1016/j.neucom.2007.07.026},
	abstract = {To solve the problem of conventional input–output space partitioning, a new learning algorithm for creating self-organizing fuzzy neural networks (SOFNN) is proposed, which automates structure and parameter identification simultaneously based on input-target samples. First, a self-organizing clustering approach is used to establish the structure of the network and obtain the initial values of its parameters, then a supervised learning method to optimize these parameters. Two specific implementations of the algorithm, including function approximation and forecast modeling of the wastewater treatment system, are developed, comprehensive comparisons are made with other approaches in both of the examples. Simulation studies demonstrate the presented algorithm is superior in terms of compact structure and learning efficiency.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {Neurocomputing},
	author = {Qiao, Junfei and Wang, Huidong},
	month = jan,
	year = {2008},
	keywords = {Fuzzy neural network, Self-organizing},
	pages = {564--569},
}

@article{lin_new_1995,
	title = {A new approach to fuzzy-neural system modeling},
	volume = {3},
	issn = {1941-0034},
	doi = {10.1109/91.388173},
	abstract = {We develop simple but effective fuzzy-rule based models of complex systems from input-output data. We introduce a simple fuzzy-neural network for modeling systems, and we prove that it can represent any continuous function over a compact set. We introduce "fuzzy curves" and use them to: 1) identify significant input variables, 2) determine model structure, and 3) set the initial weights in the fuzzy-neural network model. Our method for input identification is computationally simple and, since we determine the proper network structure and initial weights in advance, we can train the network rapidly. Viewing the network as a fuzzy model gives insight into the real system, and it provides a method to simplify the neural network.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Lin, Yinghua and Cunningham, G.A.},
	month = may,
	year = {1995},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Data mining, Fuzzy modeling, Fuzzy neural network, Fuzzy reasoning, Fuzzy sets, Fuzzy system, Neural network},
	pages = {190--198},
}

@inproceedings{shi_learning_1996,
	title = {A learning algorithm for tuning fuzzy rules based on the gradient descent method},
	volume = {1},
	doi = {10.1109/FUZZY.1996.551719},
	abstract = {In this paper, we suggest a utility learning algorithm for tuning fuzzy rules by using input-output training data, based on the gradient descent method. The major advantage of this method is that the fuzzy rules or membership functions can be learned without changing the form of the fuzzy rule table used in usual fuzzy controls, so that the case of weak-firing can be avoided, which is different from the conventional learning algorithm. Furthermore, we illustrated the efficiency of the suggested learning algorithm by means of several numerical examples.},
	booktitle = {Proceedings of {IEEE} 5th {International} {Fuzzy} {Systems}},
	author = {Shi, Y. and Mizumoto, M. and Yubazaki, N. and Otani, M.},
	month = sep,
	year = {1996},
	keywords = {Fuzzy control, Fuzzy neural network, Fuzzy reasoning, Fuzzy system, Gaussian processes, Hybrid intelligent systems, Neural network},
	pages = {55--61 vol.1},
}

@inproceedings{fukumoto_destructive_1995,
	title = {A destructive learning method of fuzzy inference rules},
	volume = {2},
	doi = {10.1109/FUZZY.1995.409758},
	abstract = {In order to construct a fuzzy system with a learning function, numerous studies combining fuzzy systems and neural networks (or descent method) are being carried out. The self-tuning method using the descent method has been proposed by Ichihashi et al. (1991) and it is known that the constructive method is more powerful than other methods using neural networks (or descent method). But this method does not have a sufficient generalization capability or an expressing capability for the acquired knowledge. In this paper, we propose a new learning method called a destructive method of fuzzy inference rules by the descent method. And we show that the destructive method is superior in the number of rules and inference errors but inferior in learning speed to the constructive one. Further more, in order to improve learning speed, we propose a learning method combining the constructive and the destructive methods. Some numerical examples are given to show the validity of the proposed methods, and applications of these methods to the obstacle avoidance problem are shown.{\textless}{\textgreater}},
	booktitle = {Proceedings of 1995 {IEEE} {International} {Conference} on {Fuzzy} {Systems}.},
	author = {Fukumoto, S. and Miyajima, H. and Kishida, K. and Nagasawa, Y.},
	month = mar,
	year = {1995},
	keywords = {Fuzzy neural network, Fuzzy system, Learning system, Neural network, Simulation, Tuning},
	pages = {687--694 vol.2},
}

@article{li_finding_2018,
	series = {6th {International} {Conference} on {Information} {Technology} and {Quantitative} {Management}},
	title = {Finding {Fuzzy} {Close} {Frequent} {Itemsets} from {Databases}},
	volume = {139},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050918319264},
	doi = {10.1016/j.procs.2018.10.257},
	abstract = {In this paper, we define the problem of fuzzy close frequent itemset mining to discover the rules of the data. A concise tree-based data synoposis named FCTree is built, where the fuzzy itemsets are sorted by their supports. In addition, an algorithm called FCFIMiner is proposed to construct and maintain the FCTree. We conduct superset pruning from the result of the FCTree. The experimental works over 2 databases show the proposed algorithm has a much better performance.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Procedia Computer Science},
	author = {Li, Haifeng and Zhang, Yuejin and Hai, Mo and Hu, Hanqing},
	month = jan,
	year = {2018},
	keywords = {Data mining, Fuzzy close frequent itemset, Fuzzy frequent itemset, Quantitative database},
	pages = {242--247},
}

@article{liquan_designing_2006,
	title = {Designing fuzzy inference system based on improved gradient descent method},
	volume = {17},
	issn = {1004-4132},
	doi = {10.1016/S1004-4132(07)60027-9},
	abstract = {The distribution of sampling data influences completeness of rule base so that extrapolating missing rules is very difficult. Based on data mining, a self-learning method is developed for identifying fuzzy model and extrapolating missing rules, by means of confidence measure and the improved gradient descent method. The proposed approach can not only identify fuzzy model, update its parameters and determine optimal output fuzzy sets simultaneously, but also resolve the uncontrollable problem led by the regions that data do not cover. The simulation results show the effectiveness and accuracy of the proposed approach with the classical truck backer-upper control problem verifying.},
	number = {4},
	journal = {Journal of Systems Engineering and Electronics},
	author = {Liquan, Zhang and Cheng, Shao},
	month = dec,
	year = {2006},
	note = {Conference Name: Journal of Systems Engineering and Electronics},
	keywords = {Convergence, Data mining, Data models, Equations, Fuzzy sets, Fuzzy system, Gradient descent, Missing rule},
	pages = {853--857},
}

@article{hong_using_2020,
	title = {Using {Tree} {Structure} to {Mine} {High} {Temporal} {Fuzzy} {Utility} {Itemsets}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3018155},
	abstract = {Data mining is a critical technology for extracting valuable knowledge from databases. It has been used in many fields, like retail, finance, biology, etc. In computational intelligence, fuzzy logic has been applied in many intelligent systems widely because it is simple and similar to human inference. Fuzzy utility mining combines utility mining and fuzzy logic for getting linguistic utility knowledge. In this paper, we study a more challenging, complicated, but practical topic called temporal fuzzy utility data mining, which considers the temporal periods in transactions, purchased amounts, item profits, and understandable linguistic terms as important factors. Although an Apriori-based algorithm was proposed previously, its execution was not efficient. We thus use a modified tree structure based on the classical frequent-pattern tree to improve its performance. A tree-based mining algorithm is also proposed to mine temporal fuzzy utility itemsets from quantitative transactional databases. The tree structure is built to keep all temporal fuzzy utility 1-itemsets in a database. All the high temporal fuzzy utility itemsets in a database can be obtained by traversing the tree-based structure. The proposed algorithm gets the final results through two phases. In the first phase, a procedure like FP-Growth is used to find the candidate itemsets. In the second phase, the temporal fuzzy utility database is scanned to decide whether the candidate itemsets are desired. Experimental results show that the proposed algorithm is superior to the existing algorithm for temporal fuzzy utility mining in terms of processing time and used memory.},
	journal = {IEEE Access},
	author = {Hong, Tzung-Pei and Lin, Cheng-Yu and Huang, Wei-Ming and Li, Katherine Shu-Min and Wang, Leon Shyue-Liang and Lin, Jerry Chun-Wei},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Data mining, Fuzzy sets, Itemsets, Linguistics, Quantitative database, Temporal fuzzy utility mining, Tree structure, Utility mining},
	pages = {153692--153706},
}

@inproceedings{hong_mining_2019,
	title = {Mining {Temporal} {Fuzzy} {Utility} {Itemsets} by {Tree} {Structure}},
	doi = {10.1109/BigData47090.2019.9006317},
	abstract = {More complicated than fuzzy data mining, temporal fuzzy utility data mining takes into account the temporal factor of transactions, purchased quantities, item profits, and linguistic terms. In this paper, a tree structure modified from the frequent-pattern tree is designed and a mining algorithm based on it was proposed to extract high temporal fuzzy utility patterns from transactional datasets with the temporal property. The method requires two-phase processing to find all high temporal fuzzy utility itemsets. Experimental results show that the proposed algorithm performs better than the Apriori-based mining algorithm.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Hong, Tzung-Pei and Lin, Cheng-Yu and Huang, Wei-Ming and Li, Shu-Min and Wang, Shyue-Liang and Lin, Jerry Chun-Wei},
	month = dec,
	year = {2019},
	keywords = {Data mining, Fuzzy sets, Itemsets, Linguistics, Temporal mining, Tree structure, Upper bound, Utility mining},
	pages = {2659--2663},
}

@inproceedings{jensen_hybrid_2009,
	title = {Hybrid fuzzy-rough rule induction and feature selection},
	doi = {10.1109/FUZZY.2009.5277058},
	abstract = {The automated generation of feature pattern-based if-then rules is essential to the success of many intelligent pattern classifiers, especially when their inference results are expected to be directly human-comprehensible. Fuzzy and rough set theory have been applied with much success to this area as well as to feature selection. Since both applications of rough set theory involve the processing of equivalence classes for their successful operation, it is natural to combine them into a single integrated method that generates concise, meaningful and accurate rules. This paper proposes such an approach, based on fuzzy-rough sets. The algorithm is experimentally evaluated against leading classifiers, including fuzzy and rough rule inducers, and shown to be effective.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Fuzzy} {Systems}},
	author = {Jensen, Richard and Cornelis, Chris and Shen, Qiang},
	month = aug,
	year = {2009},
	note = {ISSN: 1098-7584},
	keywords = {Association rules, Fuzzy logic, Fuzzy sets, Induction generators, Inference algorithms, Robustness, Set theory},
	pages = {1151--1156},
}

@article{guillaume_designing_2001,
	title = {Designing fuzzy inference systems from data: an interpretability-oriented review},
	volume = {9},
	shorttitle = {Designing fuzzy inference systems from data},
	url = {https://hal.archives-ouvertes.fr/hal-01320328},
	doi = {10.1109/91.928739},
	number = {3},
	urldate = {2023-01-04},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Guillaume, S.},
	year = {2001},
	note = {Publisher: Institute of Electrical and Electronics Engineers},
	keywords = {Fuzzy partitioning, Fuzzy system, Interpretability, Optimization, Rule generation},
	pages = {426--443},
}

@article{paun_quick_2010,
	series = {Membrane computing and programming},
	title = {A quick introduction to membrane computing},
	volume = {79},
	issn = {1567-8326},
	url = {https://www.sciencedirect.com/science/article/pii/S1567832610000287},
	doi = {10.1016/j.jlap.2010.04.002},
	abstract = {Membrane computing is a branch of natural computing inspired from the architecture and the functioning of biological cells. The obtained computing models are distributed parallel devices, called P systems, processing multisets of objects in the compartments defined by hierarchical or more general arrangements of membranes. Many classes of P systems were investigated – mainly from the point of view of computing power and computing efficiency; also, a series of applications (especially in modeling biological processes) were reported. This note is a short and informal introduction to this research area, introducing a few basic notions, research topics, types of results, and pointing out to some relevant references.},
	language = {en},
	number = {6},
	urldate = {2023-01-04},
	journal = {The Journal of Logic and Algebraic Programming},
	author = {Păun, Gheorghe},
	month = aug,
	year = {2010},
	keywords = {Membrane computing, Natural computing, P-system, Turing computability},
	pages = {291--294},
}

@article{peng_fuzzy_2013,
	series = {Data-based {Control}, {Decision}, {Scheduling} and {Fault} {Diagnostics}},
	title = {Fuzzy reasoning spiking neural {P} system for fault diagnosis},
	volume = {235},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025512004793},
	doi = {10.1016/j.ins.2012.07.015},
	abstract = {Spiking neural P systems (SN P systems) have been well established as a novel class of distributed parallel computing models. Some features that SN P systems possess are attractive to fault diagnosis. However, handling fuzzy diagnosis knowledge and reasoning is required for many fault diagnosis applications. The lack of ability is a major problem of existing SN P systems when applying them to the fault diagnosis domain. Thus, we extend SN P systems by introducing some new ingredients (such as three types of neurons, fuzzy logic and new firing mechanism) and propose the fuzzy reasoning spiking neural P systems (FRSN P systems). The FRSN P systems are particularly suitable to model fuzzy production rules in a fuzzy diagnosis knowledge base and their reasoning process. Moreover, a parallel fuzzy reasoning algorithm based on FRSN P systems is developed according to neuron’s dynamic firing mechanism. Besides, a practical example of transformer fault diagnosis is used to demonstrate the feasibility and effectiveness of the proposed FRSN P systems in fault diagnosis problem.},
	language = {en},
	urldate = {2023-01-03},
	journal = {Information Sciences},
	author = {Peng, Hong and Wang, Jun and Pérez-Jiménez, Mario J. and Wang, Hao and Shao, Jie and Wang, Tao},
	month = jun,
	year = {2013},
	keywords = {Fault diagnosis, Fuzzy knowledge representation, Fuzzy reasoning, P-system, Spiking neural P system},
	pages = {106--116},
}

@inproceedings{idowu_advocating_2014,
	title = {Advocating the use of fuzzy reasoning spiking neural {P} system in intrusion detection},
	doi = {10.1109/ACMC.2014.7065804},
	abstract = {Membrane Computing (MC) with its variants has proved to be a versatile class of distributed parallel computing model. This is because despite its infancy, it has enjoyed significant application in various fields. However, much is yet to be accomplished in the area of information and network security. So, to further explore the efficacy of MC, this paper presents a new attempt in the application of SN P system and as well provides a novel idea and method for attack detection. The extension of SN P system called trapezoidal Fuzzy Reasoning Spiking Neural P (tFRSN P) system is adopted in the network intrusion prediction model. SN P system is a neural-like computing model inspired from the way spiking neurons communicate using spikes. It has a graphical modeling advantage which makes it well suited for fuzzy reasoning as well as fuzzy knowledge representation. In order to evaluate the performance of tFRSN P system in intrusion detection, the publicly available KDD Cup benchmark dataset was employed. After the experiments, our results yielded very high detection rate of 99.78\% and very low false alarm rate of 0.16\% for Brute Force Attack (BFA).},
	booktitle = {Asian {Conference} on {Membrane} {Computing} {ACMC} 2014},
	author = {Idowu, Rufai Kazeem and Chandren, Ravie and Othman, Zulaiha Ali},
	month = sep,
	year = {2014},
	keywords = {Fuzzy reasoning, Intrusion detection, P-system},
	pages = {1--5},
}

@article{zwick_measures_1987,
	title = {Measures of similarity among fuzzy concepts: {A} comparative analysis},
	volume = {1},
	issn = {0888-613X},
	shorttitle = {Measures of similarity among fuzzy concepts},
	url = {https://www.sciencedirect.com/science/article/pii/0888613X87900156},
	doi = {10.1016/0888-613X(87)90015-6},
	abstract = {Many measures of similarity among fuzzy sets have been proposed in the literature, and some have been incorporated into linguistic approximation procedures. The motivations behind these measures are both geometric and set-theoretic. We briefly review 19 such measures and compare their performance in a behavioral experiment. For crudely categorizing pairs of fuzzy concepts as either “similar” or “dissimilar,” all measures performed well. For distinguishing between degrees of similarity or dissimilarity, certain measures were clearly superior and others were clearly inferior; for a few subjects, however, none of the distance measures adequately modeled their similarity judgments. Measures that account for ordering on the base variable proved to be more highly correlated with subjects' actual similarity judgments. And, surprisingly, the best measures were ones that focus on only one “slice” of the membership function. Such measures are easiest to compute and may provide insight into the way humans judge similarity among fuzzy concepts.},
	language = {en},
	number = {2},
	urldate = {2023-01-04},
	journal = {International Journal of Approximate Reasoning},
	author = {Zwick, Rami and Carlstein, Edward and Budescu, David V.},
	month = apr,
	year = {1987},
	keywords = {Fuzzy concepts, Similarity measures},
	pages = {221--242},
}

@article{zhou_popfnn_1996,
	title = {{POPFNN}: {A} {Pseudo} {Outer}-product {Based} {Fuzzy} {Neural} {Network}},
	volume = {9},
	issn = {0893-6080},
	shorttitle = {{POPFNN}},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608096000275},
	doi = {10.1016/S0893-6080(96)00027-5},
	abstract = {A novel fuzzy neural network, called the pseudo outer-product based fuzzy neural network (POPFNN), is proposed in this paper. The functions performed by each layer in the proposed POPFNN strictly correspond to the inference steps in the truth value restriction method in fuzzy logic [Mantaras (1990) Approximate reasoning models, Ellis Horwood]. This correspondence gives it a strong theoretical basis. Similar to most of the existing fuzzy neural networks, the proposed POPFNN uses a self-organizing algorithm (Kohonen, 1988, Self-organization and associative memories, Springer) to learn and initialize the membership functions of the input and output variables from a set of training data. However, instead of employing the popularly used competitive learning [Kosko (1990) IEEE Trans. Neural Networks, 3(5), 801], this paper proposes a novel pseudo outer-product (POP) learning algorithm to identify the fuzzy rules that are supported by the training data. The proposed POP learning algorithm is fast, reliable, and highly intuitive. Extensive experimental results and comparisons are presented at the end of the paper for discussion. Copyright © 1996 Elsevier Science Ltd.},
	language = {en},
	number = {9},
	urldate = {2023-01-04},
	journal = {Neural Networks},
	author = {Zhou, R. W. and Quek, C.},
	month = dec,
	year = {1996},
	keywords = {Fuzzy neural network, Hybrid system, Neuro-fuzzy network, POPFNN, Pseudo outer-product, Single pass, Truth value restriction method},
	pages = {1569--1581},
}

@article{buckley_fuzzy_1994,
	title = {Fuzzy neural networks: {A} survey},
	volume = {66},
	issn = {0165-0114},
	shorttitle = {Fuzzy neural networks},
	url = {https://www.sciencedirect.com/science/article/pii/0165011494902976},
	doi = {10.1016/0165-0114(94)90297-6},
	abstract = {In this paper a fuzzy neural network will be a layered, feedforward, neural net that has fuzzy signals and/or fuzzy weights. We survey recent results on learning algorithms and applications for fuzzy neural networks.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Buckley, James J. and Hayashi, Yoichi},
	month = aug,
	year = {1994},
	keywords = {Fuzzy expert systems, Fuzzy logic controller, Hierarchical analysis, Learning algorithms, Neural network, Neuro-fuzzy network, Regression, Universal approximation},
	pages = {1--13},
}

@article{bosque_fuzzy_2014,
	title = {Fuzzy systems, neural networks and neuro-fuzzy systems: {A} vision on their hardware implementation and platforms over two decades},
	volume = {32},
	issn = {0952-1976},
	shorttitle = {Fuzzy systems, neural networks and neuro-fuzzy systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197614000384},
	doi = {10.1016/j.engappai.2014.02.008},
	abstract = {In recent decades, and in order to develop applications covering several areas of knowledge, different researchers have been performing hardware implementations around paradigms such as fuzzy systems, neural networks or systems resulting from the hybridization of the previous two systems, known as neuro–fuzzy systems. Applications have been performed on different types of devices and/or platforms. The point of view of this paper is focused on a hardware taxonomy (devices where the applications have been implemented) and highlights the characteristics of the different applications covering the aforementioned paradigms done over the last two decades, and the beginning of the current decade. Special mention is made up of reconfigurable devices.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Bosque, G. and del Campo, I. and Echanobe, J.},
	month = jun,
	year = {2014},
	keywords = {Fuzzy system, Neural network, Neuro-fuzzy network},
	pages = {283--331},
}

@article{salimi-badr_novel_2022,
	title = {A {Novel} {Self}-{Organizing} {Fuzzy} {Neural} {Network} to {Learn} and {Mimic} {Habitual} {Sequential} {Tasks}},
	volume = {52},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2020.2984646},
	abstract = {In this article, a new self-organizing fuzzy neural network (FNN) model is presented which is able to simultaneously and accurately learn and reproduce different sequences. Multiple sequence learning is important in performing habitual and skillful tasks, such as writing, signing signatures, and playing piano. Generally, it is indispensable for pattern generation applications. Since multiple sequences have similar parts, local information such as some previous samples is not sufficient to efficiently reproduce them. Instead, it is necessary to consider global and discriminative information, maybe in the very initial samples of each sequence, to first recognize them, and then predict their next sample based on the current local information. Therefore, the structure of the proposed network consists of two parts: 1) sequence identifier, which computes a novel sequence identity value based on initial samples of a sequence, and detects the sequence identity based on proper fuzzy rules and 2) sequence locator, which locates the input sample in the sequence. Therefore, by integrating outputs of these two parts in fuzzy rules, the network is able to produce the proper output based on the current state of each sequence. To learn the proposed structure, a gradual learning procedure is proposed. First, learning is performed by adding new fuzzy rules, based on coverage measure, using available correct data. Next, the initialized parameters are fine-tuned, by the gradient descent algorithm, based on fed back approximated network output as the next input. The proposed method has a dynamic structure able to learn new sequences online. Finally, to investigate the effectiveness of the presented approach, it is used to simultaneously learn and reproduce multiple sequences in different applications, including sequences with similar parts, different patterns, and writing different letters. The performance of the proposed method is evaluated and compared with other existing methods, including the adaptive network-based fuzzy inference system, GDFNN, CFNN, and long short-term memory (LSTM). According to these experiments, the proposed method outperforms traditional FNNs and LSTM in learning multiple sequences.},
	number = {1},
	journal = {IEEE Transactions on Cybernetics},
	author = {Salimi-Badr, Armin and Ebadzadeh, Mohammad Mehdi},
	month = jan,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Cybernetics},
	keywords = {Fuzzy control, Fuzzy neural network, Fuzzy sets, Gradual learning, Multivariate fuzzy sets, Self-organizing, Sequence modeling},
	pages = {323--332},
}

@article{al-shamri_fuzzy-genetic_2008,
	title = {Fuzzy-genetic approach to recommender systems based on a novel hybrid user model},
	volume = {35},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S095741740700351X},
	doi = {10.1016/j.eswa.2007.08.016},
	abstract = {The main strengths of collaborative filtering (CF), the most successful and widely used filtering technique for recommender systems, are its cross-genre or ‘outside the box’ recommendation ability and that it is completely independent of any machine-readable representation of the items being recommended. However, CF suffers from sparsity, scalability, and loss of neighbor transitivity. CF techniques are either memory-based or model-based. While the former is more accurate, its scalability compared to model-based is poor. An important contribution of this paper is a hybrid fuzzy-genetic approach to recommender systems that retains the accuracy of memory-based CF and the scalability of model-based CF. Using hybrid features, a novel user model is built that helped in achieving significant reduction in system complexity, sparsity, and made the neighbor transitivity relationship hold. The user model is employed to find a set of like-minded users within which a memory-based search is carried out. This set is much smaller than the entire set, thus improving system’s scalability. Besides our proposed approaches are scalable and compact in size, computational results reveal that they outperform the classical approach.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Expert Systems with Applications},
	author = {Al-Shamri, Mohammad Yahya H. and Bharadwaj, Kamal K.},
	month = oct,
	year = {2008},
	keywords = {Collaborative filtering, Fuzzy sets, Recommender systems},
	pages = {1386--1399},
}

@article{dahal_ga-based_2015,
	title = {{GA}-based learning for rule identification in fuzzy neural networks},
	volume = {35},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494615004123},
	doi = {10.1016/j.asoc.2015.06.046},
	abstract = {Employing an effective learning process is a critical topic in designing a fuzzy neural network, especially when expert knowledge is not available. This paper presents a genetic algorithm (GA) based learning approach for a specific type of fuzzy neural network. The proposed learning approach consists of three stages. In the first stage the membership functions of both input and output variables are initialized by determining their centers and widths using a self-organizing algorithm. The second stage employs the proposed GA based learning algorithm to identify the fuzzy rules while the final stage tunes the derived structure and parameters using a back-propagation learning algorithm. The capabilities of the proposed GA-based learning approach are evaluated using a well-examined benchmark example and its effectiveness is analyzed by means of a comparative study with other approaches. The usefulness of the proposed GA-based learning approach is also illustrated in a practical case study where it is used to predict the performance of road traffic control actions. Results from the benchmarking exercise and case study effectively demonstrate the ability of the proposed three stages learning approach to identify relevant fuzzy rules from a training data set with a higher prediction accuracy than alternative approaches.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {Dahal, Keshav and Almejalli, Khaled and Hossain, M. Alamgir and Chen, Wenbing},
	month = oct,
	year = {2015},
	keywords = {Backpropagation, Fuzzy rule identification, Genetic algorithm, Mamdani-type fuzzy neural network},
	pages = {605--617},
}

@inproceedings{ashraf_linguistic_2018,
	title = {Linguistic {Fuzzy} {Modeling} for {High} {Dimensional} {Regression} {Problem} {Using} {Multi}-{Objective} {Genetic} {Algorithm}},
	doi = {10.1109/IC4ME2.2018.8465603},
	abstract = {Fuzzy logic controllers suffer from the curse of dimensionality problem since the number of rules in a standard fuzzy system increases exponentially with the number of input and output variables. One way to overcome this problem is to decide the utilized linguistic variables, partitioning the linguistic variable and the rule base together, in order to only evolve very simple, but still accurate models. In order to accomplish these, we propose a novel 2-tuple linguistic fuzzy model and linguistic fuzzy partitioning technique. Our propose 2-tuple linguistic fuzzy logic controller tackles the curse of dimensionality problem in high-dimensional regression problems when the number of input and output variables becomes high. The linguistic information can be expressed by means of 2-tuples (S,α), where S is the linguistic term and α is the numeric value between [-0.5, 0.5]. Here, tackle 2-tuple fuzzy linguistic model capable for making processes of computing with words (CW) without loss of information. In order to validate our proposed method, we solve the high dimensional regression problem: length and maintenance cost estimation of low and medium voltage line respectively. We present extensive simulation results in order to demonstrate the simplicity and superiority of the proposed technique while comparing with other methods.},
	booktitle = {2018 {International} {Conference} on {Computer}, {Communication}, {Chemical}, {Material} and {Electronic} {Engineering} ({IC4ME2})},
	author = {Ashraf, Sayeeda and Shill, Pintu Chandra},
	month = feb,
	year = {2018},
	keywords = {2-tuple membership function representation, Biological cells, Fuzzy knowledge base, Fuzzy sets, Genetic algorithm, High dimensional regression problems, Linguistic fuzzy rule base System, Linguistics, Multi-objective},
	pages = {1--4},
}

@article{russo_comments_1996,
	title = {Comments on "{A} new approach to fuzzy-neural system modeling" [with reply]},
	volume = {4},
	issn = {1941-0034},
	doi = {10.1109/91.493915},
	abstract = {In the original paper (Y. Lin and G. A. Cunningham, ibid., vol. 3, p. 190-8, 1995), an approach to fuzzy-neural knowledge extraction starting from multi-input single-output examples is given. The author shows that the performance index given there is almost monotonically decreasing with m/sup -(1/2)/; that is, it is possible to obtain a very small performance index simply by increasing m. This is possible even if at the end of the learning phase the root mean square error remains very high. The original authors acknowledge that this is correct and explain why nevertheless they presented the approach that they did.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Russo, M.},
	month = may,
	year = {1996},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Backpropagation, Genetic algorithm, Modeling, Neural network, Nonlinear control, Performance analysis},
	pages = {209--210},
}

@article{chen_cluster-based_2020,
	title = {Cluster-{Based} {Membership} {Function} {Acquisition} {Approaches} for {Mining} {Fuzzy} {Temporal} {Association} {Rules}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3004095},
	abstract = {In real-world applications, transactions are typically represented by quantitative data. Thus, fuzzy association rule mining algorithms have been proposed to handle these quantitative transactions. In addition, items generally have certain lifespans or temporal periods in which they exist in a database. Therefore, fuzzy temporal association rule mining algorithms have also been proposed in the literature. A key factor in the acquisition of fuzzy temporal association rules (FTARs) is the design of appropriate membership functions. Because current approaches have been designed to generate membership functions for mining fuzzy association rules (FARs) in market-basket analysis, in this paper, we propose a membership function tuning mechanism for a fuzzy temporal association rule mining algorithm. The proposed approach modifies an existing cluster-based method to generate unique membership functions that are specifically tailored to each item in a dataset. Two factors are utilized to decide the appropriate membership functions of each item: (1) the density similarity among intervals corresponding to the density similarity within intervals, and (2) the information closeness within an interval corresponding to the similarity in the number of data points between intervals. A parameter θ is used to indicate the relative importance of these two factors. As a result, the membership functions are generated based on the quantitative ranges of individual items, and the generated membership functions of items are different in terms of the values of each interval and the number of intervals. The generated membership functions are subsequently used in a fuzzy temporal association rule mining algorithm. Computational experiments were conducted on both a synthetic dataset and a real-world one to demonstrate the effectiveness of the proposed approach.},
	journal = {IEEE Access},
	author = {Chen, Chun-Hao and Chou, Hsiang and Hong, Tzung-Pei and Nojima, Yusuke},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Biological cells, Clustering, Data mining, Databases, Fuzzy association rule, Fuzzy temporal association rule, Genetic algorithm, Item lifespan, Membership functions, Tuning},
	pages = {123996--124006},
}

@inproceedings{ohashi_learning_2019,
	title = {A {Learning} {Method} of {Non}-{Differential} {SIC} {Fuzzy} {Inference} {Model} {Using} {Genetic} {Algorithm} and {Its} {Application} to a {Medical} {Diagnosis}},
	doi = {10.1109/SMC.2019.8914619},
	abstract = {There are typical learning methods for fuzzy inference models such as the steepest descent method, genetic algorithm, etc. It is generally impossible to apply the steepest descent method to fuzzy inference models with consequent fuzzy sets, such as Mamdani’s fuzzy inference models that use min and max operations. Therefore, genetic algorithm will be useful for the above model. However, the computational complexity of genetic algorithm is much larger than the steepest descent method. Also, since all input items are set to the antecedent parts in typical fuzzy inference model, the number of rules increases exponentially. Moreover, considering the computational complexity of genetic algorithm, it will not be necessarily suitable. On the other hand, Single Input Connected (SIC) fuzzy inference model sets the fuzzy rule of 1 input 1 output, so the number of rules can be reduced drastically. The consequent parts of the conventional SIC model were real number although linguistic interpretation is possible and easy to understand if the consequent parts are fuzzy sets. Therefore, we propose a new SIC model which extends real number of the consequent parts to fuzzy sets, and the fuzzy rules are derived by using genetic algorithm. In addition, it is applied to a medical diagnosis and compared with the conventional fuzzy inference models.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics} ({SMC})},
	author = {Ohashi, Genki and Shimizu, Tomoki and Seki, Hirosato and Inuiguchi, Masahiro},
	month = oct,
	year = {2019},
	note = {ISSN: 2577-1655},
	keywords = {Computational modeling, Fuzzy logic, Fuzzy sets, Genetic algorithm},
	pages = {2454--2459},
}

@inproceedings{andone_fuzzy_2005,
	address = {Bucharest, Romania},
	series = {Proceedings of {CSCS}-15, 15th {INTERNATIONAL} {CONFERENCE} {ON} {CONTROL} {SYSTEMS} {AND} {COMPUTER} {SCIENCE}},
	title = {Fuzzy rule base complexity reduction: a survey},
	volume = {1},
	shorttitle = {Fuzzy rule base complexity reduction},
	url = {https://hal.archives-ouvertes.fr/hal-01246577},
	doi = {10.13140/RG.2.1.5021.8326},
	abstract = {The paper presents a survey of fuzzy rule base reduction techniques. The identification of fuzzy models from training data needs to consider both data fitness and complexity. The methodologies of model design can be mainly divided into two groups: the semantic-driven modelling and the data-driven modelling. The first model design type proposes models which are built based on expert knowledge. However, it is often the case that the model contains redundant rules and /or variables, so there is a need to reduce the redundancy of the model. The second model design type became more popular in the last decade partly due to the fact that fuzzy models were found to be able to approximate with arbitrary accuracy any continuous control function. These models usually use tremendously large number of rules and do not take into account the complexity of the model. This characteristic also emerged the issue of rule base reduction. The present paper summarizes the efforts done on the complexity reduction field.},
	urldate = {2023-01-04},
	booktitle = {{CSCS}-15, 15th {INTERNATIONAL} {CONFERENCE} {ON} {CONTROL} {SYSTEMS} {AND} {COMPUTER} {SCIENCE}},
	publisher = {POLITEHNICA University of Bucharest},
	author = {Andone, Daniela},
	month = may,
	year = {2005},
	keywords = {Complexity reduction, Data-driven model, Semantic interpretability, Similarity measures},
	pages = {5},
}

@inproceedings{yao_classification_2021,
	title = {Classification and {Recognition} {Fusion} {Algorithm} {Based} on {Fuzzy} {Set} {Theory} and {Similarity} {Measure}},
	doi = {10.1109/ICSPCC52875.2021.9564472},
	abstract = {D-S evidence theory is an imprecise information reasoning decision method most suitable for the application of target recognition, and it is widely used in uncertain information reasoning systems. The data fusion algorithm is one of the key technologies in the recognition and detection system. The data fusion algorithm based on fuzzy set theory and similarity measurement merges multiple classification recognition results, which helps to improve the accuracy of the detection and recognition system, and improve the detection and detection. Identify the reliability and practicability of the system. Use fuzzy set theory to generate reliability distribution function, measure the amount of information of multiple evidence, based on the evidence similarity measurement, revise the source evidence, and constitute the evidence. After conducting experiments on the fusion algorithm for the measured noise classification data of ships, the simulation results show that the fusion algorithm can further improve the trust in the classification and recognition results of the target. The fusion algorithm is feasible and effective, which greatly improves the performance of the original detection and recognition system.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Signal} {Processing}, {Communications} and {Computing} ({ICSPCC})},
	author = {Yao, Ze and Zhang, Xin},
	month = aug,
	year = {2021},
	keywords = {Classification, D-S evidence theory, Data integration, Fusion algorithm, Fuzzy set theory, Reliability theory, Similarity measures, Simulation},
	pages = {1--5},
}

@inproceedings{razak_interpretability_2018,
	address = {Bangalore, India},
	title = {Interpretability and {Complexity} of {Design} in the {Creation} of {Fuzzy} {Logic} {Systems} — {A} {User} {Study}},
	isbn = {978-1-5386-9276-9},
	url = {https://ieeexplore.ieee.org/document/8628924/},
	doi = {10.1109/SSCI.2018.8628924},
	abstract = {In recent years, researchers have become increasingly more interested in designing an interpretable Fuzzy Logic System (FLS). Many studies have claimed that reducing the complexity of FLSs can lead to improved model interpretability. That is, reducing the number of rules tends to reduce the complexity of FLSs, thus improving their interpretability. However, none of these studies have considered interpretability and complexity from human perspectives. Since interpretability is of a subjective nature, it is essential to see how people perceive interpretability and complexity particularly in relation to creating FLSs. Therefore, in this paper we have investigated this issue using an initial user study. This is the ﬁrst time that a user study has been used to assess the interpretability and complexity of designs in relation to creating FLSs. The user study involved a range of expert practitioners in FLSs and received a diverse set of answers. We are interested to see whether, from the perspectives of people, FLSs are necessarily more interpretable when they are less complex in terms of their design. Although the initial user study is based on small samples (i.e., 25 participants), nevertheless this research provides initial insight into this issue that motivates our future research.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {2018 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	publisher = {IEEE},
	author = {Razak, Tajul Rosli and Garibaldi, Jonathan M. and Wagner, Christian and Pourabdollah, Amir and Soria, Daniele},
	month = nov,
	year = {2018},
	keywords = {Complexity of design, Complexity theory, Fuzzy logic, Fuzzy sets, Fuzzy system, Interpretability},
	pages = {420--426},
}

@misc{chung_empirical_2014,
	title = {Empirical {Evaluation} of {Gated} {Recurrent} {Neural} {Networks} on {Sequence} {Modeling}},
	url = {http://arxiv.org/abs/1412.3555},
	doi = {10.48550/arXiv.1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	month = dec,
	year = {2014},
	note = {arXiv:1412.3555 [cs]},
	keywords = {Gated recurrent neural network, Sequence modeling},
}

@incollection{bouchon-meunier_xai_2022,
	address = {Cham},
	series = {Women in {Engineering} and {Science}},
	title = {{XAI}: {A} {Natural} {Application} {Domain} for {Fuzzy} {Set} {Theory}},
	isbn = {978-3-030-79092-9},
	shorttitle = {{XAI}},
	url = {https://doi.org/10.1007/978-3-030-79092-9_2},
	abstract = {As digital systems cover all personal and professional activities, artificial intelligence is now everywhere. In this context, it is crucial for systems and decisions to be understandable for humans, in a human-in-the-loop process. This global objective is known as eXplainable Artificial Intelligence (XAI). In this chapter, we argue that fuzzy logic is a key concept for XAI as it offers a theoretical framework that is closer than many others to human cognition, human reasoning and human intuitions. We exemplify the many advantages fuzzy logic offers to the XAI domain.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Women in {Computational} {Intelligence}: {Key} {Advances} and {Perspectives} on {Emerging} {Topics}},
	publisher = {Springer International Publishing},
	author = {Bouchon-Meunier, Bernadette and Laurent, Anne and Lesot, Marie-Jeanne},
	editor = {Smith, Alice E.},
	year = {2022},
	doi = {10.1007/978-3-030-79092-9_2},
	keywords = {Approximate reasoning, Computing with words (CWW), Explainable AI (XAI), Fuzzy logic, Machine learning},
	pages = {23--49},
}

@article{ramos-soto_enriching_2021,
	series = {Knowledge {Representation} and {Logics}},
	title = {Enriching linguistic descriptions of data: {A} framework for composite protoforms},
	volume = {407},
	issn = {0165-0114},
	shorttitle = {Enriching linguistic descriptions of data},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011419305081},
	doi = {10.1016/j.fss.2019.11.013},
	abstract = {One of the current limitations of fuzzy linguistic descriptions of data is the lack of diversity of protoforms that can be used to linguistically summarize data. Despite an important effort in providing protoforms with improved semantics that are applicable to time series data or specific application domains, type-I and type-II fuzzy quantified sentences are still predominant in the literature. In this context, we propose a different approach for defining new types of protoforms. Instead of understanding protoforms as individual primitives, our proposal draws inspiration from Rhetorical Structure Theory to provide a framework that allows to define new types of complex protoforms based on semantic relations among simpler protoforms. Based on this framework, we propose an initial taxonomy of relations among protoforms and provide an illustrative use case based on real data and evaluated by human users.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Ramos-Soto, A. and Martin-Rodilla, P.},
	month = mar,
	year = {2021},
	keywords = {Computing with words (CWW), Fuzzy sets, Linguistic descriptions of data, Natural language generation, Rhetorical structure theory},
	pages = {1--26},
}

@article{velayutham_asymmetric_2005,
	title = {Asymmetric subsethood-product fuzzy neural inference system ({ASuPFuNIS})},
	volume = {16},
	issn = {1941-0093},
	doi = {10.1109/TNN.2004.836202},
	abstract = {This work presents an asymmetric subsethood-product fuzzy neural inference system (ASuPFuNIS) that directly extends the SuPFuNIS model by permitting signal and weight fuzzy sets to be modeled by asymmetric Gaussian membership functions. The asymmetric subsethood-product network admits both numeric as well as linguistic inputs. Input nodes, which act as tunable feature fuzzifiers, fuzzify numeric inputs with asymmetric Gaussian fuzzy sets; and linguistic inputs are presented as is. The antecedent and consequent labels of standard fuzzy if-then rules are represented as asymmetric Gaussian fuzzy connection weights of the network. The model uses mutual subsethood based activation spread and a product aggregation operator that works in conjunction with volume defuzzification in a gradient descent learning framework. Despite the increase in the number of free parameters, the proposed model performs better than SuPFuNIS, on various benchmarking problems, both in terms of the performance accuracy and architectural economy and compares excellently with other various existing models with a performance better than most of them.},
	number = {1},
	journal = {IEEE Transactions on Neural Networks},
	author = {Velayutham, C.S. and Kumar, S.},
	month = jan,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Asymmetric Gaussian membership functions, Fuzzy neural network, Fuzzy sets, Fuzzy system, Gradient descent, Inference algorithms, Multilayer perceptrons, Mutual subsethood, Supervised learning, Volume defuzzification},
	pages = {160--174},
}

@inproceedings{nauck_neuro-fuzzy_2013,
	address = {Berlin, Heidelberg},
	series = {Studies in {Computational} {Intelligence}},
	title = {Neuro-fuzzy {Systems}: {A} {Short} {Historical} {Review}},
	isbn = {978-3-642-32378-2},
	shorttitle = {Neuro-fuzzy {Systems}},
	doi = {10.1007/978-3-642-32378-2_7},
	abstract = {When the popularity of fuzzy systems in the guise of fuzzy controllers began to rise in the beginning of the 1990s researchers became interested in supporting the development process by an automatic learning process. Just a few years earlier the backpropagation learning rule for multi-layer neural networks had been rediscovered and triggered a massive new interest in neural networks. The approach of combining fuzzy systems with neural networks into neuro-fuzzy systems therefore was an obvious choice for making fuzzy systems learn. In this chapter we briefly recall some milestones on the evolution of neuro-fuzzy systems.},
	language = {en},
	booktitle = {Computational {Intelligence} in {Intelligent} {Data} {Analysis}},
	publisher = {Springer},
	author = {Nauck, Detlef D. and Nürnberger, Andreas},
	editor = {Moewes, Christian and Nürnberger, Andreas},
	year = {2013},
	keywords = {Fuzzy inference system, Fuzzy logic controller, Fuzzy rule, Fuzzy system, Radial basis function (RBF)},
	pages = {91--109},
}

@inproceedings{shill_optimization_2013,
	title = {Optimization of fuzzy logic controllers with rule base size reduction using genetic algorithms},
	doi = {10.1109/CICA.2013.6611664},
	abstract = {In this paper, we present the automatic design methods with rule base size reduction for fuzzy logic controllers (FLCs). The adaptive schema is divided into two phases: the first phase is concerned with the adaptive learning method for optimizing the MFs parameters based on the binary coded genetic algorithms. The second phase is about the learning and reducing: automatically generate the fuzzy rules and at the same time apply the genetic reduction technique to determine the minimum number of fuzzy rules required in building the fuzzy models. In the rule base, the redundant rules are removed by setting their all consequents weight factor to zero and merging the conflicting rules during the learning process. The real and binary coded coupled genetic algorithms are applied for generating the optimal controllers that reduce the rule base size and optimal selection of fuzzy sets. Optimizing the MFs of FLCs with learning and reducing the number of fuzzy control rules concurrently represents a way to improve the computational efficiency and interpretability of FLCs to minimize the errors. The control algorithm is successfully tested for intelligent control of two degrees of freedom inverted pendulum. Finally, the simulation studies exhibits competing results with high accuracy that demonstrate the effective use of the proposed algorithm.},
	booktitle = {2013 {IEEE} {Symposium} on {Computational} {Intelligence} in {Control} and {Automation} ({CICA})},
	author = {Shill, Pintu Chandra and Maeda, Yoichiro and Murase, Kazuyuki},
	month = apr,
	year = {2013},
	note = {ISSN: 2328-1464},
	keywords = {Binary and Real coded Genetic Algorithms, Biological cells, Fuzzy logic, Fuzzy logic controller, Genetic algorithm, Optimization, Pragmatics, Rule Base Size Reduction, Two Degrees Freedom Inverted Pendulum},
	pages = {57--64},
}

@inproceedings{li_temporal_2017,
	title = {Temporal fuzzy association rules mining based on fuzzy information granulation},
	doi = {10.1109/FSKD.2017.8392930},
	abstract = {In this paper, we developed a sound conceptual framework for temporal fuzzy association rules mining based on fuzzy information granulation. First, the definition of the support rate of traditional fuzzy association rules is extended to the temporal data, including the fuzzy support rate of both continuous and discontinues temporal fuzzy item set and their association rules. It is found that the computation of support rate under our definition is a simply dynamic programming problem with very low complexity. Then an algorithm based on Apriori is demonstrated. At last, experiments were carried out to show the good performance of our new algorithm in mining continuous rules and discontinuous rules by our definition.},
	booktitle = {2017 13th {International} {Conference} on {Natural} {Computation}, {Fuzzy} {Systems} and {Knowledge} {Discovery} ({ICNC}-{FSKD})},
	author = {Li, Zebang and Bu, Fan and Yu, Fusheng},
	month = jul,
	year = {2017},
	keywords = {Data mining, Databases, Fuzzy clustering, Fuzzy information granulation, Fuzzy systems, Market research, Microsoft Windows, Remuneration, Temporal fuzzy association rules, Time series},
	pages = {1168--1174},
}

@misc{khalifa_multiple_2016,
	title = {Multiple {Instance} {Fuzzy} {Inference} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1610.04973},
	abstract = {Fuzzy logic is a powerful tool to model knowledge uncertainty, measurements imprecision, and vagueness. However, there is another type of vagueness that arises when data have multiple forms of expression that fuzzy logic does not address quite well. This is the case for multiple instance learning problems (MIL). In MIL, an object is represented by a collection of instances, called a bag. A bag is labeled negative if all of its instances are negative, and positive if at least one of its instances is positive. Positive bags encode ambiguity since the instances themselves are not labeled. In this paper, we introduce fuzzy inference systems and neural networks designed to handle bags of instances as input and capable of learning from ambiguously labeled data. First, we introduce the Multiple Instance Sugeno style fuzzy inference (MI-Sugeno) that extends the standard Sugeno style inference to handle reasoning with multiple instances. Second, we use MI-Sugeno to define and develop Multiple Instance Adaptive Neuro Fuzzy Inference System (MI-ANFIS). We expand the architecture of the standard ANFIS to allow reasoning with bags and derive a learning algorithm using backpropagation to identify the premise and consequent parameters of the network. The proposed inference system is tested and validated using synthetic and benchmark datasets suitable for MIL problems. We also apply the proposed MI-ANFIS to fuse the output of multiple discrimination algorithms for the purpose of landmine detection using Ground Penetrating Radar.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Khalifa, Amine Ben and Frigui, Hichem},
	month = oct,
	year = {2016},
	note = {arXiv:1610.04973 [cs]},
}

@misc{ravi_accelerating_2020,
	title = {Accelerating {3D} {Deep} {Learning} with {PyTorch3D}},
	url = {http://arxiv.org/abs/2007.08501},
	abstract = {Deep learning has significantly improved 2D image recognition. Extending into 3D may advance many new applications including autonomous vehicles, virtual and augmented reality, authoring 3D content, and even improving 2D recognition. However despite growing interest, 3D deep learning remains relatively underexplored. We believe that some of this disparity is due to the engineering challenges involved in 3D deep learning, such as efficiently processing heterogeneous data and reframing graphics operations to be differentiable. We address these challenges by introducing PyTorch3D, a library of modular, efficient, and differentiable operators for 3D deep learning. It includes a fast, modular differentiable renderer for meshes and point clouds, enabling analysis-by-synthesis approaches. Compared with other differentiable renderers, PyTorch3D is more modular and efficient, allowing users to more easily extend it while also gracefully scaling to large meshes and images. We compare the PyTorch3D operators and renderer with other implementations and demonstrate significant speed and memory improvements. We also use PyTorch3D to improve the state-of-the-art for unsupervised 3D mesh and point cloud prediction from 2D images on ShapeNet. PyTorch3D is open-source and we hope it will help accelerate research in 3D deep learning.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Ravi, Nikhila and Reizenstein, Jeremy and Novotny, David and Gordon, Taylor and Lo, Wan-Yen and Johnson, Justin and Gkioxari, Georgia},
	month = jul,
	year = {2020},
	note = {arXiv:2007.08501 [cs]},
}

@book{kohonen_self-organization_2012,
	title = {Self-{Organization} and {Associative} {Memory}},
	isbn = {978-3-642-88163-3},
	abstract = {While the present edition is bibliographically the third one of Vol. 8 of the Springer Series in Information Sciences (IS 8), the book actually stems from Vol. 17 of the series Communication and Cybernetics (CC 17), entitled Associative Memory - A System-Theoretical Approach, which appeared in 1977. That book was the first monograph on distributed associative memories, or "content-addressable memories" as they are frequently called, especially in neural-networks research. This author, however, would like to reserve the term "content-addressable memory" for certain more traditional constructs, the memory locations of which are selected by parallel search. Such devices are discussed in Vol. 1 of the Springer Series in Information Sciences, Content-Addressable Memories. This third edition of IS 8 is rather similar to the second one. Two new discussions have been added: one to the end of Chap. 5, and the other (the L VQ 2 algorithm) to the end of Chap. 7. Moreover, the convergence proof in Sect. 5.7.2 has been revised.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Kohonen, Teuvo},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: cSzwCAAAQBAJ},
	keywords = {Associative memory, Self-organizing},
}

@book{melin_analysis_2007,
	title = {Analysis and {Design} of {Intelligent} {Systems} {Using} {Soft} {Computing} {Techniques}},
	isbn = {978-3-540-72432-2},
	abstract = {This book comprises a selection of papers from IFSA 2007 on new methods for ana- sis and design of hybrid intelligent systems using soft computing techniques. Soft Computing (SC) consists of several computing paradigms, including fuzzy logic, n- ral networks, and genetic algorithms, which can be used to produce powerful hybrid intelligent systems for solving problems in pattern recognition, time series prediction, intelligent control, robotics and automation. Hybrid intelligent systems that combine several SC techniques are needed due to the complexity and high dimensionality of real-world problems. Hybrid intelligent systems can have different architectures, which have an impact on the efficiency and accuracy of these systems, for this reason it is very important to optimize architecture design. The architectures can combine, in different ways, neural networks, fuzzy logic and genetic algorithms, to achieve the ultimate goal of pattern recognition, time series prediction, intelligent control, or other application areas. This book is intended to be a major reference for scientists and engineers interested in applying new computational and mathematical tools to design hybrid intelligent systems. This book can also be used as a reference for graduate courses like the f- lowing: soft computing, intelligent pattern recognition, computer vision, applied ar- ficial intelligence, and similar ones. The book is divided in to twelve main parts. Each part contains a set of papers on a common subject, so that the reader can find similar papers grouped together.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Melin, Patricia and Castillo, Oscar and Ramírez, Eduardo G. and Pedrycz, Witold},
	month = sep,
	year = {2007},
	note = {Google-Books-ID: rw4LeQBc2p4C},
	keywords = {Soft computing},
}

@book{dubois_linguistic_2014,
	title = {"{A} {Linguistic} {Self}-{Organizing} {Process} {Controller}" within {Readings} in {Fuzzy} {Sets} for {Intelligent} {Systems}},
	isbn = {978-1-4832-1450-4},
	abstract = {Readings in Fuzzy Sets for Intelligent Systems is a collection of readings that explore the main facets of fuzzy sets and possibility theory and their use in intelligent systems. Basic notions in fuzzy set theory are discussed, along with fuzzy control and approximate reasoning. Uncertainty and informativeness, information processing, and membership, cognition, neural networks, and learning are also considered. Comprised of eight chapters, this book begins with a historical background on fuzzy sets and possibility theory, citing some forerunners who discussed ideas or formal definitions very close to the basic notions introduced by Lotfi Zadeh (1978). The reader is then introduced to fundamental concepts in fuzzy set theory, including symmetric summation and the setting of fuzzy logic; uncertainty and informativeness; and fuzzy control. Subsequent chapters deal with approximate reasoning; information processing; decision and management sciences; and membership, cognition, neural networks, and learning. Numerical methods for fuzzy clustering are described, and adaptive inference in fuzzy knowledge networks is analyzed. This monograph will be of interest to both students and practitioners in the fields of computer science, information science, applied mathematics, and artificial intelligence.},
	language = {en},
	publisher = {Morgan Kaufmann},
	author = {Dubois, Didier J. and Prade, Henri and Yager, Ronald R.},
	month = may,
	year = {2014},
	note = {Google-Books-ID: JCSjBQAAQBAJ},
	keywords = {Self-organizing},
}

@misc{cho_properties_2014,
	title = {On the {Properties} of {Neural} {Machine} {Translation}: {Encoder}-{Decoder} {Approaches}},
	shorttitle = {On the {Properties} of {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1409.1259},
	doi = {10.48550/arXiv.1409.1259},
	abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
	month = oct,
	year = {2014},
	note = {arXiv:1409.1259 [cs, stat]},
}

@article{van_krieken_analyzing_2022,
	title = {Analyzing {Differentiable} {Fuzzy} {Logic} {Operators}},
	volume = {302},
	issn = {00043702},
	url = {http://arxiv.org/abs/2002.06100},
	doi = {10.1016/j.artint.2021.103602},
	abstract = {The AI community is increasingly putting its attention towards combining symbolic and neural approaches, as it is often argued that the strengths and weaknesses of these approaches are complementary. One recent trend in the literature are weakly supervised learning techniques that employ operators from fuzzy logics. In particular, these use prior background knowledge described in such logics to help the training of a neural network from unlabeled and noisy data. By interpreting logical symbols using neural networks, this background knowledge can be added to regular loss functions, hence making reasoning a part of learning. We study, both formally and empirically, how a large collection of logical operators from the fuzzy logic literature behave in a differentiable learning setting. We find that many of these operators, including some of the most well-known, are highly unsuitable in this setting. A further finding concerns the treatment of implication in these fuzzy logics, and shows a strong imbalance between gradients driven by the antecedent and the consequent of the implication. Furthermore, we introduce a new family of fuzzy implications (called sigmoidal implications) to tackle this phenomenon. Finally, we empirically show that it is possible to use Differentiable Fuzzy Logics for semi-supervised learning, and compare how different operators behave in practice. We find that, to achieve the largest performance improvement over a supervised baseline, we have to resort to non-standard combinations of logical operators which perform well in learning, but no longer satisfy the usual logical laws.},
	urldate = {2023-01-04},
	journal = {Artificial Intelligence},
	author = {van Krieken, Emile and Acar, Erman and van Harmelen, Frank},
	month = jan,
	year = {2022},
	note = {arXiv:2002.06100 [cs]},
	pages = {103602},
}

@article{bui_sfcm_2021,
	title = {{SFCM}: {A} {Fuzzy} {Clustering} {Algorithm} of {Extracting} the {Shape} {Information} of {Data}},
	volume = {29},
	issn = {1941-0034},
	shorttitle = {{SFCM}},
	doi = {10.1109/TFUZZ.2020.3014662},
	abstract = {Topological data analysis is a new theoretical trend using topological techniques to mine data. This approach helps determine topological data structures. It focuses on investigating the global shape of data rather than on local information of high-dimensional data. The Mapper algorithm is considered as a sound representative approach in this area. It is used to cluster and identify concise and meaningful global topological data structures that are out of reach for many other clustering methods. In this article, we propose a new method called the Shape Fuzzy C-Means (SFCM) algorithm, which is constructed based on the Fuzzy C-Means algorithm with particular features of the Mapper algorithm. The SFCM algorithm can not only exhibit the same clustering ability as the Fuzzy C-Means but also reveal some relationships through visualizing the global shape of data supplied by the Mapper. We present a formal proof and include experiments to confirm our claims. The performance of the enhanced algorithm is demonstrated through a comparative analysis involving the original algorithm, Mapper, and the other fuzzy set based improved algorithm, F-Mapper, for synthetic and real-world data. The comparison is conducted with respect to output visualization in the topological sense and clustering stability.},
	number = {1},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Bui, Quang-Thinh and Vo, Bay and Snasel, Vaclav and Pedrycz, Witold and Hong, Tzung-Pei and Nguyen, Ngoc-Thanh and Chen, Mu-Yen},
	month = jan,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Big data, Clustering, Data mining, Data visualization, Fuzzy, Fuzzy C-means (FCM) clustering, Mapper, Shape, Shape of data, Topological data analysis (TDA)},
	pages = {75--89},
}

@article{wang_building_2011,
	title = {Building interpretable fuzzy models for high dimensional data analysis in cancer diagnosis},
	volume = {12},
	issn = {1471-2164},
	url = {https://doi.org/10.1186/1471-2164-12-S2-S5},
	doi = {10.1186/1471-2164-12-S2-S5},
	abstract = {Analysing gene expression data from microarray technologies is a very important task in biology and medicine, and particularly in cancer diagnosis. Different from most other popular methods in high dimensional bio-medical data analysis, such as microarray gene expression or proteomics mass spectroscopy data analysis, fuzzy rule-based models can not only provide good classification results, but also easily be explained and interpreted in human understandable terms, by using fuzzy rules. However, the advantages offered by fuzzy-based techniques in microarray data analysis have not yet been fully explored in the literature. Although some recently developed fuzzy-based modeling approaches can provide satisfactory classification results, the rule bases generated by most of the reported fuzzy models for gene expression data are still too large to be easily comprehensible.},
	number = {2},
	urldate = {2023-01-04},
	journal = {BMC Genomics},
	author = {Wang, Zhenyu and Palade, Vasile},
	month = jul,
	year = {2011},
	keywords = {Candidate rule, Fuzzy rule},
	pages = {S5},
}

@book{casillas_interpretability_2013,
	title = {Interpretability {Issues} in {Fuzzy} {Modeling}},
	isbn = {978-3-540-37057-4},
	abstract = {Fuzzy modeling has become one of the most productive and successful results of fuzzy logic. Among others, it has been applied to knowledge discovery, automatic classification, long-term prediction, or medical and engineering analysis. The research developed in the topic during the last two decades has been mainly focused on exploiting the fuzzy model flexibility to obtain the highest accuracy. This approach usually sets aside the interpretability of the obtained models. However, we should remember the initial philosophy of fuzzy sets theory directed to serve the bridge between the human understanding and the machine processing. In this challenge, the ability of fuzzy models to express the behavior of the real system in a comprehensible manner acquires a great importance. This book collects the works of a group of experts in the field that advocate the interpretability improvements as a mechanism to obtain well balanced fuzzy models.},
	language = {en},
	publisher = {Springer},
	author = {Casillas, Jorge and Cordón, O. and Triguero, Francisco Herrera and Magdalena, Luis},
	month = jun,
	year = {2013},
	note = {Google-Books-ID: 7r\_qCAAAQBAJ},
}

@article{figueiredo_design_1999,
	title = {Design of fuzzy systems using neurofuzzy networks},
	volume = {10},
	issn = {1941-0093},
	doi = {10.1109/72.774229},
	abstract = {Introduces a systematic approach for fuzzy system design based on a class of neural fuzzy networks built upon a general neuron model. The network structure is such that it encodes the knowledge learned in the form of if-then fuzzy rules and processes data following fuzzy reasoning principles. The technique provides a mechanism to obtain rules covering the whole input/output space as well as the membership functions (including their shapes) for each input variable. Such characteristics are of utmost importance in fuzzy systems design and application. In addition, after learning, it is very simple to extract fuzzy rules in the linguistic form. The network has universal approximation capability, a property very useful in, e.g., modeling and control applications. Here we focus on function approximation problems as a vehicle to illustrate its usefulness and to evaluate its performance. Comparisons with alternative approaches are also included. Both, non-noisy and noisy data have been studied and considered in the computational experiments. The neural fuzzy network developed here and, consequently, the underlying approach, has shown to provide good results from the accuracy, complexity, and system design points of view.},
	number = {4},
	journal = {IEEE Transactions on Neural Networks},
	author = {Figueiredo, M. and Gomide, F.},
	month = jul,
	year = {1999},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Design methodology, Design optimization, Function approximation, Fuzzy neural network, Fuzzy reasoning, Fuzzy sets, Fuzzy system, Neuro-fuzzy network},
	pages = {815--827},
}

@article{yager_representation_1991,
	title = {The representation of fuzzy relational production rules},
	volume = {1},
	issn = {1573-7497},
	url = {https://doi.org/10.1007/BF00117744},
	doi = {10.1007/BF00117744},
	abstract = {We look at the representation within the framework of the approximate reasoning of relational type rules. A relational production rule consists of a rule in which one of the antecedent requirements involves the satisfaction of a relationship between two variables. An example of this type of rule is if lower and upper bounds are close then the uncertainty is low.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Applied Intelligence},
	author = {Yager, Ronald R.},
	month = jul,
	year = {1991},
	keywords = {Expert systems, Fuzzy sets, Relational antecedents, Uncertainty},
	pages = {35--42},
}

@article{klir_principle_1990,
	title = {A {Principle} of {Uncertainty} and {Information} {Invariance}*},
	volume = {17},
	issn = {0308-1079},
	url = {https://doi.org/10.1080/03081079008935110},
	doi = {10.1080/03081079008935110},
	abstract = {The paper introduces a new principle, referred to as the principle of uncertainty and information invariance, for making transformations between different mathematical theories by which situations under uncertainty can be characterized. This principle requires that the amount of uncertainty (and related information) be preserved under these transformations. The principle is developed in sufficient details for transformations between probability theory and possibility theory under interval, log-interval and ordinal scales. Its broader use is discussed only in general terms and illustrated by an example.},
	number = {2-3},
	urldate = {2023-01-04},
	journal = {International Journal of General Systems},
	author = {KLIR, GEORGE J.},
	month = jun,
	year = {1990},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03081079008935110},
	keywords = {Dempster-Shafer theory, Information, Possibility theory, Principle of uncertainty and information invariance, Probability theory, Transformation scales, Uncertainty},
	pages = {249--275},
}

@incollection{burda_lift_2015,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {Lift {Measure} for {Fuzzy} {Association} {Rules}},
	isbn = {978-3-319-10765-3},
	url = {https://doi.org/10.1007/978-3-319-10765-3_30},
	abstract = {The aim of this paper is to provide a correct definition of lift measure for fuzzy association rules, to study some of it’s interesting mathematical properties, and to provide an algorithm for fast computation of fuzzy lift during the process of fuzzy association rules mining.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Strengthening {Links} {Between} {Data} {Analysis} and {Soft} {Computing}},
	publisher = {Springer International Publishing},
	author = {Burda, Michal},
	editor = {Grzegorzewski, Przemyslaw and Gagolewski, Marek and Hryniewicz, Olgierd and Gil, María Ángeles},
	year = {2015},
	doi = {10.1007/978-3-319-10765-3_30},
	keywords = {Fuzzy association rules, Lift Measure},
	pages = {249--260},
}

@inproceedings{gorrini_self-structuring_1995,
	title = {Self-structuring fuzzy systems for function approximation},
	volume = {2},
	doi = {10.1109/FUZZY.1995.409792},
	abstract = {This paper presents an algorithm developed in a biological spirit and dedicated to the incremental building of fuzzy systems for function approximation. It is called EFUSS (evolving fuzzy systems structure) and aims at automatically and incrementally finding the minimal number of membership functions along with their appropriate shaping. The main mechanisms constituting our algorithm are to: observe the oscillatory tendency of the parameters defining the output part of the fuzzy rules, then detect the most oscillatory one, and finally supply the zone covered by the input of this strongly oscillating rule with a complementary fuzzy rule.{\textless}{\textgreater}},
	booktitle = {Proceedings of 1995 {IEEE} {International} {Conference} on {Fuzzy} {Systems}.},
	author = {Gorrini, V. and Salome, T. and Bersini, H.},
	month = mar,
	year = {1995},
	keywords = {Adaptive, Automatic control, Biological systems, Function approximation, Fuzzy control, Fuzzy systems, Neural network, System identification},
	pages = {919--926 vol.2},
}

@article{wang_self-adaptive_2002,
	title = {Self-adaptive neuro-fuzzy inference systems for classification applications},
	volume = {10},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2002.805880},
	abstract = {This paper presents a self-adaptive neuro-fuzzy inference system (SANFIS) that is capable of self-adapting and self-organizing its internal structure to acquire a parsimonious rule-base for interpreting the embedded knowledge of a system from the given training data set. A connectionist topology of fuzzy basis functions with their universal approximation capability is served as a fundamental SANFIS architecture that provides an elasticity to be extended to all existing fuzzy models whose consequent could be fuzzy term sets, fuzzy singletons, or functions of linear combination of input variables. Without a priori knowledge of the distribution of the training data set, a novel mapping-constrained agglomerative clustering algorithm is devised to reveal the true cluster configuration in a single pass for an initial SANFIS construction, estimating the location and variance of each cluster. Subsequently, a fast recursive linear/nonlinear least-squares algorithm is performed to further accelerate the learning convergence and improve the system performance. Good generalization capability, fast learning convergence and compact comprehensible knowledge representation summarize the strength of SANFIS. Computer simulations for the Iris, Wisconsin breast cancer, and wine classifications show that SANFIS achieves significant improvements in terms of learning convergence, higher accuracy in recognition, and a parsimonious architecture.},
	number = {6},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Wang, Jeen-Shing and Lee, C.S.G.},
	month = dec,
	year = {2002},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Clustering, Convergence, Elasticity, Fuzzy sets, Input variables, Knowledge representation, Neuro-fuzzy network, SANFIS, System performance, Topology},
	pages = {790--802},
}

@article{hsu_nonlinear_2013,
	title = {Nonlinear system control using a self-organizing functional-linked neuro-fuzzy network},
	volume = {73},
	issn = {1573-269X},
	url = {https://doi.org/10.1007/s11071-013-0891-y},
	doi = {10.1007/s11071-013-0891-y},
	abstract = {This study presents a self-organizing functional-linked neuro-fuzzy network (SFNN) for a nonlinear system controller design. An online learning algorithm, which consists of structure learning and parameter learning of a SFNN, is presented. The structure learning is designed to determine the number of fuzzy rules and the parameter learning is designed to adjust the parameters of membership function and corresponding weights. Thus, an adaptive self-organizing functional-linked neuro-fuzzy control (ASFNC) system, which is composed of a computation controller and a robust compensator, is proposed. In the computation controller, a SFNN observer is utilized to approximate the system dynamic and the robust compensator is designed to eliminate the effect of the approximation error introduced by the SFNN observer upon the system stability. Finally, to show the effectiveness of the proposed ASFNC system, it is applied to a chaotic system. The simulation results demonstrate that favorable control performance can be achieved by the proposed ASFNC scheme without any knowledge of the control plants and without requiring preliminary offline tuning of the SFNN observer.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Nonlinear Dynamics},
	author = {Hsu, Chun-Fei},
	month = aug,
	year = {2013},
	keywords = {Adaptive, Chaotic system, Functional-linked neural network, Neural control, Neural-fuzzy network},
	pages = {1631--1643},
}

@article{kasabov_denfis_2002,
	title = {{DENFIS}: dynamic evolving neural-fuzzy inference system and its application for time-series prediction},
	volume = {10},
	issn = {1941-0034},
	shorttitle = {{DENFIS}},
	doi = {10.1109/91.995117},
	abstract = {This paper introduces a new type of fuzzy inference systems, denoted as dynamic evolving neural-fuzzy inference system (DENFIS), for adaptive online and offline learning, and their application for dynamic time series prediction. DENFIS evolve through incremental, hybrid (supervised/unsupervised), learning, and accommodate new input data, including new features, new classes, etc., through local element tuning. New fuzzy rules are created and updated during the operation of the system. At each time moment, the output of DENFIS is calculated through a fuzzy inference system based on m-most activated fuzzy rules which are dynamically chosen from a fuzzy rule set. Two approaches are proposed: (1) dynamic creation of a first-order Takagi-Sugeno-type fuzzy rule set for a DENFIS online model; and (2) creation of a first-order Takagi-Sugeno-type fuzzy rule set, or an expanded high-order one, for a DENFIS offline model. A set of fuzzy rules can be inserted into DENFIS before or during its learning process. Fuzzy rules can also be extracted during or after the learning process. An evolving clustering method (ECM), which is employed in both online and offline DENFIS models, is also introduced. It is demonstrated that DENFIS can effectively learn complex temporal sequences in an adaptive way and outperform some well-known, existing models.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Kasabov, N.K. and Song, Qun},
	month = apr,
	year = {2002},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Adaptive, Clustering, Fuzzy logic, Fuzzy sets, Fuzzy system, Neuro-fuzzy network, Programmable control},
	pages = {144--154},
}

@article{kim_hyfis_1999,
	title = {{HyFIS}: adaptive neuro-fuzzy inference systems and their application to nonlinear dynamical systems},
	volume = {12},
	issn = {0893-6080},
	shorttitle = {{HyFIS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608099000672},
	doi = {10.1016/S0893-6080(99)00067-2},
	abstract = {This paper proposes an adaptive neuro-fuzzy system, HyFIS (Hybrid neural Fuzzy Inference System), for building and optimising fuzzy models. The proposed model introduces the learning power of neural networks to fuzzy logic systems and provides linguistic meaning to the connectionist architectures. Heuristic fuzzy logic rules and input–output fuzzy membership functions can be optimally tuned from training examples by a hybrid learning scheme comprised of two phases: rule generation phase from data; and rule tuning phase using error backpropagation learning scheme for a neural fuzzy system. To illustrate the performance and applicability of the proposed neuro-fuzzy hybrid model, extensive simulation studies of nonlinear complex dynamic systems are carried out. The proposed method can be applied to an on-line incremental adaptive learning for the prediction and control of nonlinear dynamical systems. Two benchmark case studies are used to demonstrate that the proposed HyFIS system is a superior neuro-fuzzy modelling technique.},
	language = {en},
	number = {9},
	urldate = {2023-01-04},
	journal = {Neural Networks},
	author = {Kim, J. and Kasabov, N.},
	month = nov,
	year = {1999},
	keywords = {Adaptive, Fuzzy logic, Knowledge acquisition, Neural networks, Neuro-fuzzy network, Neuro-fuzzy system, Parameter estimation, Structure estimation, Time series},
	pages = {1301--1319},
}

@article{dovzan_implementation_2015,
	title = {Implementation of an {Evolving} {Fuzzy} {Model} ({eFuMo}) in a {Monitoring} {System} for a {Waste}-{Water} {Treatment} {Process}},
	volume = {23},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2014.2379252},
	abstract = {Increasing demands on effluent quality and loads call for an improved control, monitoring, and fault detection of waste-water treatment plants (WWTPs). Improved control and optimization of WWTP lead to increased pollutant removal, a reduced need for chemicals as well as energy savings. An important step toward the optimal functioning of a WWTP is to minimize the influence of sensor faults on the control quality. To achieve this, a fault-detection system should be implemented. In this paper, the idea of using an evolving method as a base for the fault-detection/monitoring system is tested. The system is based on the evolving fuzzy model method. This method allows us to model the nonlinear relations between the variables with the Takagi-Sugeno fuzzy model. The method uses basic evolving mechanisms to add and remove clusters and the adaptation mechanism to adapt the clusters' and local models' parameters. The proposed fault-detection system is tested on measured data from a real WWTP. The results indicate the potential improvement of the WWTP's control during a sensor malfunction.},
	number = {5},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Dovžan, Dejan and Logar, Vito and Škrjanc, Igor},
	month = oct,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Adaptive, Clustering, Covariance matrices, Evolving Fuzzy Model, Evolving mechanisms, Fault detection, Inductors, Monitoring, eFuMo, evolving fuzzy model (eFuMo)},
	pages = {1761--1776},
}

@article{nobile_fuzzy_2018,
	title = {Fuzzy {Self}-{Tuning} {PSO}: {A} settings-free algorithm for global optimization},
	volume = {39},
	issn = {2210-6502},
	shorttitle = {Fuzzy {Self}-{Tuning} {PSO}},
	url = {https://www.sciencedirect.com/science/article/pii/S2210650216303534},
	doi = {10.1016/j.swevo.2017.09.001},
	abstract = {Among the existing global optimization algorithms, Particle Swarm Optimization (PSO) is one of the most effective methods for non-linear and complex high-dimensional problems. Since PSO performance strongly depends on the choice of its settings (i.e., inertia, cognitive and social factors, minimum and maximum velocity), Fuzzy Logic (FL) was previously exploited to select these values. So far, FL-based implementations of PSO aimed at the calculation of a unique settings for the whole swarm. In this work we propose a novel self-tuning algorithm—called Fuzzy Self-Tuning PSO (FST-PSO)—which exploits FL to calculate the inertia, cognitive and social factor, minimum and maximum velocity independently for each particle, thus realizing a complete settings-free version of PSO. The novelty and strength of FST-PSO lie in the fact that it does not require any expertise in PSO functioning, since the behavior of every particle is automatically and dynamically adjusted during the optimization. We compare the performance of FST-PSO with standard PSO, Proactive Particles in Swarm Optimization, Artificial Bee Colony, Covariance Matrix Adaptation Evolution Strategy, Differential Evolution and Genetic Algorithms. We empirically show that FST-PSO can basically outperform all tested algorithms with respect to the convergence speed and is competitive concerning the best solutions found, noticeably with a reduced computational effort.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Swarm and Evolutionary Computation},
	author = {Nobile, Marco S. and Cazzaniga, Paolo and Besozzi, Daniela and Colombo, Riccardo and Mauri, Giancarlo and Pasi, Gabriella},
	month = apr,
	year = {2018},
	keywords = {Adaptive, Fuzzy logic, Particle Swarm Optimization, Self-tuning, Settings-free optimization},
	pages = {70--85},
}

@inproceedings{ballini_recurrent_2010,
	title = {Recurrent fuzzy neural computation: {Modeling}, learning and application},
	shorttitle = {Recurrent fuzzy neural computation},
	doi = {10.1109/FUZZY.2010.5584099},
	abstract = {A novel recurrent neurofuzzy network is developed in this paper. The network model is composed by two structures: a fuzzy system and a neural network. The fuzzy system contains fuzzy neurons modeled using t-norms and s-norms. The neural network is composed by nonlinear elements placed in series with the fuzzy system. The network model implicitly encodes a fuzzy rule-based system and its recurrent multilayered structure performs fuzzy inference. The topology induces a clear relationship between the network structure and the associated fuzzy rule-based system. Network learning involves three main steps. The first step uses a modified vector quantization approach to granulate the input universes. The next step assembles the network connections and their initial, randomly chosen weights. The third step uses two main paradigms to update the network weights: gradient descent and gradient projection method. The recurrent fuzzy neural network is particularly suitable to model nonlinear dynamic systems and to learn sequences. Computational experiment with a classic prediction problem benchmark shows that the fuzzy neural model outperforms a finite impulse response neural network.},
	booktitle = {International {Conference} on {Fuzzy} {Systems}},
	author = {Ballini, Rosangela and Gomide, Fernando},
	month = jul,
	year = {2010},
	note = {ISSN: 1098-7584},
	keywords = {Artificial neural network, Fuzzy neural network, Fuzzy sets, Recurrent neural network},
	pages = {1--6},
}

@inproceedings{wu_knowledge_2006,
	title = {Knowledge {Representation} and {Learning} {Mechanism} {Based} on {Networks} of {Spiking} {Neurons}},
	volume = {4},
	doi = {10.1109/ICSMC.2006.385297},
	abstract = {Knowledge representation is very important in intelligent systems -e.g. for knowledge discovery, data mining, and machine learning. The human brain, a significant intelligent system, works with a huge number of spiking neurons. Based on spiking neuron models a new generation of spiking neural networks (SNNs) has been developed for artificial intelligence systems. SNNs are computationally more powerful than conventional artificial neural networks. In this paper, the spiking neuron model is applied to represent logic rules and fuzzy rules. Based on the STDP (Spike Timing Dependent Plasticity) principle, a new SNN model is proposed for pattern recognition. An efficient learning rule derived from the STDP is applied for self-organizing the input training set efficiently. An example, Animal-Growth-Record, is used to explain the principle of the SNN model. Benchmark data sets are applied to compare the proposed approach with other approaches. As there are very efficient learning rules in the SNN model, the model can be applied not only for fusion of multi-sensory data, but also for data mining in large databases with large numbers of attributes.},
	booktitle = {2006 {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	author = {Wu, QingXiang and Bell, David and Qi, Guilin and Cai, Jianyong},
	month = oct,
	year = {2006},
	note = {ISSN: 1062-922X},
	keywords = {Artificial neural network, Data mining, Fuzzy logic, Intelligent systems, Knowledge representation, Machine learning},
	pages = {2796--2801},
}

@article{peng_spiking_2020,
	title = {Spiking neural {P} systems with inhibitory rules},
	volume = {188},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705119304514},
	doi = {10.1016/j.knosys.2019.105064},
	abstract = {Motivated by the mechanism of inhibitory synapses, a new kind of spiking neural P (SNP) system rules, called inhibitory rules, is introduced in this paper. Based on this, a new variant of SNP systems is proposed, called spiking neural P systems with inhibitory rules (SNP-IR systems). Different from the usual firing rules in SNP systems, the firing condition of an inhibitory rule not only depends on the state of the neuron associated with the rule but also is related to the states of other neurons. Moreover, from the perspective of topological structure, the new variant is shown as a directed graph with inhibitory arcs, and therefore seems to have more powerful control. The computational completeness of SNP-IR systems is discussed. In particular, it is proved that SNP-IR systems are Turing universal number accepting/generating devices. Moreover, we obtain a small universal function-computing device for SNP-IR systems consisting of 100 neurons.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Knowledge-Based Systems},
	author = {Peng, Hong and Li, Bo and Wang, Jun and Song, Xiaoxiao and Wang, Tao and Valencia-Cabrera, Luis and Pérez-Hurtado, Ignacio and Riscos-Núñez, Agustín and Pérez-Jiménez, Mario J.},
	month = jan,
	year = {2020},
	keywords = {Inhibitory rules, Inhibitory synapse, Membrane computing, Spiking neural P system},
	pages = {105064},
}

@article{wang_behavior_2008,
	series = {Neural {Networks}: {Algorithms} and {Applications}},
	title = {A behavior controller based on spiking neural networks for mobile robots},
	volume = {71},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231207003025},
	doi = {10.1016/j.neucom.2007.08.025},
	abstract = {Spiking neural networks (SNNs), as the third generation of artificial neural networks, have unique advantages and are good candidates for robot controllers. A behavior controller based on a spiking neural network is designed for mobile robots to avoid obstacles using ultrasonic sensory signals. Detailed structure and implementation of the controller are discussed. In the controller the integrated-and-firing model is used and the SNN is trained by the Hebbian learning algorithm. Under the framework of SNNs, fewer neurons are employed in the controller than those of the classical neural networks (NNs). Experimental results show that the proposed controller is effective and is easy to implement.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {Neurocomputing},
	author = {Wang, Xiuqing and Hou, Zeng-Guang and Zou, Anmin and Tan, Min and Cheng, Long},
	month = jan,
	year = {2008},
	keywords = {Hebbian learning, Mobile robot, Obstacle avoidance, Spiking neural network, Ultrasonic data},
	pages = {655--666},
}

@inproceedings{kubota_genetic_2005,
	title = {Genetic algorithm for a fuzzy spiking neural network of a mobile robot},
	doi = {10.1109/CIRA.2005.1554297},
	abstract = {It is very difficult to design the learning structure of a robot beforehand in an unknown and dynamic environment, because the dynamics of the environment is unknown. Therefore, this paper proposes a fuzzy spiking neural network (FSNN) for behavior learning of a mobile robot. Furthermore, the network structure of the FSNN should be adaptive to the environmental condition. In this paper, we apply a steady-state genetic algorithm for acquiring the suitable network structure through the interaction with the environment. The simulation results show the robot can update the network structure and learn the weights of FSNN according to the spatio-temporal context of the facing environment.},
	booktitle = {2005 {International} {Symposium} on {Computational} {Intelligence} in {Robotics} and {Automation}},
	author = {Kubota, N. and Sasaki, H.},
	month = jun,
	year = {2005},
	keywords = {Artificial neural network, Behavior learning, Fuzzy control, Fuzzy neural network, Fuzzy system, Genetic algorithm, Learning algorithm, Robot control, Spiking neural network},
	pages = {321--326},
}

@article{song_design_2016,
	title = {Design of logic gates using spiking neural {P} systems with homogeneous neurons and astrocytes-like control},
	volume = {372},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516306247},
	doi = {10.1016/j.ins.2016.08.055},
	abstract = {In biological nervous systems, the operation of interacting neurons depends largely on the regulation from astrocytes. Inspired by this biological phenomenon, spiking neural P systems, i.e. SN P systems, with astrocyte-like control were proposed and were proven to have “Turing completeness” as computing models. In this work, the application of such systems for creating logical operators is investigated. Specifically, it is obtained in a constructive way that SN P systems with astrocyte-like control can synthesize the operations of Boolean logic gates, i.e. AND, OR, NOT, NOR, XOR and NAND gates. The resulting systems are simple and homogeneous, which means only one type of neuron with a unique spiking rule is used. With these neural-like logic gates, more complex Boolean circuits with cascade connections can be constructed. As such, they can be used to implement finite computing devices, such as the finite transducers. These results demonstrate a novel method of constructing logic circuits that work in a neural-like manner, as well as shed some lights on potential directions of designing neural circuits theoretically.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Song, Tao and Zheng, Pan and Dennis Wong, M. L. and Wang, Xun},
	month = dec,
	year = {2016},
	keywords = {Astrocytes-like control, Bio-inspired computing, Boolean circuits, Logic gates, Spiking neural P system},
	pages = {380--391},
}

@article{song_spiking_2021,
	title = {Spiking neural {P} systems with autapses},
	volume = {570},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025521003807},
	doi = {10.1016/j.ins.2021.04.051},
	abstract = {Inspired by the structure and communication method of neural systems, a parallel computing model, spiking neural P systems (SN P systems, for short), was proposed in 2006. A new class of SN P systems, SN P systems with autapses (SNP-AU systems), is presented in this work. Autapses are a special kind of synapses, connecting the axon of a neuron onto itself. We prove that SNP-AU systems can generate Turing-computable numbers, through the simulation of the modules of universal register machines. This result improves significantly the results given by classical SN P systems in terms of the number of neurons and rules, while preserving simplicity and power to a reasonable extent. Moreover, we construct an SNP-AU system using 53 neurons, proving its universality for computing functions. Finally, going beyond the design of the building blocks of register machines, a whole universal machine is provided. Thus, a simulator is developed and used to check the correctness of two universal SNP-AU systems proposed in this paper, complementing the theoretical proof with the experimental validation of our systems with respect to the reference example appearing in the foundational paper of small register machines.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Song, Xiaoxiao and Valencia-Cabrera, Luis and Peng, Hong and Wang, Jun},
	month = sep,
	year = {2021},
	keywords = {Autapses, Membrane computing, Spiking neural P system, Universality},
	pages = {383--402},
}

@misc{noauthor_spiking_nodate,
	title = {Spiking {Neural} {Networks}, the {Next} {Generation} of {Machine} {Learning} {\textbar} by {Devin} {Soni} {\textbar} {Towards} {Data} {Science}},
	url = {https://towardsdatascience.com/spiking-neural-networks-the-next-generation-of-machine-learning-84e167f4eb2b},
	urldate = {2023-01-04},
	keywords = {Spiking neural network},
}

@article{ghosh-dastidar_spiking_2009,
	title = {Spiking neural networks},
	volume = {19},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0129065709002002},
	doi = {10.1142/S0129065709002002},
	abstract = {Most current Artificial Neural Network (ANN) models are based on highly simplified brain dynamics. They have been used as powerful computational tools to solve complex pattern recognition, function estimation, and classification problems. ANNs have been evolving towards more powerful and more biologically realistic models. In the past decade, Spiking Neural Networks (SNNs) have been developed which comprise of spiking neurons. Information transfer in these neurons mimics the information transfer in biological neurons, i.e., via the precise timing of spikes or a sequence of spikes. To facilitate learning in such networks, new learning algorithms based on varying degrees of biological plausibility have also been developed recently. Addition of the temporal dimension for information encoding in SNNs yields new insight into the dynamics of the human brain and could result in compact representations of large neural networks. As such, SNNs have great potential for solving complicated time-dependent pattern recognition problems because of their inherent dynamic representation. This article presents a state-of-the-art review of the development of spiking neurons and SNNs, and provides insight into their evolution as the third generation neural networks.},
	number = {04},
	urldate = {2023-01-04},
	journal = {International Journal of Neural Systems},
	author = {Ghosh-Dastidar, Samanwoy and Adeli, Hojjat},
	month = aug,
	year = {2009},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {Information encoding, Learning algorithm, Spiking neural network, Spiking neuron, Supervised learning, Unsupervised learning},
	pages = {295--308},
}

@inproceedings{wang_knowledge_2010,
	title = {Knowledge representation using fuzzy spiking neural {P} system},
	doi = {10.1109/BICTA.2010.5645191},
	abstract = {This paper presents a fuzzy spiking neural P system (FSN P system) to represent the fuzzy production rules in a knowledge base of a rule-based system, where the certainty factors of fuzzy production rules and the truth values of propositions are described by trapezoidal fuzzy numbers. In the proposed FSN P system, the definition of traditional neurons has been extended. The neurons are divided into two types: proposition neurons and rule neurons; the content of each neuron is a trapezoidal fuzzy number in instead of an integer. Also the fuzzy reasoning process can be modeled by the proposed FSN P system.},
	booktitle = {2010 {IEEE} {Fifth} {International} {Conference} on {Bio}-{Inspired} {Computing}: {Theories} and {Applications} ({BIC}-{TA})},
	author = {Wang, Tao and Wang, Jun and Peng, Hong and Deng, Yanli},
	month = sep,
	year = {2010},
	keywords = {Fuzzy reasoning, Fuzzy sets, Fuzzy spiking neural P system, Knowledge representation, Trapezoidal fuzzy number},
	pages = {586--590},
}

@article{zhang_optimization_2014,
	title = {An optimization spiking neural p system for approximately solving combinatorial optimization problems},
	volume = {24},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0129065714400061},
	doi = {10.1142/S0129065714400061},
	abstract = {Membrane systems (also called P systems) refer to the computing models abstracted from the structure and the functioning of the living cell as well as from the cooperation of cells in tissues, organs, and other populations of cells. Spiking neural P systems (SNPS) are a class of distributed and parallel computing models that incorporate the idea of spiking neurons into P systems. To attain the solution of optimization problems, P systems are used to properly organize evolutionary operators of heuristic approaches, which are named as membrane-inspired evolutionary algorithms (MIEAs). This paper proposes a novel way to design a P system for directly obtaining the approximate solutions of combinatorial optimization problems without the aid of evolutionary operators like in the case of MIEAs. To this aim, an extended spiking neural P system (ESNPS) has been proposed by introducing the probabilistic selection of evolution rules and multi-neurons output and a family of ESNPS, called optimization spiking neural P system (OSNPS), are further designed through introducing a guider to adaptively adjust rule probabilities to approximately solve combinatorial optimization problems. Extensive experiments on knapsack problems have been reported to experimentally prove the viability and effectiveness of the proposed neural system.},
	number = {05},
	urldate = {2023-01-04},
	journal = {International Journal of Neural Systems},
	author = {Zhang, Gexiang and Rong, Haina and Neri, Ferrante and Pérez-Jiménez, Mario J.},
	month = aug,
	year = {2014},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {Extended spiking neural P system, Knapsack problem, Membrane computing, Optimization spiking neural P system, Spiking neural P system},
	pages = {1440006},
}

@inproceedings{chen_fuzzy_1995,
	title = {Fuzzy perceptron learning and its application to classifiers with numerical data and linguistic knowledge},
	volume = {6},
	doi = {10.1109/ICNN.1995.487284},
	abstract = {This paper proposes a fuzzy perceptron neural network learning algorithm for classifiers that use expert knowledge represented by fuzzy if-then rules as well as numerical data. We extend the conventional linear perceptron network to a second-order one that provides much more discrimination flexibility. In order to handle linguistic variables in neural networks, fuzzy set levels are incorporated into perceptron neural learning. At different levels of the input fuzzy number, the fuzzy perceptron algorithm is derived from the fuzzy output function and the corresponding nonfuzzy target output that indicates the correct class of the fuzzy input vector. Moreover, the pocket algorithm is modified according to our fuzzy perceptron learning scheme and called the fuzzy pocket algorithm, to solve nonseparability problems, such as overlapping fuzzy inputs. Simulation results are provided to demonstrate the power of the proposed algorithm.},
	booktitle = {Proceedings of {ICNN}'95 - {International} {Conference} on {Neural} {Networks}},
	author = {Chen, Jia-Lin and Chang, Jyh-Yeong},
	month = nov,
	year = {1995},
	keywords = {Artificial neural network, Classification, Fuzzy control, Fuzzy neural network, Fuzzy set theory, Fuzzy sets, Fuzzy system, Level set, Multi-layer neural network},
	pages = {3129--3133 vol.6},
}

@inproceedings{buja_neural_1993,
	title = {Neural network implementation of a fuzzy logic controller},
	doi = {10.1109/IECON.1993.339042},
	abstract = {Fuzzy logic is an attractive technique for plant control but suffers from complex data processing. A solution to this problem is here presented and consists in implementing a fuzzy logic controller (FLC) on a neural network (NN). As an example, a DC drive is considered. After designing a FLC for controlling the drive speed, a NN is trained by supervision to learn the input-output relationship of the FLC. It is found that a NN with few neurons implements the relationship very well. Equipment is then set up to test the NN control. The experimental responses obtained from the drive demonstrate the effectiveness of the solution.{\textless}{\textgreater}},
	booktitle = {Proceedings of {IECON} '93 - 19th {Annual} {Conference} of {IEEE} {Industrial} {Electronics}},
	author = {Buja, G.S.},
	month = nov,
	year = {1993},
	keywords = {Artificial neural network, Fuzzy logic, Fuzzy reasoning},
	pages = {414--417 vol.1},
}

@article{oduro-gyimah_application_2018,
	title = {Application of {CANFIS} {Model} in the {Prediction} of {Multiple}-{Input} {Telecommunication} {Network} {Traffic}},
	volume = {1},
	abstract = {Telecommunication network traffic prediction is an important approach that ensure efficient network planning and management. Telecommunication network traffic is univariate and prediction models have mostly been concentrated on single-input and single-output traffic. This study proposes a new approach, the multiple-input multiple-output Coactive Neuro-Fuzzy Inference System (CANFIS) model to predict a five time span univariate hourly, daily, weekly, monthly and quarterly time series of 3G downlink traffic simultaneously. In the modelling process several parameters were used in the configuration of the network. The best model for predicting five-input telecommunication traffic was CANFIS (5-2-5) which employed a Bell membership function, Axon transfer function and Momentum learning rule and the membership function per input of 2. The performance of the model was evaluated by comparing the predicted traffic with actual traffic obtained from a 3G network operator and the results indicate a minimum accuracy measure value of MSE = 0.000486, NRMSE = 0.01120 and percent error = 12.33\%.},
	author = {Oduro-Gyimah, Francis and Boateng, Kwame},
	month = nov,
	year = {2018},
	keywords = {ANFIS},
	pages = {1--9},
}

@article{chiu_efficient_1997,
	title = {An {Efficient} {Method} for {Extracting} {Fuzzy} {Classification} {Rules} from {High} {Dimensional} {Data}.},
	volume = {1},
	abstract = {We present an efficient method for extracting fuzzy classification rules from high dimensional data. A cluster estimation method called subtractive clustering is used to efficiently extract rules from a high dimensional feature space. A complementary search method can quickly identify the important input features from the resultant high dimensional fuzzy classifier, and thus provides the ability to quickly generate a simpler, more robust fuzzy classifier that uses a minimal number of input features. These methods are illustrated through the benchmark iris data and through two aerospace applications.},
	journal = {JACIII},
	author = {Chiu, Stephen},
	month = jan,
	year = {1997},
	keywords = {Classification, Subtractive clustering, Unsupervised learning},
	pages = {31--36},
}

@article{brouwer_fuzzy_1999,
	title = {A {Fuzzy} {Neuron} with {Binary} {Input} and its {Training} {Algorithm}},
	volume = {9},
	issn = {1573-773X},
	url = {https://doi.org/10.1023/A:1018663627241},
	doi = {10.1023/A:1018663627241},
	abstract = {This paper is concerned with a proposal for a fuzzy artificial neuron with bi-nary input. The fuzzy neuron is based on fuzzy logic in that each component of the input vector is compared to a number which represent the membership value for a 0 in that position. The results of the comparisons are then combined using a generalized mean function to produce a single number which is compared to a threshold as in the case of a perceptron consisting of a linear combiner with hard limiting function. A training algorithm is developed based on an algorithm for linear inequalities described by Ho and Kashyap in a paper titled ‘An Algorithm for Linear Inequalities and its Applications’. The results obtained by simulation look promising.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Neural Processing Letters},
	author = {Brouwer, Roelof K.},
	month = feb,
	year = {1999},
	keywords = {Fuzzy neural network, Fuzzy neuron, Fuzzy perceptron, Fuzzy sets},
	pages = {25--33},
}

@article{liu_integrating_nodate,
	title = {Integrating {Classification} and {Association} {Rule} {Mining}},
	abstract = {Classification rule mining aims to discover a small set of rules in the database that forms an accurate classifier. Association rule mining finds all the rules existing in the database that satisfy some minimum support and minimum confidence constraints. For association rule mining, the target of discovery is not pre-determined, while for classification rule mining there is one and only one predetermined target. In this paper, we propose to integrate these two mining techniques. The integration is done by focusing on mining a special subset of association rules, called class association rules (CARs). An efficient algorithm is also given for building a classifier based on the set of discovered CARs. Experimental results show that the classifier built this way is, in general, more accurate than that produced by the state-of-the-art classification system C4.5. In addition, this integration helps to solve a number of problems that exist in the current classification systems.},
	language = {en},
	author = {Liu, Bing and Hsu, Wynne and Ma, Yiming},
	keywords = {Association rule mining},
}

@misc{sabour_dynamic_2017,
	title = {Dynamic {Routing} {Between} {Capsules}},
	url = {http://arxiv.org/abs/1710.09829},
	abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E.},
	month = nov,
	year = {2017},
	note = {arXiv:1710.09829 [cs]},
	keywords = {Capsule network},
}

@article{g_reduct_2007,
	title = {Reduct {Generation} in {Information} {Systems}.},
	volume = {14},
	abstract = {In any information system, the reducts are useful in classifying data. Janusz Starzyk developed an algorithm for computing reducts using strong equivalence and the law of expansion on the data. However, implementation of this algorithm is cumbersome for huge volume of data. This paper deals with a technique for obtaining the reduct of the entire system by partitioning it into two with respect to records and obtaining the reducts of the two subsystems and the 'between reducts'. Further, it also deals with a technique for combining the reducts computed at the clients to obtain global reducts. Moreover, for the huge volume of data, computation of the reduct is NP-hard. Hence, in this paper, the system is subdivided into two subsystems with respect to records and the reducts of each subsystem and the 'relational reduct' are found. Using them, in section VIII, we modify the reduct generation algorithm to compute the reduct of the entire system. First, we shall discuss the elimination method, which is useful in finding the reducts. In this method it is necessary to check all possible combination of data to find the reduct. Hence it is effective only in a system with limited number of records and attributes},
	journal = {Engineering Letters},
	author = {G, Ganesan and Durairaj, Latha and Rao, C.},
	month = jan,
	year = {2007},
	keywords = {Rough sets},
	pages = {36--41},
}

@inproceedings{van_rijsbergen_hard_1994,
	address = {London},
	title = {Hard and {Soft} {Sets}},
	isbn = {978-3-540-19885-7 978-1-4471-3238-7},
	url = {http://link.springer.com/10.1007/978-1-4471-3238-7_15},
	doi = {10.1007/978-1-4471-3238-7_15},
	abstract = {In this paper I would like to make some remarks on the concept of a set in the context of some recent developments concerning vagueness, imprecision and uncertainty.},
	urldate = {2023-01-04},
	publisher = {Springer London},
	author = {Pawlak, Zdzislaw},
	editor = {van Rijsbergen, C. J. and Ziarko, Wojciech P.},
	year = {1994},
	doi = {10.1007/978-1-4471-3238-7_15},
	note = {Book Title: Rough Sets, Fuzzy Sets and Knowledge Discovery
Series Title: Workshops in Computing},
	keywords = {Hard sets, Soft sets},
	pages = {130--135},
}

@book{jacob_handbook_2016,
	title = {Handbook of {Research} on {Generalized} and {Hybrid} {Set} {Structures} and {Applications} for {Soft} {Computing}},
	isbn = {978-1-4666-9799-7},
	abstract = {Successful development of effective computational systems is a challenge for IT developers across sectors due to uncertainty issues that are inherently present within computational problems. Soft computing proposes one such solution to the problem of uncertainty through the application of generalized set structures including fuzzy sets, rough sets, and multisets.The Handbook of Research on Generalized and Hybrid Set Structures and Applications for Soft Computing presents double blind peer-reviewed and original research on soft computing applications for solving problems of uncertainty within the computing environment. Emphasizing essential concepts on generalized and hybrid set structures that can be applied across industries for complex problem solving, this timely resource is essential to engineers across disciplines, researchers, computer scientists, and graduate-level students.},
	language = {en},
	publisher = {IGI Global},
	author = {Jacob, Sunil, John},
	month = apr,
	year = {2016},
	note = {Google-Books-ID: NDwBDAAAQBAJ},
	keywords = {Soft sets},
}

@inproceedings{lin_set_1996,
	title = {A set theory for soft computing: a unified view of fuzzy sets via neighborboods},
	volume = {2},
	shorttitle = {A set theory for soft computing},
	doi = {10.1109/FUZZY.1996.552338},
	abstract = {The notion of fuzzy is context dependent, so for each context very often there is a fuzzy theory. Present papers use the notion of neighborhood systems to unify them. A neighborhood system is an association that assigns to each datum a list of data (a neighborhood). Rough sets and topological spaces are special cases. A "real world" fuzzy set should allow small amount of perturbation, so it should have an elastic membership function. Mathematically, such an elastic membership function can be expressed by a highly structured subset of membership function space. Structured sets can be singletons, equivalence classes, neighborhoods, or their fuzzified versions. This paper proposed that fuzzy sets should be abstractly defined by such structures and are termed soft sets (sofsets). Based on such structures, W-sofset, F-sofset, P-sofset, B-sofset, C-sofset, N-sofset, FP-sofset, and FF-sofsets have been identified. In this sequence, a predecessor is always a special case of a successor. Each type represents some implicit form of classical fuzzy theory. It is hoped that such a unified view will provide a useful set theory for soft computing.},
	booktitle = {Proceedings of {IEEE} 5th {International} {Fuzzy} {Systems}},
	author = {Lin, T.Y.},
	month = sep,
	year = {1996},
	keywords = {Elasticity, Fuzzy sets, Geometry, Rough sets, Set theory, Soft sets},
	pages = {1140--1146 vol.2},
}

@article{maji_application_2002,
	title = {An application of soft sets in a decision making problem},
	volume = {44},
	issn = {08981221},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S089812210200216X},
	doi = {10.1016/S0898-1221(02)00216-X},
	language = {en},
	number = {8-9},
	urldate = {2023-01-04},
	journal = {Computers \& Mathematics with Applications},
	author = {Maji, P.K. and Roy, A.R. and Biswas, R.},
	month = oct,
	year = {2002},
	keywords = {Soft sets},
	pages = {1077--1083},
}

@misc{noauthor_towards_nodate,
	title = {Towards {Explainable} {Fuzzy} {AI}: {Concepts}, {Paradigms}, {Tools}, and {Techniques}},
	author = {{Kreinovich} {Vladik}},
	shorttitle = {Towards {Explainable} {Fuzzy} {AI}},
	url = {http://www.lavoisier.eu/books/note.asp?ouvrage=4731215},
	abstract = {Description of Towards Explainable Fuzzy AI: Concepts, Paradigms, Tools, and Techniques Kreinovich Vladik},
	language = {en},
	year = {2022},
	urldate = {2023-01-04},
	journal = {Lavoisier bookseller},
	keywords = {Explainable AI (XAI), Fuzzy},
}

@incollection{rayz_why_2022,
	address = {Cham},
	title = {Why {Fuzzy} {Techniques} in {Explainable} {AI}? {Which} {Fuzzy} {Techniques} in {Explainable} {AI}?},
	volume = {258},
	isbn = {978-3-030-82098-5 978-3-030-82099-2},
	shorttitle = {Why {Fuzzy} {Techniques} in {Explainable} {AI}?},
	url = {https://link.springer.com/10.1007/978-3-030-82099-2_7},
	abstract = {One of big challenges of many state-of-the-art AI techniques such as deep learning is that their results do not come with any explanations – and, taking into account that some of the resulting conclusions and recommendations are far from optimal, it is difﬁcult to distinguish good advice from bad one. It is therefore desirable to come up with explainable AI. In this paper, we argue that fuzzy techniques are a proper way to this explainability, and we also analyze which fuzzy techniques are most appropriate for this purpose. Interestingly, it turns out that the answer depends on what problem we are solving: e.g., different “and”- and “or”-operations are preferable when we are controlling a single object and when we are controlling a group of objects.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Explainable {AI} and {Other} {Applications} of {Fuzzy} {Techniques}},
	publisher = {Springer International Publishing},
	author = {Cohen, Kelly and Bokati, Laxman and Ceberio, Martine and Kosheleva, Olga and Kreinovich, Vladik},
	editor = {Rayz, Julia and Raskin, Victor and Dick, Scott and Kreinovich, Vladik},
	year = {2022},
	doi = {10.1007/978-3-030-82099-2_7},
	note = {Series Title: Lecture Notes in Networks and Systems},
	keywords = {Explainable AI (XAI), Fuzzy},
	pages = {74--78},
}

@article{hagras_towards_nodate,
	title = {Towards {Human} {Understandable} {Explainable} {AI}},
	abstract = {The recent increases in computing power coupled with rapid growth in the availability and quantity of data have resulted in a resurgence of interest in the theory and applications of Artificial intelligence (AI). However, the use of complex AI algorithms like Deep Learning, Random Forests, etc., could result in a lack of transparency to users which is termed black/opaque box models. Thus, For AI to be confidently rolled out by industries and governments, there is a need for greater transparency in explaining the AI decision making process to users to generate “White /Transparent Box” models which can also be termed Explainable AI (XAI). The paper reviews the need for XAI, the efforts to realise XAI and some areas which needs further exploration (like type-2 fuzzy logic systems) to realise XAI systems which could be fully understood and analysed by the lay user.},
	language = {en},
	author = {Hagras, Hani},
	keywords = {Explainable AI (XAI), Human understandable},
}

@misc{hohman_summit_2019,
	title = {Summit: {Scaling} {Deep} {Learning} {Interpretability} by {Visualizing} {Activation} and {Attribution} {Summarizations}},
	shorttitle = {Summit},
	url = {http://arxiv.org/abs/1904.02323},
	abstract = {Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Hohman, Fred and Park, Haekyu and Robinson, Caleb and Chau, Duen Horng},
	month = sep,
	year = {2019},
	note = {arXiv:1904.02323 [cs]},
	keywords = {Deep Learning, Interpretability},
}

@incollection{mencar_paving_2019,
	title = {Paving the {Way} to {Explainable} {Artificial} {Intelligence} with {Fuzzy} {Modeling}: {Tutorial}},
	isbn = {978-3-030-12543-1},
	shorttitle = {Paving the {Way} to {Explainable} {Artificial} {Intelligence} with {Fuzzy} {Modeling}},
	abstract = {Explainable Artificial Intelligence (XAI) is a relatively new approach to AI with special emphasis to the ability of machines to give sound motivations about their decisions and behavior. Since XAI is human-centered, it has tight connections with Granular Computing (GrC) in general, and Fuzzy Modeling (FM) in particular. However, although FM has been originally conceived to provide easily understandable models to users, this property cannot be taken for grant but it requires careful design choices. Furthermore, full integration of FM into XAI requires further processing, such as Natural Language Generation (NLG), which is a matter of current research.},
	author = {Mencar, Corrado and Alonso, Jose},
	month = jan,
	year = {2019},
	doi = {10.1007/978-3-030-12544-8_17},
	keywords = {Explainable AI (XAI), Fuzzy modeling},
	pages = {215--227},
}

@misc{noauthor_machine_2020,
	title = {Machine {Learning} {Model} {Explanation} using {Shapley} {Values}},
	url = {https://onezero.blog/machine-learning-model-explanation-using-shapley-values/},
	abstract = {Learn how to interpret a BlackBox model using SHAP (SHapley Additive exPlanations)},
	language = {en-US},
	urldate = {2023-01-04},
	journal = {One Zero Blog},
	month = sep,
	year = {2020},
	keywords = {Explainable AI (XAI)},
}

@article{gacto_interpretability_2011,
	series = {Special {Issue} on {Interpretable} {Fuzzy} {Systems}},
	title = {Interpretability of linguistic fuzzy rule-based systems: {An} overview of interpretability measures},
	volume = {181},
	issn = {0020-0255},
	shorttitle = {Interpretability of linguistic fuzzy rule-based systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025511001034},
	doi = {10.1016/j.ins.2011.02.021},
	abstract = {Linguistic fuzzy modelling, developed by linguistic fuzzy rule-based systems, allows us to deal with the modelling of systems by building a linguistic model which could become interpretable by human beings. Linguistic fuzzy modelling comes with two contradictory requirements: interpretability and accuracy. In recent years the interest of researchers in obtaining more interpretable linguistic fuzzy models has grown. Whereas the measures of accuracy are straightforward and well-known, interpretability measures are difficult to define since interpretability depends on several factors; mainly the model structure, the number of rules, the number of features, the number of linguistic terms, the shape of the fuzzy sets, etc. Moreover, due to the subjectivity of the concept the choice of appropriate interpretability measures is still an open problem. In this paper, we present an overview of the proposed interpretability measures and techniques for obtaining more interpretable linguistic fuzzy rule-based systems. To this end, we will propose a taxonomy based on a double axis: “Complexity versus semantic interpretability” considering the two main kinds of measures; and “rule base versus fuzzy partitions” considering the different components of the knowledge base to which both kinds of measures can be applied. The main aim is to provide a well established framework in order to facilitate a better understanding of the topic and well founded future works.},
	language = {en},
	number = {20},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Gacto, M. J. and Alcalá, R. and Herrera, F.},
	month = oct,
	year = {2011},
	keywords = {Complexity, Interpretability measures, Linguistic fuzzy rule-based systems, Semantic interpretability},
	pages = {4340--4360},
}

@inproceedings{pierrard_learning_2018,
	address = {Rio de Janeiro, Brazil},
	title = {Learning {Fuzzy} {Relations} and {Properties} for {Explainable} {Artificial} {Intelligence}},
	url = {https://hal.archives-ouvertes.fr/hal-02425453},
	doi = {10.1109/FUZZ-IEEE.2018.8491538},
	abstract = {The goal of explainable artificial intelligence is to solve problems in a way that humans can understand how it does it. However, few approaches have been proposed so far and some of them lay more emphasis on interpretabil-ity than on explainability. In this paper, we propose an approach that is based on learning fuzzy relations and fuzzy properties. We extract frequent relations from a dataset to generate an explained decision. Our approach can deal with different problems, such as classification or annotation. A model was built to perform explained classification on a toy dataset that we generated. It managed to correctly classify examples while providing convincing explanations. A few areas for improvement have been spotted, such as the need to filter relations and properties before or while learning them in order to avoid useless computations.},
	urldate = {2023-01-04},
	booktitle = {2018 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	author = {Pierrard, Régis and Poli, Jean-Philippe and Hudelot, Céline},
	month = jul,
	year = {2018},
	keywords = {Explainable AI (XAI)},
}

@inproceedings{razak_interpretability_2017,
	title = {Interpretability indices for hierarchical fuzzy systems},
	doi = {10.1109/FUZZ-IEEE.2017.8015616},
	abstract = {Hierarchical fuzzy systems (HFSs) have been shown to have the potential to improve interpretability of fuzzy logic systems (FLSs). In recent years, a variety of indices have been proposed to measure the interpretability of FLSs such as the Nauck index and Fuzzy index. However, interpretability indices associated with HFSs have not so far been discussed. The structure of HFSs, with multiple layers, subsystems, and varied topologies, is the main challenge in constructing interpretability indices for HFSs. Thus, the comparison of interpretability between FLSs and HFSs-even at the index level-is still subject to open discussion. This paper begins to address these challenges by introducing extensions to the FLS Nauck and Fuzzy interpretability indices for HFSs. Using the proposed indices, we explore the concept of interpretability in relation to the different structures in FLSs and HFSs. Initial experiments on benchmark datasets show that based on the proposed indices, HFSs with equivalent function to FLSs produce higher indices, i.e. are more interpretable than their corresponding FLSs.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	author = {Razak, T. R. and Garibaldi, J. M. and Wagner, C. and Pourabdollah, A. and Soria, D.},
	month = jul,
	year = {2017},
	note = {ISSN: 1558-4739},
	keywords = {Complexity, Fuzzy logic, Fuzzy system, Hafnium, Topology},
	pages = {1--6},
}

@article{maddox_fuzzy_1983,
	title = {Fuzzy sets make fuzzy logic},
	volume = {306},
	copyright = {1983 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/306637a0},
	doi = {10.1038/306637a0},
	abstract = {Artificial intelligence has become all the rage, often by government sponsorship. The concept of fuzziness, while interesting, points to few distinctive benefits. Understanding remains the need.},
	language = {en},
	number = {5944},
	urldate = {2023-01-04},
	journal = {Nature},
	author = {Maddox, John},
	month = dec,
	year = {1983},
	note = {Number: 5944
Publisher: Nature Publishing Group},
	pages = {637--637},
}

@article{wang_explaining_2021,
	title = {Explaining the {Behavior} of {Neuron} {Activations} in {Deep} {Neural} {Networks}},
	volume = {111},
	issn = {1570-8705},
	url = {https://www.sciencedirect.com/science/article/pii/S1570870520306958},
	doi = {10.1016/j.adhoc.2020.102346},
	abstract = {Deep Neural Networks has shown superior performance in various applications. But it is often seen as black box in real world applications, which is challenging to explain from the viewpoint of humans. It is important to understand the behavior of deep neural networks so as to trust the decision made and improve the classification accuracy of deep neural networks. In this study, the information theoretical analysis is used to investigate the behavior of layer-wise neurons in deep neural networks. The activation patterns of individual neurons in fully connected layers can provide insights for the performance of the neural network model. The behavior of neuron activation is investigated based on state-of-art classification network model. We study and compare the layer-wise pattern of neurons activation in fully connected layers given the same image input. Experiments are conducted on various data sets. We find that in a well trained classification model, the randomness level of the neurons activation pattern is reduced with the depth of the fully connected layers. This means that the neuron activation patterns of deep layers is more stable than that of shallow layers. The results in this study can also answer the question of how many layers are needed to avoid overfitting in deep neural networks. Corresponding experiments are conducted to validate the assumptions.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Ad Hoc Networks},
	author = {Wang, Longwei and Wang, Chengfei and Li, Yupeng and Wang, Rui},
	month = feb,
	year = {2021},
	keywords = {Behavior analysis, Explaining neural networks},
	pages = {102346},
}

@inproceedings{chen_explaining_2019,
	address = {Seoul, Korea (South)},
	title = {Explaining {Neural} {Networks} {Semantically} and {Quantitatively}},
	isbn = {978-1-72814-803-8},
	url = {https://ieeexplore.ieee.org/document/9008520/},
	doi = {10.1109/ICCV.2019.00928},
	abstract = {This paper presents a method to pursue a semantic and quantitative explanation for the knowledge encoded in a convolutional neural network (CNN). The estimation of the speciﬁc rationale of each prediction made by the CNN presents a key issue of understanding neural networks, and it is of signiﬁcant values in real applications. In this study, we propose to distill knowledge from the CNN into an explainable additive model, which explains the CNN prediction quantitatively. We discuss the problem of the biased interpretation of CNN predictions. To overcome the biased interpretation, we develop prior losses to guide the learning of the explainable additive model. Experimental results have demonstrated the effectiveness of our method.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Chen, Runjin and Chen, Hao and Huang, Ge and Ren, Jie and Zhang, Quanshi},
	month = oct,
	year = {2019},
	keywords = {Explaining neural networks},
	pages = {9186--9195},
}

@article{mishra_explainable_2022,
	title = {Explainable {Fuzzy} {AI} {Challenge} 2022: {Winner}’s {Approach} to a {Computationally} {Efficient} and {Explainable} {Solution}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2075-1680},
	shorttitle = {Explainable {Fuzzy} {AI} {Challenge} 2022},
	url = {https://www.mdpi.com/2075-1680/11/10/489},
	doi = {10.3390/axioms11100489},
	abstract = {An explainable artificial intelligence (XAI) agent is an autonomous agent that uses a fundamental XAI model at its core to perceive its environment and suggests actions to be performed. One of the significant challenges for these XAI agents is performing their operation efficiently, which is governed by the underlying inference and optimization system. Along similar lines, an Explainable Fuzzy AI Challenge (XFC 2022) competition was launched, whose principal objective was to develop a fully autonomous and optimized XAI algorithm that could play the Python arcade game “Asteroid Smasher”. This research first investigates inference models to implement an efficient (XAI) agent using rule-based fuzzy systems. We also discuss the proposed approach (which won the competition) to attain efficiency in the XAI algorithm. We have explored the potential of the widely used Mamdani- and TSK-based fuzzy inference systems and investigated which model might have a more optimized implementation. Even though the TSK-based model outperforms Mamdani in several applications, no empirical evidence suggests this will also be applicable in implementing an XAI agent. The experimentations are then performed to find a better-performing inference system in a fast-paced environment. The thorough analysis recommends more robust and efficient TSK-based XAI agents than Mamdani-based fuzzy inference systems.},
	language = {en},
	number = {10},
	urldate = {2023-01-04},
	journal = {Axioms},
	author = {Mishra, Sunny and Shukla, Amit K. and Muhuri, Pranab K.},
	month = oct,
	year = {2022},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Explainable AI (XAI), Fuzzy system, Mamdani, TSK},
	pages = {489},
}

@inproceedings{bede_pexplainable_2022,
	title = {{\textless}p{\textgreater}{Explainable} {Artificial} {Intelligence} based on {Lukasiewicz} {Fuzzy} {Logic}{\textless}/p{\textgreater}},
	url = {https://meetings.ams.org/math/fall2022c/meetingapp.cgi/Paper/15099},
	abstract = {Explainability of neural networks and deep learning architectures, has gained i...},
	urldate = {2023-01-04},
	publisher = {AMS},
	author = {Bede, Barnabas},
	month = sep,
	year = {2022},
	keywords = {Explainable AI (XAI)},
}

@article{camastra_fuzzy_nodate,
	title = {A {Fuzzy} {Rule} {Base} {Minimization} {Perspective} in {XAI}},
	abstract = {Fuzzy rule-based systems are raising great interest in the last years in eXpalianable Artificial Intelligence. These systems represents knowledge easily understood by humans but they are not interpretable per se. They, in fact, must remain simple and understandable, and the rule base must be compactness. In this work a fuzzy rule base minimization approach based on rough sets theory and a greedy algorithm is proposed. The reduction of the fuzzy rules makes the rule base simpler, and thus easier to produce explainable inference systems (e.g., decision support systems and recommenders). Encouraging results are obtained validating and comparing the methodology on data of UCI benchmark.},
	language = {en},
	author = {Camastra, F and Ciaramella, A and Sposato, S and Staiano, A},
	keywords = {Explainable AI (XAI), Rule reduction},
}

@article{fernandez_evolutionary_2019,
	title = {Evolutionary {Fuzzy} {Systems} for {Explainable} {Artificial} {Intelligence}: {Why}, {When}, {What} for, and {Where} to?},
	volume = {14},
	issn = {1556-603X, 1556-6048},
	shorttitle = {Evolutionary {Fuzzy} {Systems} for {Explainable} {Artificial} {Intelligence}},
	url = {https://ieeexplore.ieee.org/document/8610271/},
	doi = {10.1109/MCI.2018.2881645},
	abstract = {Evolutionary fuzzy systems are one of the greatest advances within the area of computational intelligence. They consist of evolutionary algorithms applied to the design of fuzzy systems. Thanks to this hybridization, superb abilities are provided to fuzzy modeling in many different data science scenarios. This contribution is intended to comprise a position paper developing a comprehensive analysis of the evolutionary fuzzy systems research ﬁeld. To this end, the “4 W” questions are posed and addressed with the aim of understanding the current context of this topic and its signiﬁcance. Speciﬁcally, it will be pointed out why evolutionary fuzzy systems are important from an explainable point of view, when they began, what they are used for, and where the attention of researchers should be directed to in the near future in this area. They must play an important role for the emerging area of eXplainable Artiﬁcial Inteligence (XAI) learning from data.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Fernandez, Alberto and Herrera, Francisco and Cordon, Oscar and Jose del Jesus, Maria and Marcelloni, Francesco},
	month = feb,
	year = {2019},
	keywords = {Explainable AI (XAI)},
	pages = {69--81},
}

@misc{noauthor_explainable_nodate,
	title = {Explainable {AI} and {Fuzzy} {Logic} {Systems}},
	url = {https://www.springerprofessional.de/en/explainable-ai-and-fuzzy-logic-systems/16314474},
	abstract = {The recent advances in computing power coupled with the rapid increases in the quantity of available data has led to a resurgence in the theory and applications of Artificial Intelligence (AI). However, the use of complex AI algorithms like Deep …},
	language = {en},
	urldate = {2023-01-04},
	journal = {springerprofessional.de},
	keywords = {Explainable AI (XAI)},
}

@misc{arrieta_explainable_2019,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, {Taxonomies}, {Opportunities} and {Challenges} toward {Responsible} {AI}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {http://arxiv.org/abs/1910.10045},
	abstract = {In the last years, Artificial Intelligence (AI) has achieved a notable momentum that may deliver the best of expectations over many application sectors across the field. For this to occur, the entire community stands in front of the barrier of explainability, an inherent problem of AI techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI. Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is acknowledged as a crucial feature for the practical deployment of AI models. This overview examines the existing literature in the field of XAI, including a prospect toward what is yet to be reached. We summarize previous efforts to define explainability in Machine Learning, establishing a novel definition that covers prior conceptual propositions with a major focus on the audience for which explainability is sought. We then propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at Deep Learning methods for which a second taxonomy is built. This literature analysis serves as the background for a series of challenges faced by XAI, such as the crossroads between data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to XAI with a reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Arrieta, Alejandro Barredo and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and García, Salvador and Gil-López, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = dec,
	year = {2019},
	note = {arXiv:1910.10045 [cs]},
	keywords = {Explainable AI (XAI)},
}

@misc{knapic_explainable_2021,
	title = {Explainable {Artificial} {Intelligence} for {Human} {Decision}-{Support} {System} in {Medical} {Domain}},
	url = {http://arxiv.org/abs/2105.02357},
	abstract = {In the present paper we present the potential of Explainable Artificial Intelligence methods for decision-support in medical image analysis scenarios. With three types of explainable methods applied to the same medical image data set our aim was to improve the comprehensibility of the decisions provided by the Convolutional Neural Network (CNN). The visual explanations were provided on in-vivo gastral images obtained from a Video capsule endoscopy (VCE), with the goal of increasing the health professionals' trust in the black box predictions. We implemented two post-hoc interpretable machine learning methods LIME and SHAP and the alternative explanation approach CIU, centered on the Contextual Value and Utility (CIU). The produced explanations were evaluated using human evaluation. We conducted three user studies based on the explanations provided by LIME, SHAP and CIU. Users from different non-medical backgrounds carried out a series of tests in the web-based survey setting and stated their experience and understanding of the given explanations. Three user groups (n=20, 20, 20) with three distinct forms of explanations were quantitatively analyzed. We have found that, as hypothesized, the CIU explainable method performed better than both LIME and SHAP methods in terms of increasing support for human decision-making as well as being more transparent and thus understandable to users. Additionally, CIU outperformed LIME and SHAP by generating explanations more rapidly. Our findings suggest that there are notable differences in human decision-making between various explanation support settings. In line with that, we present three potential explainable methods that can with future improvements in implementation be generalized on different medical data sets and can provide great decision-support for medical experts.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Knapič, Samanta and Malhi, Avleen and Saluja, Rohit and Främling, Kary},
	month = may,
	year = {2021},
	note = {arXiv:2105.02357 [cs]},
	keywords = {Explainable AI (XAI)},
}

@article{aliev_introduction_2017,
	series = {9th {International} {Conference} on {Theory} and {Application} of {Soft} {Computing}, {Computing} with {Words} and {Perception}, {ICSCCW} 2017, 22-23 {August} 2017, {Budapest}, {Hungary}},
	title = {An introduction to the arithmetic of {Z}-numbers by using horizontal membership functions},
	volume = {120},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050917324614},
	doi = {10.1016/j.procs.2017.11.249},
	abstract = {As a theoretical basis of computation with imprecise and partially reliable information, arithmetic of Z-numbers should be developed with an emphasis of informativeness. In this paper we propose an approach to develop arithmetic of Z-numbers where a result of computation can be obtained with a predefined informativeness level. The proposed approach is based on the use of horizontal membership functions and a measure of specificity concept. An example is used to show validity of the approach.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Procedia Computer Science},
	author = {Aliev, R. A. and Alizadeh, A. V. and Huseynov, O. H.},
	month = jan,
	year = {2017},
	keywords = {Fuzzy arithmetic, Informativeness, Measure of specificity, Partial reliability, RDM arithmetic, Z-number},
	pages = {349--356},
}

@misc{slater_answer_2017,
	title = {Answer to "{Batch} reinforcement learning: {Algorithm} example"},
	shorttitle = {Answer to "{Batch} reinforcement learning},
	url = {https://stats.stackexchange.com/a/297892},
	urldate = {2023-01-04},
	journal = {Cross Validated},
	author = {Slater, Neil},
	month = aug,
	year = {2017},
	keywords = {Batch, Example, Reinforcement learning},
}

@misc{teoh_answer_2017,
	title = {Answer to "{Batch} reinforcement learning: {Algorithm} example"},
	shorttitle = {Answer to "{Batch} reinforcement learning},
	url = {https://stats.stackexchange.com/a/297801},
	urldate = {2023-01-04},
	journal = {Cross Validated},
	author = {Teoh, Peter},
	month = aug,
	year = {2017},
	keywords = {Batch, Example, Reinforcement learning},
}

@misc{vainer_batch_2017,
	type = {Forum post},
	title = {Batch reinforcement learning: {Algorithm} example},
	shorttitle = {Batch reinforcement learning},
	url = {https://stats.stackexchange.com/q/297708},
	urldate = {2023-01-04},
	journal = {Cross Validated},
	author = {Vainer, Jan},
	month = aug,
	year = {2017},
	keywords = {Batch, Example, Reinforcement learning},
}

@misc{noauthor_batch_nodate,
	title = {Batch {Reinforcement} {Learning} — {Reinforcement} {Learning} {Coach} 0.12.0 documentation},
	url = {https://intellabs.github.io/coach/features/batch_rl.html},
	urldate = {2023-01-04},
	keywords = {Batch, Code, Reinforcement learning},
}

@incollection{wiering_batch_2012,
	address = {Berlin, Heidelberg},
	title = {Batch {Reinforcement} {Learning}},
	volume = {12},
	isbn = {978-3-642-27644-6 978-3-642-27645-3},
	url = {http://link.springer.com/10.1007/978-3-642-27645-3_2},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Reinforcement {Learning}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
	editor = {Wiering, Marco and van Otterlo, Martijn},
	year = {2012},
	doi = {10.1007/978-3-642-27645-3_2},
	note = {Series Title: Adaptation, Learning, and Optimization},
	keywords = {Batch, Reinforcement learning},
	pages = {45--73},
}

@misc{shawntraynor_dqn_2019,
	type = {Reddit {Post}},
	title = {{DQN} {Mountain} {Car}},
	url = {www.reddit.com/r/reinforcementlearning/comments/cd4gk6/dqn_mountain_car/},
	urldate = {2023-01-04},
	journal = {r/reinforcementlearning},
	author = {shawntraynor},
	month = jul,
	year = {2019},
	keywords = {Deep, Deep Q-Network, Mountain car, Reinforcement learning},
}

@misc{noauthor_mountain_nodate,
	title = {Mountain {Car} {Google} {Colab} {Solution}},
	url = {https://colab.research.google.com/drive/1g9VVBNQq08wexIpqFiNW9ahVg3w40n1d#scrollTo=tDdnZpCfgKoQ},
	language = {en},
	urldate = {2023-01-04},
	keywords = {Code, Mountain car, Reinforcement learning},
}

@misc{xiaotian_simple_2022,
	title = {Simple {Solvers} for {Mountain} {Car}},
	url = {https://github.com/greatwallet/mountain-car},
	abstract = {A simple baseline for mountain-car @ gym},
	urldate = {2023-01-04},
	author = {Xiaotian), 程笑天 (Cheng},
	month = nov,
	year = {2022},
	note = {original-date: 2020-01-02T17:12:32Z},
	keywords = {Code, Mountain car, Reinforcement learning},
}

@misc{rulerd_when_2019,
	type = {Reddit {Post}},
	title = {When is {Mountain} {Car} considered  solved?},
	url = {www.reddit.com/r/reinforcementlearning/comments/bispc6/when_is_considered_mountain_car_solved/},
	urldate = {2023-01-04},
	journal = {r/reinforcementlearning},
	author = {RulerD},
	month = apr,
	year = {2019},
	keywords = {Mountain car, Reinforcement learning},
}

@misc{admin_understanding_2017,
	title = {Understanding {RL}: {The} {Bellman} {Equations}},
	shorttitle = {Understanding {RL}},
	url = {https://joshgreaves.com/understanding-rl-the-bellman-equations/},
	abstract = {Step-by-step derivation, explanation, and demystification of the most important equations in reinforcement learning In the previous post we learnt about},
	language = {en-US},
	urldate = {2023-01-04},
	journal = {Josh Greaves},
	author = {{admin}},
	month = nov,
	year = {2017},
	keywords = {Reinforcement learning},
}

@inproceedings{argerich_tutor4rl_2020,
	title = {{Tutor4RL}: {Guiding} {Reinforcement} {Learning} with {External} {Knowledge}},
	shorttitle = {{Tutor4RL}},
	url = {https://www.semanticscholar.org/paper/Tutor4RL%3A-Guiding-Reinforcement-Learning-with-Argerich-F%C3%BCrst/407657b07c11ca707a21e6c70f18648843bd4a9b},
	abstract = {We introduce Tutor4RL, a method to improve reinforcement learning (RL) performance during training, using external knowledge to guide the agents’ decisions and experience. Current approaches of RL need extensive experience to deliver good performance, something that is not acceptable in many real systems when no simulation environment or considerable previous data are available. In Tutor4RL, external knowledge– such as expert or domain knowledge– is expressed as programmable functions that are fed to the RL agent. During its first steps, the agent uses these knowledge functions to decide the best action, guiding its exploration and providing better performance from the start. As the agent gathers experience, it increasingly exploits its learned policy, eventually leaving its tutor behind. We demonstrate Tutor4RL with a DQN agent. In our tests, Tutor4RL achieves more than 3 times higher reward in the beginning of its training than an agent with no external knowledge.},
	urldate = {2023-01-04},
	author = {Argerich, Mauricio Fadel and Fürst, Jonathan and Cheng, Bin},
	year = {2020},
	keywords = {Reinforcement learning},
}

@misc{zychlinski_complete_2022,
	title = {The {Complete} {Reinforcement} {Learning} {Dictionary}},
	url = {https://towardsdatascience.com/the-complete-reinforcement-learning-dictionary-e16230b7d24e},
	abstract = {The Reinforcement Learning Terminology, A to Z},
	language = {en},
	urldate = {2023-01-04},
	journal = {Medium},
	author = {Zychlinski, Shaked},
	month = oct,
	year = {2022},
	keywords = {Reinforcement learning, Tutorial},
}

@article{lin_self-improving_nodate,
	title = {Self-improving reactive agents based on reinforcement learning, planning and teaching},
	abstract = {To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus twofold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.},
	language = {en},
	author = {Lin, Long-Ji},
	keywords = {Reinforcement learning},
}

@misc{jaderberg_reinforcement_2016,
	title = {Reinforcement {Learning} with {Unsupervised} {Auxiliary} {Tasks}},
	url = {http://arxiv.org/abs/1611.05397},
	doi = {10.48550/arXiv.1611.05397},
	abstract = {Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the-art on Atari, averaging 880{\textbackslash}\% expert human performance, and a challenging suite of first-person, three-dimensional {\textbackslash}emph\{Labyrinth\} tasks leading to a mean speedup in learning of 10\${\textbackslash}times\$ and averaging 87{\textbackslash}\% expert human performance on Labyrinth.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z. and Silver, David and Kavukcuoglu, Koray},
	month = nov,
	year = {2016},
	note = {arXiv:1611.05397 [cs]},
	keywords = {Reinforcement learning},
}

@misc{noauthor_reinforcement_nodate,
	title = {Reinforcement {Learning} ({DQN}) {Tutorial} — {PyTorch} {Tutorials} 1.13.1+cu117 documentation},
	url = {https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html},
	urldate = {2023-01-04},
	keywords = {Code, Deep, Deep Q-Network, Reinforcement Learning, Tutorial},
}

@article{liu_feature_2015,
	title = {Feature selection and feature learning for high-dimensional batch reinforcement learning: {A} survey},
	volume = {12},
	issn = {1751-8520},
	shorttitle = {Feature selection and feature learning for high-dimensional batch reinforcement learning},
	url = {https://doi.org/10.1007/s11633-015-0893-y},
	doi = {10.1007/s11633-015-0893-y},
	abstract = {Tremendous amount of data are being generated and saved in many complex engineering and social systems every day. It is significant and feasible to utilize the big data to make better decisions by machine learning techniques. In this paper, we focus on batch reinforcement learning (RL) algorithms for discounted Markov decision processes (MDPs) with large discrete or continuous state spaces, aiming to learn the best possible policy given a fixed amount of training data. The batch RL algorithms with handcrafted feature representations work well for low-dimensional MDPs. However, for many real-world RL tasks which often involve high-dimensional state spaces, it is difficult and even infeasible to use feature engineering methods to design features for value function approximation. To cope with high-dimensional RL problems, the desire to obtain data-driven features has led to a lot of works in incorporating feature selection and feature learning into traditional batch RL algorithms. In this paper, we provide a comprehensive survey on automatic feature selection and unsupervised feature learning for high-dimensional batch RL. Moreover, we present recent theoretical developments on applying statistical learning to establish finite-sample error bounds for batch RL algorithms based on weighted Lpnorms. Finally, we derive some future directions in the research of RL algorithms, theories and applications.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {International Journal of Automation and Computing},
	author = {Liu, De-Rong and Li, Hong-Liang and Wang, Ding},
	month = jun,
	year = {2015},
	keywords = {Adaptive, Batch, Big data, Dynamic programming, Feature learning, Feature selection, Reinforcement learning},
	pages = {229--242},
}

@incollection{sarma_intelligent_2007,
	address = {Boston, MA},
	title = {Intelligent {Tutoring} {Systems} using {Reinforcement} {Learning} to teach {Autistic} {Students}},
	volume = {241},
	isbn = {978-0-387-73696-9},
	url = {http://link.springer.com/10.1007/978-0-387-73697-6_5},
	abstract = {Many Intelligent Tutoring Systems have been developed using different Artificial Intelligence techniques. In this paper we propose to use Reinforcement Learning for building an intelligent tutoring system to teach autistic students, who can't communicate well with others. In reinforcement learning, a policy is updated for taking appropriate action to teach the student. The main advantage of using reinforcement learning is that, it eliminates the need for encoding pedagogical rules. Various issues in using reinforcement learning for intelligent tutoring systems are discussed in this paper.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Home {Informatics} and {Telematics}: {ICT} for {The} {Next} {Billion}},
	publisher = {Springer US},
	author = {Sarma, B. H. Sreenivasa and Ravindran, B.},
	year = {2007},
	doi = {10.1007/978-0-387-73697-6_5},
	note = {Series Title: IFIP — The International Federation for Information Processing},
	keywords = {Intelligent tutoring system (ITS), Reinforcement learning},
	pages = {65--78},
}

@article{barto_neuronlike_1983,
	title = {Neuronlike adaptive elements that can solve difficult learning control problems},
	volume = {SMC-13},
	issn = {2168-2909},
	doi = {10.1109/TSMC.1983.6313077},
	abstract = {It is shown how a system consisting of two neuronlike adaptive elements can solve a difficult learning control problem. The task is to balance a pole that is hinged to a movable cart by applying forces to the cart's base. It is argued that the learning problems faced by adaptive elements that are components of adaptive networks are at least as difficult as this version of the pole-balancing problem. The learning system consists of a single associative search element (ASE) and a single adaptive critic element (ACE). In the course of learning to balance the pole, the ASE constructs associations between input and output by searching under the influence of reinforcement feedback, and the ACE constructs a more informative evaluation function than reinforcement feedback alone can provide. The differences between this approach and other attempts to solve problems using neurolike elements are discussed, as is the relation of this work to classical and instrumental conditioning in animal learning studies and its possible implications for research in the neurosciences.},
	number = {5},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},
	month = sep,
	year = {1983},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {Adaptive, Biological neural networks, Pattern recognition, Problem-solving, Reinforcement learning, Supervised learning},
	pages = {834--846},
}

@misc{fujimoto_off-policy_2019,
	title = {Off-{Policy} {Deep} {Reinforcement} {Learning} without {Exploration}},
	url = {http://arxiv.org/abs/1812.02900},
	doi = {10.48550/arXiv.1812.02900},
	abstract = {Many practical applications of reinforcement learning constrain agents to learn from a fixed batch of data which has already been gathered, without offering further possibility for data collection. In this paper, we demonstrate that due to errors introduced by extrapolation, standard off-policy deep reinforcement learning algorithms, such as DQN and DDPG, are incapable of learning with data uncorrelated to the distribution under the current policy, making them ineffective for this fixed batch setting. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space in order to force the agent towards behaving close to on-policy with respect to a subset of the given data. We present the first continuous control deep reinforcement learning algorithm which can learn effectively from arbitrary, fixed batch data, and empirically demonstrate the quality of its behavior in several tasks.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Fujimoto, Scott and Meger, David and Precup, Doina},
	month = aug,
	year = {2019},
	note = {arXiv:1812.02900 [cs, stat]},
	keywords = {Deep, Off-Policy, Reinforcement learning},
}

@misc{levine_offline_2020,
	title = {Offline {Reinforcement} {Learning}: {Tutorial}, {Review}, and {Perspectives} on {Open} {Problems}},
	shorttitle = {Offline {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2005.01643},
	abstract = {In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	month = nov,
	year = {2020},
	note = {arXiv:2005.01643 [cs, stat]},
	keywords = {Offline, Reinforcement learning},
}

@misc{samal_reinforcement_2017,
	title = {Reinforcement {Learning} : {Its} necessity and challenges},
	shorttitle = {Reinforcement {Learning}},
	url = {https://towardsdatascience.com/reinforcement-learning-its-necessity-and-challenges-febef1470e9a},
	abstract = {Introduction:},
	language = {en},
	urldate = {2023-01-04},
	journal = {Medium},
	author = {Samal, Ashis},
	month = jun,
	year = {2017},
	keywords = {Offline, Reinforcement learning},
}

@misc{roderick_implementing_2017,
	title = {Implementing the {Deep} {Q}-{Network}},
	url = {http://arxiv.org/abs/1711.07478},
	abstract = {The Deep Q-Network proposed by Mnih et al. [2015] has become a benchmark and building point for much deep reinforcement learning research. However, replicating results for complex systems is often challenging since original scientific publications are not always able to describe in detail every important parameter setting and software engineering solution. In this paper, we present results from our work reproducing the results of the DQN paper. We highlight key areas in the implementation that were not covered in great detail in the original paper to make it easier for researchers to replicate these results, including termination conditions and gradient descent algorithms. Finally, we discuss methods for improving the computational performance and provide our own implementation that is designed to work with a range of domains, and not just the original Arcade Learning Environment [Bellemare et al., 2013].},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Roderick, Melrose and MacGlashan, James and Tellex, Stefanie},
	month = nov,
	year = {2017},
	note = {arXiv:1711.07478 [cs]},
}

@article{riza_development_2021,
	title = {Development of data-to-text ({D2T}) on generic data using fuzzy sets},
	volume = {8},
	issn = {23945443, 23947454},
	url = {https://www.accentsjournals.org/paperInfo.php?journalPaperId=1277},
	doi = {10.19101/IJATEE.2020.762134},
	abstract = {Data-to-Text (D2T) is an option for translating non-linguistic data into textual form. However, along with technological developments, the various fields of data and the variety of users are one of the focuses that must be considered in the development of D2T. This study aims to develop a D2T system with input in the form of general data so that it can receive data from any field or domain, whether the data have header information, data types, rules or not. Then fuzzy rule based systems are used to interpret data in general. The system developed can produce information in the form of data summaries, newest data information, and predictive information. It is carried out in the R programming language by utilizing several available packages. Experiments are carried out by measuring the level of readability of the news generated, computation time, and comparing the results with related research. The experimental results show that the information generated is proven to represent the data provided and can be understood by the level of students even at the elementary school level, and the computation time is quite good.},
	language = {en},
	number = {75},
	urldate = {2023-01-04},
	journal = {International Journal of Advanced Technology and Engineering Exploration},
	author = {Riza, Lala Septem and Ridwan, Muhammad and Junaeti, Enjun and Samah, Khyrina Airin Fariza Abu},
	month = feb,
	year = {2021},
	keywords = {Data-to-Text},
	pages = {382--390},
}

@misc{rebuffel_hierarchical_2019,
	title = {A {Hierarchical} {Model} for {Data}-to-{Text} {Generation}},
	url = {http://arxiv.org/abs/1912.10011},
	abstract = {Transcribing structured data into natural language descriptions has emerged as a challenging task, referred to as "data-to-text". These structures generally regroup multiple elements, as well as their attributes. Most attempts rely on translation encoder-decoder methods which linearize elements into a sequence. This however loses most of the structure contained in the data. In this work, we propose to overpass this limitation with a hierarchical model that encodes the data-structure at the element-level and the structure level. Evaluations on RotoWire show the effectiveness of our model w.r.t. qualitative and quantitative metrics.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Rebuffel, Clément and Soulier, Laure and Scoutheeten, Geoffrey and Gallinari, Patrick},
	month = dec,
	year = {2019},
	note = {arXiv:1912.10011 [cs]},
	keywords = {Data-to-Text, Natural-language generation (NLG)},
}

@misc{sai_survey_2020,
	title = {A {Survey} of {Evaluation} {Metrics} {Used} for {NLG} {Systems}},
	url = {http://arxiv.org/abs/2008.12009},
	abstract = {The success of Deep Learning has created a surge in interest in a wide a range of Natural Language Generation (NLG) tasks. Deep Learning has not only pushed the state of the art in several existing NLG tasks but has also facilitated researchers to explore various newer NLG tasks such as image captioning. Such rapid progress in NLG has necessitated the development of accurate automatic evaluation metrics that would allow us to track the progress in the field of NLG. However, unlike classification tasks, automatically evaluating NLG systems in itself is a huge challenge. Several works have shown that early heuristic-based metrics such as BLEU, ROUGE are inadequate for capturing the nuances in the different NLG tasks. The expanding number of NLG models and the shortcomings of the current metrics has led to a rapid surge in the number of evaluation metrics proposed since 2014. Moreover, various evaluation metrics have shifted from using pre-determined heuristic-based formulae to trained transformer models. This rapid change in a relatively short time has led to the need for a survey of the existing NLG metrics to help existing and new researchers to quickly come up to speed with the developments that have happened in NLG evaluation in the last few years. Through this survey, we first wish to highlight the challenges and difficulties in automatically evaluating NLG systems. Then, we provide a coherent taxonomy of the evaluation metrics to organize the existing metrics and to better understand the developments in the field. We also describe the different metrics in detail and highlight their key contributions. Later, we discuss the main shortcomings identified in the existing metrics and describe the methodology used to evaluate evaluation metrics. Finally, we discuss our suggestions and recommendations on the next steps forward to improve the automatic evaluation metrics.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Sai, Ananya B. and Mohankumar, Akash Kumar and Khapra, Mitesh M.},
	month = oct,
	year = {2020},
	note = {arXiv:2008.12009 [cs]},
	keywords = {Natural-language generation (NLG)},
}

@misc{noauthor_automatically_2021,
	title = {Automatically generating text from structured data},
	url = {https://www.amazon.science/blog/automatically-generating-text-from-structured-data},
	abstract = {Technique that lets devices convey information in natural language improves on state of the art.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Amazon Science},
	month = apr,
	year = {2021},
	keywords = {Natural-language generation (NLG)},
}

@misc{noauthor_natural_nodate,
	title = {Natural {Language} {Generation} ({Practical} {Guide}) {\textbar} by {German} {Sharabok} {\textbar} {Towards} {Data} {Science}},
	url = {https://towardsdatascience.com/natural-language-generation-practical-guide-9dc03df6bffd},
	urldate = {2023-01-04},
	keywords = {Natural-language generation (NLG)},
}

@article{gatt_multilingual_2016,
	series = {Special {Issue} on {Linguistic} {Description} of {Time} {Series}},
	title = {Multilingual generation of uncertain temporal expressions from data: {A} study of a possibilistic formalism and its consistency with human subjective evaluations},
	volume = {285},
	issn = {0165-0114},
	shorttitle = {Multilingual generation of uncertain temporal expressions from data},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011415003590},
	doi = {10.1016/j.fss.2015.07.018},
	abstract = {In NLG systems, temporal uncertainty in raw data can hamper the inference of temporal and causal relationships between events and thus impact the quality of the generated texts. In this paper, we introduce a framework to represent and reason with temporal uncertainty based on possibility theory and propose a model that uses the outcomes of such temporal reasoning to select linguistic expressions to convey uncertainty to the reader. Our model is based on Fuzzy Temporal Constraint Networks (FTCN) and our work is based on the assumption that uncertainty should be communicated to an end user. The model we propose is grounded in experimental data from three languages. We present a large-scale empirical study that investigates the conditions that influence human subjective uncertainty in reasoning about temporal relations. Based on this, we also construct a classifier to select expressions to convey uncertainty, based on possibility and necessity values. We then present an evaluation which shows that the predictions of the FTCN model correlate well with human subjective uncertainty in different scenarios. An evaluation of our temporal expressions classifier also suggests good results, compared to human selection of linguistic expressions, as compared to baseline models.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Gatt, Albert and Portet, François},
	month = feb,
	year = {2016},
	keywords = {Epistemic modality, Natural-language generation (NLG), Possibility theory, Temporal uncertainty},
	pages = {73--93},
}

@misc{noauthor_fuzzy_2016,
	title = {Fuzzy {Sets} {Across} the {Natural} {Language} {Generation} {Pipeline}},
	url = {https://deepai.org/publication/fuzzy-sets-across-the-natural-language-generation-pipeline},
	abstract = {05/17/16 - We explore the implications of using fuzzy techniques (mainly those commonly
used in the linguistic description/summarization of d...},
	urldate = {2023-01-04},
	journal = {DeepAI},
	month = may,
	year = {2016},
	keywords = {Natural-language generation (NLG)},
}

@article{kacprzyk_computing_2010,
	title = {Computing {With} {Words} {Is} an {Implementable} {Paradigm}: {Fuzzy} {Queries}, {Linguistic} {Data} {Summaries}, and {Natural}-{Language} {Generation}},
	volume = {18},
	issn = {1941-0034},
	shorttitle = {Computing {With} {Words} {Is} an {Implementable} {Paradigm}},
	doi = {10.1109/TFUZZ.2010.2040480},
	abstract = {We point out some relevant issues that are related to the computing-with-words (CWW) paradigm and argue for an urgent need for a new, nontraditional look at the area, since the traditional approach has resulted in very valuable theoretical research results. However, there is no proper exposure and recognition in other areas to which CWW belongs and can really contribute, notably natural-language processing (NLP), in general, and natural-language understanding (NLU) and natural-language generation (NLG), in particular. First, we present crucial elements of CWW, in particular Zadeh's protoforms, and indicate their power and stress a need to develop new tools to handle more modalities. We argue that CWW also has a high implementation potential and present our approach to linguistic data(base) summaries, which is a very intuitive and human-consistent natural-language-based knowledge-discovery tool. Special emphasis is on the use of Zadeh's protoform (prototypical form) as a general form of a linguistic data summary. We present an extension of our interactive approach, which is based on fuzzy logic and fuzzy database queries, to implement such linguistic summaries. In the main part of the paper, we discuss a close relation between linguistic summarization in the sense considered and some basic ideas and solutions in NLG, thus analyzing possible common elements and an opportunity to use developed tools, as well as some inherent differences and difficulties. Notably, we indicate a close relation of linguistic summaries that are considered to be some type of an extended template-based, and even a simple phrase-based, NLG system and emphasize a possibility to use software that is available in these areas. An important conclusion is also an urgent need to develop new protoforms, thus going beyond the classical ones of Zadeh. For illustration, we present an implementation for a sales database in a computer retailer, thereby showing the power of linguistic summaries, as well as an urgent need for new types of protoforms. Although we use linguistic summaries throughout, our discussion is also valid for CWW in general. We hope that this paper—which presents our personal view and perspective that result from our long-time involvement in both theoretical work in broadly perceived CWW and real-world implementations—will trigger a discussion and research efforts to help find a way out of a strange situation in which, on one hand, one can clearly see that CWW is related to words (language) and computing and, hence, should be part of broadly perceived mainstream computational linguistics, which lack tools to handle imprecision. These tools can be provided by CWW. Yet, CWW is practically unknown to these communities and is not mentioned or cited, and—reciprocally—even the top people in CWW do not refer to the results that are obtained in these areas. We hope that our paper, for the benefit of both the areas, will help bridge this gap that results from a wrong and dangerous fragmentation of{\textbackslash}break science.},
	number = {3},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Kacprzyk, Janusz and Zadrozny, Slawomir},
	month = jun,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Computational linguistics, Computing with words (CWW), Data mining, Databases, Fuzzy logic, Fuzzy query, Fuzzy sets, Linguistic summarization, Marketing and sales, Natural-language generation (NLG), Protoform, Prototypes},
	pages = {461--472},
}

@article{song_tissue-like_2017,
	title = {Tissue-like {P} systems with evolutional symport/antiport rules},
	volume = {378},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516313974},
	doi = {10.1016/j.ins.2016.10.046},
	abstract = {Tissue P systems with symport/antiport rules are a class of distributed parallel computing models inspired by the cell intercommunication in tissues, where objects are never modified in the process of communication, just changing their place within the system. In this work, a variant of tissue P systems, called tissue P systems with evolutional symport/antiport rules is introduced, where objects are moved from one region to another region and may be evolved during this process. The computational power of such P systems is studied. Specifically, it is proved that such P systems with one cell and using evolutional symport rules of length at most 3 or using evolutional antiport rules of length at most 4 are Turing universal (only the family of all finite sets of positive integers can be generated by such P systems if standard symport/antiport rules are used). Moreover, cell division rules are considered in tissue P systems with evolutional symport/antiport rules, and a limit on the efficiency of such P systems is provided with evolutional communication rules of length at most 2. The computational efficiency of this kind of models is shown when using evolutional communication rules of length at most 4.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Song, Bosheng and Zhang, Cheng and Pan, Linqiang},
	month = feb,
	year = {2017},
	keywords = {Bio-inspired computing, Membrane computing, Symport/antiport rule, Tissue P-system, Universality},
	pages = {177--193},
}

@article{peng_automatic_2015,
	title = {An automatic clustering algorithm inspired by membrane computing},
	volume = {68},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865515002676},
	doi = {10.1016/j.patrec.2015.08.008},
	abstract = {Membrane computing is a class of distributed parallel computing models. Inspired from the structure and inherent mechanism of membrane computing, a membrane clustering algorithm is proposed to deal with automatic clustering problem, in which a tissue-like membrane system with fully connected structure is designed as its computing framework. Moreover, based on its special structure and inherent mechanism, an improved velocity-position model is developed as evolution rules. Under the control of evolution-communication mechanism, the tissue-like membrane system cannot only find the most appropriate number of clusters but else determine a good clustering partitioning for a data set. Six benchmark data sets are used to evaluate the proposed membrane clustering algorithm. Experiment results show that the proposed algorithm is superior or competitive to three state-and-the-art automatic clustering algorithms recently reported in the literature.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Pattern Recognition Letters},
	author = {Peng, Hong and Wang, Jun and Shi, Peng and Riscos-Núñez, Agustín and Pérez-Jiménez, Mario J.},
	month = dec,
	year = {2015},
	keywords = {Automatic clustering, Membrane clustering algorithm, Membrane computing, Membrane system, Tissue-like membrane system},
	pages = {34--40},
}

@article{nishida_application_2004,
	title = {An application of {P}-system: {A} new algorithm for {NP}-complete optimization problems},
	volume = {5},
	shorttitle = {An application of {P}-system},
	journal = {Proceedings of the 8th World Multi-Conference on Systems, Cybernetics and Informatics},
	author = {Nishida, Taishin},
	month = jan,
	year = {2004},
	keywords = {P-system},
	pages = {109--112},
}

@article{he_adaptive_2014,
	title = {An adaptive membrane algorithm for solving combinatorial optimization problems},
	volume = {34},
	issn = {0252-9602},
	url = {https://www.sciencedirect.com/science/article/pii/S0252960214600904},
	doi = {10.1016/S0252-9602(14)60090-4},
	abstract = {Membrane algorithms (MAs), which inherit from P systems, constitute a new parallel and distribute framework for approximate computation. In the paper, a membrane algorithm is proposed with the improvement that the involved parameters can be adaptively chosen. In the algorithm, some membranes can evolve dynamically during the computing process to specify the values of the requested parameters. The new algorithm is tested on a well-known combinatorial optimization problem, the travelling salesman problem. The empirical evidence suggests that the proposed approach is efficient and reliable when dealing with 11 benchmark instances, particularly obtaining the best of the known solutions in eight instances. Compared with the genetic algorithm, simulated annealing algorithm, neural network and a fine-tuned non-adaptive membrane algorithm, our algorithm performs better than them. In practice, to design the airline network that minimize the total routing cost on the CAB data with twenty-five US cities, we can quickly obtain high quality solutions using our algorithm.},
	language = {en},
	number = {5},
	urldate = {2023-01-04},
	journal = {Acta Mathematica Scientia},
	author = {He, Juanjuan and Xiao, Jianhua and Shao, Zehui},
	month = sep,
	year = {2014},
	keywords = {Adaptive, Membrane computing, Travelling salesman problem},
	pages = {1377--1394},
}

@misc{hosseini_interpretable_2019,
	title = {Interpretable {Discriminative} {Dimensionality} {Reduction} and {Feature} {Selection} on the {Manifold}},
	url = {http://arxiv.org/abs/1909.09218},
	doi = {10.48550/arXiv.1909.09218},
	abstract = {Dimensionality reduction (DR) on the manifold includes effective methods which project the data from an implicit relational space onto a vectorial space. Regardless of the achievements in this area, these algorithms suffer from the lack of interpretation of the projection dimensions. Therefore, it is often difficult to explain the physical meaning behind the embedding dimensions. In this research, we propose the interpretable kernel DR algorithm (I-KDR) as a new algorithm which maps the data from the feature space to a lower dimensional space where the classes are more condensed with less overlapping. Besides, the algorithm creates the dimensions upon local contributions of the data samples, which makes it easier to interpret them by class labels. Additionally, we efficiently fuse the DR with feature selection task to select the most relevant features of the original space to the discriminative objective. Based on the empirical evidence, I-KDR provides better interpretations for embedding dimensions as well as higher discriminative performance in the embedded space compared to the state-of-the-art and popular DR algorithms.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Hosseini, Babak and Hammer, Barbara},
	month = sep,
	year = {2019},
	note = {arXiv:1909.09218 [cs, stat]},
}

@article{alfaverh_demand_2020,
	title = {Demand {Response} {Strategy} {Based} on {Reinforcement} {Learning} and {Fuzzy} {Reasoning} for {Home} {Energy} {Management}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2974286},
	abstract = {As energy demand continues to increase, demand response (DR) programs in the electricity distribution grid are gaining momentum and their adoption is set to grow gradually over the years ahead. Demand response schemes seek to incentivise consumers to use green energy and reduce their electricity usage during peak periods which helps support grid balancing of supply-demand and generate revenue by selling surplus of energy back to the grid. This paper proposes an effective energy management system for residential demand response using Reinforcement Learning (RL) and Fuzzy Reasoning (FR). RL is considered as a model-free control strategy which learns from the interaction with its environment by performing actions and evaluating the results. The proposed algorithm considers human preference by directly integrating user feedback into its control logic using fuzzy reasoning as reward functions. Q-learning, a RL strategy based on a reward mechanism, is used to make optimal decisions to schedule the operation of smart home appliances by shifting controllable appliances from peak periods, when electricity prices are high, to off-peak hours, when electricity prices are lower without affecting the customer's preferences. The proposed approach works with a single agent to control 14 household appliances and uses a reduced number of state-action pairs and fuzzy logic for rewards functions to evaluate an action taken for a certain state. The simulation results show that the proposed appliances scheduling approach can smooth the power consumption profile and minimise the electricity cost while considering user's preferences, user's feedbacks on each action taken and his/her preference settings. A user-interface is developed in MATLAB/Simulink for the Home Energy Management System (HEMS) to demonstrate the proposed DR scheme. The simulation tool includes features such as smart appliances, electricity pricing signals, smart meters, solar photovoltaic generation, battery energy storage, electric vehicle and grid supply.},
	journal = {IEEE Access},
	author = {Alfaverh, Fayiz and Denaï, M. and Sun, Yichuang},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Fuzzy Q-learning (FQL), Fuzzy reasoning, Reinforcement learning},
	pages = {39310--39321},
}

@article{malik_novel_2021,
	title = {A novel hybrid approach based on relief algorithm and fuzzy reinforcement learning approach for predicting wind speed},
	volume = {43},
	issn = {2213-1388},
	url = {https://www.sciencedirect.com/science/article/pii/S2213138820313473},
	doi = {10.1016/j.seta.2020.100920},
	abstract = {Wind speed (WS) prediction has become popular nowadays due to increasing demand for wind power generation and competitive development in wind energy. Many prediction models are used to predict WS for which wind is non-stationary, nonlinear and irregular. However, they neglect the effectiveness of feature selection methods in WS prediction, thereby creating very challenging for precise prediction of WS and safe operation of the wind industry. To overpower these challenges and further improve WS prediction accuracy, a prediction model is developed based on feature selection technique and prediction models. Therefore this study proposes an adaptive self-learning wind speed (WS) predicting model using fuzzy reinforcement learning (FRL) that is Fuzzy Q Learning (FQL). Proposed FQL based WS predictor model can predict with great accuracy. This is a first effort at developing a forecasting model using FRL for WS prediction. The presented model has no prior knowledge of the system or plant or target speed information. Measured WS is processed through Info Gain attribute evaluator with Ranker search method feature selection purpose which serves as input to the FQL based WS prediction model. The comparison of proposed prediction method and existing machine learning based is carried out using simulations. The performance analysis indicates that the proposed method serves as an important tool for wind potential assessment.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Sustainable Energy Technologies and Assessments},
	author = {Malik, Hasmat and Yadav, Amit Kumar},
	month = feb,
	year = {2021},
	keywords = {Fuzzy Q-learning (FQL), Fuzzy logic, Fuzzy system, Reinforcement},
	pages = {100920},
}

@article{malik_fuzzy_2020,
	title = {Fuzzy reinforcement learning based intelligent classifier for power transformer faults},
	volume = {101},
	issn = {0019-0578},
	url = {https://www.sciencedirect.com/science/article/pii/S0019057820300161},
	doi = {10.1016/j.isatra.2020.01.016},
	abstract = {In this work a fuzzy reinforcement learning (RL) based intelligent classifier for power transformer incipient faults is proposed. Fault classifiers proposed till date have low identification accuracy and do not identify all types of transformer faults. Herein, an attempt has been made to design an adaptive, intelligent transformer fault classifier that progressively learns to identify faults on-line with high accuracy for all fault types. In the proposed approach, dissolved gas analysis (DGA) data of oil samples collected from real power transformers (and from credible sources) has been used, which serves as input to a fuzzy RL based classifier. Typically, classification accuracy is heavily dependent on the number of input variables chosen. This has been resolved by using the J48 algorithm to select 8 most appropriate input variables from the 24 variables obtained using DGA. Proposed fuzzy RL approach achieves a fault identification accuracy of 99.7\%, which is significantly higher than other contemporary soft computing based identifiers. Experimental results and comparison with other state-of-the-art approaches, highlights superiority and efficacy of the proposed fuzzy RL technique for transformer fault classification.},
	language = {en},
	urldate = {2023-01-04},
	journal = {ISA Transactions},
	author = {Malik, Hasmat and Sharma, Rajneesh and Mishra, Sukumar},
	month = jun,
	year = {2020},
	keywords = {Decision tree, Fuzzy Q-learning (FQL)},
	pages = {390--398},
}

@inproceedings{qu_adaptive_2021,
	title = {An {Adaptive} {Fuzzy} {Reinforcement} {Learning} {Cooperative} {Approach} for the {Autonomous} {Control} of {Flock} {Systems}},
	doi = {10.1109/ICRA48506.2021.9561204},
	abstract = {The flock-guidance problem enjoys a challenging structure where multiple optimization objectives are solved simultaneously. This usually necessitates different control approaches to tackle various objectives, such as guidance, collision avoidance, and cohesion. The guidance schemes, in particular, have long suffered from complex tracking-error dynamics. Furthermore, techniques that are based on linear feedback strategies obtained at equilibrium conditions either may not hold or degrade when applied to uncertain dynamic environments. Pre-tuned fuzzy inference architectures lack robustness under such unmodeled conditions. This work introduces an adaptive distributed technique for the autonomous control of flock systems. Its relatively flexible structure is based on online fuzzy reinforcement learning schemes which simultaneously target a number of objectives; namely, following a leader, avoiding collision, and reaching a flock velocity consensus. In addition to its resilience in the face of dynamic disturbances, the algorithm does not require more than the agent position as a feedback signal. The effectiveness of the proposed method is validated with two simulation scenarios and benchmarked against a similar technique from the literature.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Qu, Shuzheng and Abouheaf, Mohammed and Gueaieb, Wail and Spinello, Davide},
	month = may,
	year = {2021},
	note = {ISSN: 2577-087X},
	keywords = {Adaptive, Fuzzy logic, Heuristic algorithm, Reinforcement learning, Robustness},
	pages = {8927--8933},
}

@article{berenji_learning_1992,
	title = {Learning and tuning fuzzy logic controllers through reinforcements},
	volume = {3},
	issn = {1941-0093},
	doi = {10.1109/72.159061},
	abstract = {A method for learning and tuning a fuzzy logic controller based on reinforcements from a dynamic system is presented. It is shown that: the generalized approximate-reasoning-based intelligent control (GARIC) architecture learns and tunes a fuzzy logic controller even when only weak reinforcement, such as a binary failure signal, is available; introduces a new conjunction operator in computing the rule strengths of fuzzy control rules; introduces a new localized mean of maximum (LMOM) method in combining the conclusions of several firing control rules; and learns to produce real-valued control actions. Learning is achieved by integrating fuzzy inference into a feedforward network, which can then adaptively improve performance by using gradient descent methods. The GARIC architecture is applied to a cart-pole balancing system and demonstrates significant improvements in terms of the speed of learning and robustness to changes in the dynamic system's parameters over previous schemes for cart-pole balancing.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Berenji, H.R. and Khedkar, P.},
	month = sep,
	year = {1992},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Automatic control, Fuzzy control, Fuzzy logic, Supervised learning},
	pages = {724--740},
}

@article{hinojosa_systems_2011,
	title = {Systems {Control} {With} {Generalized} {Probabilistic} {Fuzzy}-{Reinforcement} {Learning}},
	volume = {19},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2010.2081994},
	abstract = {Reinforcement learning (RL) is a valuable learning method when the systems require a selection of control actions whose consequences emerge over long periods for which input-output data are not available. In most combinations of fuzzy systems and RL, the environment is considered to be deterministic. In many problems, however, the consequence of an action may be uncertain or stochastic in nature. In this paper, we propose a novel RL approach to combine the universal-function-approximation capability of fuzzy systems with consideration of probability distributions over possible consequences of an action. The proposed generalized probabilistic fuzzy RL (GPFRL) method is a modified version of the actor-critic (AC) learning architecture. The learning is enhanced by the introduction of a probability measure into the learning structure, where an incremental gradient-descent weight-updating algorithm provides convergence. Our results show that the proposed approach is robust under probabilistic uncertainty while also having an enhanced learning speed and good overall performance.},
	number = {1},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Hinojosa, William M. and Nefti, Samia and Kaymak, Uzay},
	month = feb,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Actor-critic, Function approximation, Fuzzy system, Probabilistic fuzzy system, Reinforcement learning, Stochastic processes, Uncertainty},
	pages = {51--64},
}

@ARTICLE{are_ann_black_boxes,
  author={Benitez, J.M. and Castro, J.L. and Requena, I.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Are artificial neural networks black boxes?}, 
  year={1997},
  volume={8},
  number={5},
  pages={1156-1164},
  keywords={Artificial neural networks;Neurons;Neural networks;Fuzzy neural networks;Fuzzy systems;Fuzzy logic;Multi-layer neural network;Artificial intelligence;Knowledge based systems;Computer networks},
  doi={10.1109/72.623216}}

@ARTICLE{are_ann_white_boxes,
  author={Kolman, E. and Margaliot, M.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Are artificial neural networks white boxes?}, 
  year={2005},
  volume={16},
  number={4},
  pages={844-852},
  keywords={Artificial neural networks;Neural networks;Fuzzy neural networks;Fuzzy systems;Fuzzy reasoning;Logistics;Computer networks;Equations;Fuzzy sets;Mathematical model;Feedforward neural networks;hybrid intelligent systems;knowledge-based networks;rule extraction;rule generation;rule refinement},
  doi={10.1109/TNN.2005.849843}}


@article{er_online_2004,
	title = {Online tuning of fuzzy inference systems using dynamic fuzzy {Q}-learning},
	volume = {34},
	issn = {1941-0492},
	doi = {10.1109/TSMCB.2004.825938},
	abstract = {This paper presents a dynamic fuzzy Q-learning (DFQL) method that is capable of tuning fuzzy inference systems (FIS) online. A novel online self-organizing learning algorithm is developed so that structure and parameters identification are accomplished automatically and simultaneously based only on Q-learning. Self-organizing fuzzy inference is introduced to calculate actions and Q-functions so as to enable us to deal with continuous-valued states and actions. Fuzzy rules provide a natural mean of incorporating the bias components for rapid reinforcement learning. Experimental results and comparative studies with the fuzzy Q-learning (FQL) and continuous-action Q-learning in the wall-following task of mobile robots demonstrate that the proposed DFQL method is superior.},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Er, Meng Joo and Deng, Chang},
	month = jun,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	keywords = {Epsilon-completeness, Fuzzy system, Parameter estimation, Robot control, State estimation, Supervised learning},
	pages = {1478--1489},
}

@article{wong_r-poptvr_2009,
	title = {R-{POPTVR}: {A} {Novel} {Reinforcement}-{Based} {POPTVR} {Fuzzy} {Neural} {Network} for {Pattern} {Classification}},
	volume = {20},
	issn = {1941-0093},
	shorttitle = {R-{POPTVR}},
	doi = {10.1109/TNN.2009.2029857},
	abstract = {In general, a fuzzy neural network (FNN) is characterized by its learning algorithm and its linguistic knowledge representation. However, it does not necessarily interact with its environment when the training data is assumed to be an accurate description of the environment under consideration. In interactive problems, it would be more appropriate for an agent to learn from its own experience through interactions with the environment, i.e., reinforcement learning. In this paper, three clustering algorithms are developed based on the reinforcement learning paradigm. This allows a more accurate description of the clusters as the clustering process is influenced by the reinforcement signal. They are the REINFORCE clustering technique I (RCT-I), the REINFORCE clustering technique II (RCT-II), and the episodic REINFORCE clustering technique (ERCT). The integrations of the RCT-I, the RCT-II, and the ERCT within the pseudo-outer product truth value restriction (POPTVR), which is a fuzzy neural network integrated with the truth restriction value (TVR) inference scheme in its five layered feedforward neural network, form the RPOPTVR-I, the RPOPTVR-II, and the ERPOPTVR, respectively. The Iris, Phoneme, and Spiral data sets are used for benchmarking. For both Iris and Phoneme data, the RPOPTVR is able to yield better classification results which are higher than the original POPTVR and the modified POPTVR over the three test trials. For the Spiral data set, the RPOPTVR-II is able to outperform the others by at least a margin of 5.8\% over multiple test trials. The three reinforcement-based clustering techniques applied to the POPTVR network are able to exhibit the trial-and-error search characteristic that yields higher qualitative performance.},
	number = {11},
	journal = {IEEE Transactions on Neural Networks},
	author = {Wong, Wing-Cheong and Cho, Siu-Yeung and Quek, Chai},
	month = nov,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Classification, Clustering, Fuzzy neural network, Knowledge representation, Pattern classification, Reinforcement learning},
	pages = {1740--1755},
}

@article{fan_self-optimization_2014,
	title = {Self-optimization of coverage and capacity based on a fuzzy neural network with cooperative reinforcement learning},
	volume = {2014},
	issn = {1687-1499},
	url = {https://doi.org/10.1186/1687-1499-2014-57},
	doi = {10.1186/1687-1499-2014-57},
	abstract = {Self-organization is a key concept in long-term evolution (LTE) systems to reduce capital and operational expenditures (CAPEX and OPEX). Self-optimization of coverage and capacity, which allows the system to periodically and automatically adjust the key radio frequency (RF) parameters through intelligent algorithms, is one of the most important tasks in the context of self-organizing networks (SON). In this paper, we propose self-optimization of antenna tilt and power using a fuzzy neural network optimization based on reinforcement learning (RL-FNN). In our approach, a central control mechanism enables cooperation-based learning by allowing distributed SON entities to share their optimization experience, represented as the parameters of learning method. Specifically, SON entities use cooperative Q-learning and reinforced back-propagation method to acquire and adjust their optimization experience. To evaluate the coverage and capacity performance of RL-FNN, we analyze cell-edge performance and cell-center performance indicators jointly across neighboring cells and specifically consider the difference in load distribution in a given region. The simulation results show that RL-FNN performs significantly better than the best fixed configuration proposed in the literature. Furthermore, this is achieved with significantly lower energy consumption. Finally, since each self-optimization round completes in less than a minute, RL-FNN can meet the need of practical applications of self-optimization in a dynamic environment.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {EURASIP Journal on Wireless Communications and Networking},
	author = {Fan, Shaoshuai and Tian, Hui and Sengul, Cigdem},
	month = apr,
	year = {2014},
	keywords = {Fuzzy neural network, Reinforcement learning, Self-organizing network},
	pages = {57},
}

@inproceedings{wu_reinforcement_2000,
	title = {Reinforcement learning and tuning for neural network based fuzzy logic controller},
	volume = {3},
	doi = {10.1109/ICOSP.2000.893427},
	abstract = {Proposes a reinforcement neural network based fuzzy logic controller (RNNFLC) for solving reinforcement learning and tuning problems. A simplified and effective reinforcement based learning algorithm is proposed to generate fuzzy rules automatically. A reinforcement-tuning algorithm is introduced to tune the membership function. The RNNFLC is applied to a cart-pole balancing system and shows significant improvements.},
	booktitle = {{WCC} 2000 - {ICSP} 2000. 2000 5th {International} {Conference} on {Signal} {Processing} {Proceedings}. 16th {World} {Computer} {Congress} 2000},
	author = {Wu, Gengfeng and Sun, Hongjin and Dong, Jianquan and Cao, Min and Wang, Tao},
	month = aug,
	year = {2000},
	keywords = {Fuzzy control, Fuzzy logic, Fuzzy neural network, Neural network},
	pages = {1695--1700 vol.3},
}

@article{huang_interpretable_2020,
	title = {Interpretable policies for reinforcement learning by empirical fuzzy sets},
	volume = {91},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S095219762030049X},
	doi = {10.1016/j.engappai.2020.103559},
	abstract = {This paper proposes a method and an algorithm to implement interpretable fuzzy reinforcement learning (IFRL). It provides alternative solutions to common problems in RL, like function approximation and continuous action space. The learning process resembles that of human beings by clustering the encountered states, developing experiences for each of the typical cases, and making decisions fuzzily. The learned policy can be expressed as human-intelligible IF-THEN rules, which facilitates further investigation and improvement. It adopts the actor–critic architecture whereas being different from mainstream policy gradient methods. The value function is approximated through the fuzzy system AnYa. The state–action space is discretized into a static grid with nodes. Each node is treated as one prototype and corresponds to one fuzzy rule, with the value of the node being the consequent. Values of consequents are updated using the Sarsa(λ) algorithm. Probability distribution of optimal actions regarding different states is estimated through Empirical Data Analytics (EDA), Autonomous Learning Multi-Model Systems (ALMMo), and Empirical Fuzzy Sets (εFS). The fuzzy kernel of IFRL avoids the lack of interpretability in other methods based on neural networks. Simulation results with four problems, namely Mountain Car, Continuous Gridworld, Pendulum Position, and Tank Level Control, are presented as a proof of the proposed concept.},
	language = {en},
	urldate = {2023-01-03},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Huang, Jianfeng and Angelov, Plamen P. and Yin, Chengliang},
	month = may,
	year = {2020},
	keywords = {AnYa type fuzzy system, Autonomous learning, Empirical fuzzy sets, Interpretable fuzzy system, Probability distribution learning, Reinforcement learning},
	pages = {103559},
}

@article{sanjay_gandhi_grid_2020,
	title = {Grid clustering and fuzzy reinforcement-learning based energy-efficient data aggregation scheme for distributed {WSN}},
	volume = {14},
	issn = {1751-8636},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-com.2019.1005},
	doi = {10.1049/iet-com.2019.1005},
	abstract = {The widely acceptable problem in wireless sensor networks (WSNs) is to develop a practical scheme for data aggregation in the massive range of sensor nodes that are randomly distributed over a network region. The essential operation of cluster heads (CHs) in such a network is to transmit the aggregated data to the sink node through multi-hop communication, thus the energy to be used in a better way during the period of aggregation and transmission. Therefore, this study presents a scheme based on grid clustering and fuzzy reinforcement-learning to maximise network lifetime as well as energy-efficient data aggregation for distributed WSN. Initially, grid clustering is employed for cluster formation and CH selection. Further, a fuzzy rule system-based reinforcement learning algorithm is used to select the data aggregator node based on the parameters, such as distance, neighbourhood overlap, and algebraic connectivity. Finally, the dynamic relocation of the mobile sink is performed within a grid-based clustered network region using a fruit fly optimisation algorithm. The experimental outcomes revealed that the proposed data aggregation scheme provides superior performance in terms of energy consumption and network lifetime compared to earlier systems.},
	language = {en},
	number = {16},
	urldate = {2023-01-04},
	journal = {IET Communications},
	author = {Sanjay Gandhi, Gundabatini and Vikas, K. and Ratnam, Vijayananda and Suresh Babu, Kolluru},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-com.2019.1005},
	keywords = {Algebraic connectivity, Clustering, Data aggregation, Fruit fly optimisation algorithm, Optimization, Reinforcement learning},
	pages = {2840--2848},
}

@article{vemireddy_fuzzy_2021,
	title = {Fuzzy {Reinforcement} {Learning} for energy efficient task offloading in {Vehicular} {Fog} {Computing}},
	volume = {199},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128621004163},
	doi = {10.1016/j.comnet.2021.108463},
	abstract = {Vehicular Fog Computing (VFC) has been envisioned as a potential fog computing paradigm which aims to offload delay sensitive tasks to mobile fog vehicles instead of remote cloud in order to facilitate computational demands of smart villages close to rural highways. There exists challenges related to task offloading in VFC that need to be addressed. Most often, Road Side Units (RSUs) deployed along rural highways are energy constrained and they need to provide energy efficient scheduling services for the allocation of tasks to fog vehicles. On the other hand, energy consumption optimization is challenging, since scheduling decision of local processing of tasks incur computation cost while the allocation of tasks to fog vehicles incurs communication cost. Although the task offloading to VFC reduces response latency, it leads to higher RSU energy consumption contributed by the communication of task data to fog vehicles. Therefore, this paper presents an energy efficient vehicle scheduling problem for offloading of tasks to mobile fog nodes subject to satisfy constraints of task deadline and resource availability. To resolve high dimensionality issue caused by increased number of vehicles in RSU coverage, we propose an on-policy reinforcement leaning based scheduling algorithm combined with fuzzy logic based greedy heuristic, named as Fuzzy Reinforcement Learning (FRL). This greedy heuristic not only accelerates learning process, but also improves long term reward when compared to Q-learning algorithm. Extensive experiments have been performed to evaluate the proposed algorithm and the simulation results show that the proposed FRL algorithm outperforms other scheduling algorithms such as First Come First Serve (FCFS), Rate Monotonic Scheduling (RMS), Fuzzy and Distributed Task Allocation with Distributed Process (DTA\_DP).},
	language = {en},
	urldate = {2023-01-04},
	journal = {Computer Networks},
	author = {Vemireddy, Satish and Rout, Rashmi Ranjan},
	month = nov,
	year = {2021},
	keywords = {Fuzzy logic, Optimization, Reinforcement learning, Scheduling},
	pages = {108463},
}

@inproceedings{glorennec_fuzzy_1997,
	title = {Fuzzy {Q}-learning},
	volume = {2},
	doi = {10.1109/FUZZY.1997.622790},
	abstract = {This paper proposes an adaptation of Watkins' Q-learning (1989, 1992) for fuzzy inference systems where both the actions and the Q-functions are inferred from fuzzy rules. This approach is compared with genetic algorithm on the cart-centering problem, showing its effectiveness.},
	booktitle = {Proceedings of 6th {International} {Fuzzy} {Systems} {Conference}},
	author = {Glorennec, P.Y. and Jouffe, L.},
	month = jul,
	year = {1997},
	keywords = {Fuzzy control, Fuzzy system, Genetic algorithm, Neural network, State estimation, State-space methods, Table lookup},
	pages = {659--662 vol.2},
}

@article{jouffe_fuzzy_1998,
	title = {Fuzzy inference system learning by reinforcement methods},
	volume = {28},
	issn = {1558-2442},
	doi = {10.1109/5326.704563},
	abstract = {Fuzzy Actor-Critic Learning (FACL) and Fuzzy Q-Learning (FQL) are reinforcement learning methods based on dynamic programming (DP) principles. In the paper, they are used to tune online the conclusion part of fuzzy inference systems (FIS). The only information available for learning is the system feedback, which describes in terms of reward and punishment the task the fuzzy agent has to realize. At each time step, the agent receives a reinforcement signal according to the last action it has performed in the previous state. The problem involves optimizing not only the direct reinforcement, but also the total amount of reinforcements the agent can receive in the future. To illustrate the use of these two learning methods, we first applied them to a problem that involves finding a fuzzy controller to drive a boat from one bank to another, across a river with a strong nonlinear current. Then, we used the well known Cart-Pole Balancing and Mountain-Car problems to be able to compare our methods to other reinforcement learning methods and focus on important characteristic aspects of FACL and FQL. We found that the genericity of our methods allows us to learn every kind of reinforcement learning problem (continuous states, discrete/continuous actions, various type of reinforcement functions). The experimental studies also show the superiority of these methods with respect to the other related methods we can find in the literature.},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Jouffe, L.},
	month = aug,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	keywords = {Dynamic programming, Expert systems, Fuzzy control, Fuzzy logic, Fuzzy system},
	pages = {338--355},
}

@inproceedings{gordon_fuzzy_2012,
	title = {Fuzzy {Fitted} {Q}},
	abstract = {In recent years a number of different algorithms have been applied to learning robot control [1], [2], [3]. One family of methods, Fitted value iteration methods [4], are particularly promising because of their data efficiency, a valuable capability in real world problems [5]. This paper proposes a variation of Fitted value iteration that uses Q-learning with fuzzy logic based function approximation [6]. We demonstrate the viability of this algorithm in simulation and in real world experiments.},
	booktitle = {2012 19th {International} {Conference} on {Mechatronics} and {Machine} {Vision} in {Practice} ({M2VIP})},
	author = {Gordon, Sean W.},
	month = nov,
	year = {2012},
	keywords = {Function approximation, Fuzzy logic},
	pages = {244--248},
}

@article{moghadam_autonomous_2022,
	title = {An autonomous performance testing framework using self-adaptive fuzzy reinforcement learning},
	volume = {30},
	issn = {1573-1367},
	url = {https://doi.org/10.1007/s11219-020-09532-z},
	doi = {10.1007/s11219-020-09532-z},
	abstract = {Test automation brings the potential to reduce costs and human effort, but several aspects of software testing remain challenging to automate. One such example is automated performance testing to find performance breaking points. Current approaches to tackle automated generation of performance test cases mainly involve using source code or system model analysis or use-case-based techniques. However, source code and system models might not always be available at testing time. On the other hand, if the optimal performance testing policy for the intended objective in a testing process instead could be learned by the testing system, then test automation without advanced performance models could be possible. Furthermore, the learned policy could later be reused for similar software systems under test, thus leading to higher test efficiency. We propose SaFReL, a self-adaptive fuzzy reinforcement learning-based performance testing framework. SaFReL learns the optimal policy to generate performance test cases through an initial learning phase, then reuses it during a transfer learning phase, while keeping the learning running and updating the policy in the long term. Through multiple experiments in a simulated performance testing setup, we demonstrate that our approach generates the target performance test cases for different programs more efficiently than a typical testing process and performs adaptively without access to source code and performance models.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Software Quality Journal},
	author = {Moghadam, Mahshid Helali and Saadatmand, Mehrdad and Borg, Markus and Bohlin, Markus and Lisper, Björn},
	month = mar,
	year = {2022},
	keywords = {Reinforcement learning, Test case generation},
	pages = {127--159},
}

@article{berenji_reinforcement_nodate,
	title = {A {Reinforcement} {Learning}-{Based} {Architecture} for {Fuzzy} {Logic} {Control}},
	abstract = {This paper introduces a new method for learning to refine a rule-based fuzzy logic controller. A reinforcement learning technique is used in conjunction with a multilayer neural network model of a fuzzy controller. The approximate reasoning based intelligent control (ARIC) architecture proposed here learns by updating its prediction of the physical system's behavior and fine tunes a control knowledge base. Its theory is related to Sutton's temporal difference (TD) method. Because ARIC has the advantage of using the control knowledge of an experienced operator and .fine tuning it through the process of learning, it learns faster than systems that train networks from scratch. The approach is applied to a cart-pole balancing system.},
	language = {en},
	author = {Berenji, Hamid R},
	keywords = {ARIC},
}

@article{khooban_novel_2021,
	title = {A {Novel} {Deep} {Reinforcement} {Learning} {Controller} {Based} {Type}-{II} {Fuzzy} {System}: {Frequency} {Regulation} in {Microgrids}},
	volume = {5},
	issn = {2471-285X},
	shorttitle = {A {Novel} {Deep} {Reinforcement} {Learning} {Controller} {Based} {Type}-{II} {Fuzzy} {System}},
	doi = {10.1109/TETCI.2020.2964886},
	abstract = {The high-penetration of distributed generation technologies in the form of MicroGrids (MGs), in recent years, has increased the risk of frequency instability since their energy is supplied by renewable energy resources (RESs) with uncertain nature. Under such circumstances, providing an MG model with an efficient load frequency control (LFC) has a fundamental role in restoring the stability of the unstructured power system. In this study, a hybrid power system with the application of the Tidal Power Unit (TPU) and Vehicle-to-Grid (V2G) is effectively planed as an isolated MG. A new fractional gradient descent (FGD) based on a single-input interval type-2 fuzzy logic controller (SIT2-FLC) is suggested as the main LFC controller, where the footprint of uncertainty (FOU) coefficient of the SIT2-FLC is specifically adjusted to enhance the LFC performance. Additionally, a deep deterministic policy gradient (DDPG) with the actor-critic framework is considered to generate the supplementary control action, which is useful for the frequency stabilization by adapting to the randomness of load disturbances and RESs. Lastly, a model-in-the-loop (MiL) simulation is conducted to appraise the feasibility and applicability of the suggested design method from a systemic perspective.},
	number = {4},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Khooban, Mohammad Hassan and Gheisarnejad, Meysam},
	month = aug,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Emerging Topics in Computational Intelligence},
	keywords = {Deep Deterministic Policy Gradient (DDPG), Fractional Gradient Descent (FGD), Frequency control, Generators, Interval Type-2 (IT2) Fuzzy Logic Control, Uncertainty},
	pages = {689--699},
}

@article{goharimanesh_fuzzy_2020,
	title = {A {Fuzzy} {Reinforcement} {Learning} {Approach} for {Continuum} {Robot} {Control}},
	volume = {100},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-020-01237-6},
	doi = {10.1007/s10846-020-01237-6},
	abstract = {Continuum robots (CRs) hold great potential for many medical and industrial applications where compliant interaction within the potentially confined environment is required. However, the navigation of CRs poses several challenges due to their limited actuation channels and the hyper-flexibility of their structure. Environmental uncertainty and characteristic hysteresis in such procedures add to the complexity of their operation. Therefore, the quality of trajectory tracking for continuum robots plays an essential role in the success of the application procedures. While there are a few different actuation configurations available for CRs, the focus of this paper will be placed on tendon-driven manipulators. In this research, a new fuzzy reinforcement learning (FRL) approach is introduced. The proposed FRL-based control parameters are tuned by the Taguchi method and evolutionary genetic algorithm (GA) to provide faster convergence to the Nash Equilibrium. The approach is verified through a comprehensive set of simulations using a Cosserat rod model. The results show a steady and accurate trajectory tracking capability for a CR.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Goharimanesh, M. and Mehrkish, A. and Janabi-Sharifi, F.},
	month = dec,
	year = {2020},
	keywords = {Evolutionary algorithm, Fuzzy control, Reinforcement learning, Robot control, Taguchi method},
	pages = {809--826},
}

@article{ye_fuzzy_2003,
	title = {A fuzzy controller with supervised learning assisted reinforcement learning algorithm for obstacle avoidance},
	volume = {33},
	issn = {1941-0492},
	doi = {10.1109/TSMCB.2003.808179},
	abstract = {Fuzzy logic systems are promising for efficient obstacle avoidance. However, it is difficult to maintain the correctness, consistency, and completeness of a fuzzy rule base constructed and tuned by a human expert. A reinforcement learning method is capable of learning the fuzzy rules automatically. However, it incurs a heavy learning phase and may result in an insufficiently learned rule base due to the curse of dimensionality. In this paper, we propose a neural fuzzy system with mixed coarse learning and fine learning phases. In the first phase, a supervised learning method is used to determine the membership functions for input and output variables simultaneously. After sufficient training, fine learning is applied which employs reinforcement learning algorithm to fine-tune the membership functions for output variables. For sufficient learning, a new learning method using a modification of Sutton and Barto's model is proposed to strengthen the exploration. Through this two-step tuning approach, the mobile robot is able to perform collision-free navigation. To deal with the difficulty of acquiring a large amount of training data with high consistency for supervised learning, we develop a virtual environment (VE) simulator, which is able to provide desktop virtual environment (DVE) and immersive virtual environment (IVE) visualization. Through operating a mobile robot in the virtual environment (DVE/IVE) by a skilled human operator, training data are readily obtained and used to train the neural fuzzy system.},
	number = {1},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Ye, Cang and Yung, N.H.C. and Wang, Danwei},
	month = feb,
	year = {2003},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	keywords = {Fuzzy control, Fuzzy logic, Fuzzy system, Navigation, Robot control, Supervised learning, Virtual environment},
	pages = {17--27},
}

@inproceedings{wu_fast_2000,
	title = {A fast approach for automatic generation of fuzzy rules by generalized dynamic fuzzy neural networks},
	volume = {4},
	doi = {10.1109/ACC.2000.878622},
	abstract = {Generalized dynamic fuzzy neural networks (G-DFNN) based on ellipsoidal basis functions, which implement TSK fuzzy inference systems, are presented to extract fuzzy rules from input-output sample patterns. The salient characteristics of the approach are: (1) fuzzy rules can be gained quickly without using the backpropagation iteration learning; (2) the online self-organizing learning paradigm is employed so that structure and parameters identification are done automatically and simultaneously without partitioning the input space and selecting initial parameters a priori; (3) the sensitivity of fuzzy rules and input variables are analyzed based on the error reduction ratio method so that fuzzy rules can be recruited or deleted dynamically and the premise parameters of each input variable can be modified. Simulation studies and comprehensive comparisons with some other approaches demonstrate that the proposed scheme is superior in terms of learning efficiency and performance.},
	booktitle = {Proceedings of the 2000 {American} {Control} {Conference}. {ACC} ({IEEE} {Cat}. {No}.{00CH36334})},
	author = {Wu, Shiqian and Er, Meng Joo and Ni, Maolin and Leithead, W.E.},
	month = jun,
	year = {2000},
	note = {ISSN: 0743-1619},
	keywords = {Fuzzy control, Fuzzy logic, Fuzzy neural network, Fuzzy system, Neural network},
	pages = {2453--2457 vol.4},
}

@inproceedings{lee_supervised_1992,
	title = {Supervised and unsupervised learning with fuzzy similarity for neural-network-based fuzzy logic control systems},
	doi = {10.1109/ICSMC.1992.271691},
	abstract = {A feedforward multilayered connectionist network that has distributed learning abilities is proposed to realize the basic elements and functions of a traditional fuzzy logic controller. Two complementary structure/parameter learning algorithms are proposed for setting up the proposed neural-network-based fuzzy logic control system (NN-FLCS). First, a two-phase hybrid learning algorithm is proposed which combines unsupervised and supervised learning procedures to build the rule nodes and train the membership functions. The two-phase hybrid learning algorithm performs well if sets of training data are available offline. The authors then propose an online supervised structure/parameter learning algorithm for constructing the NN-FLCS dynamically. This algorithm combines the backpropagation learning scheme for the parameter learning and a fuzzy similarity measure for the structure learning. The proposed online structure/parameter learning algorithm can find proper fuzzy logic rules, membership functions, and the size of output fuzzy partitions simultaneously. Computer simulation examples are presented to illustrate the performance of the learning algorithms.{\textless}{\textgreater}},
	booktitle = {[{Proceedings}] 1992 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
	author = {Lee, C.S.G. and Lin, C.T.},
	month = oct,
	year = {1992},
	keywords = {Fuzzy control, Fuzzy logic, Heuristic algorithm, Partitioning algorithm, Supervised learning, Training data, Unsupervised learning},
	pages = {688--693 vol.1},
}

@inproceedings{REM,
author = {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
title = {An optimistic perspective on offline reinforcement learning},
year = {2020},
publisher = {JMLR.org},
abstract = {Off-policy reinforcement learning (RL) using a fixed offline dataset of logged interactions is an important consideration in real world applications. This paper studies offline RL using the DQN Replay Dataset comprising the entire replay experience of a DQN agent on 60 Atari 2600 games. We demonstrate that recent off-policy deep RL algorithms, even when trained solely on this fixed dataset, outperform the fully-trained DQN agent. To enhance generalization in the offline setting, we present Random Ensemble Mixture (REM), a robust Q-learning algorithm that enforces optimal Bellman consistency on random convex combinations of multiple Q-value estimates. Offline REM trained on the DQN Replay Dataset surpasses strong RL baselines. Ablation studies highlight the role of offline dataset size and diversity as well as the algorithm choice in our positive results. Overall, the results here present an optimistic view that robust RL algorithms used on sufficiently large and diverse offline datasets can lead to high quality policies. To provide a testbed for offline RL and reproduce our results, the DQN Replay Dataset is released at offline-rl.github.io.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {11},
numpages = {11},
series = {ICML'20}
}

@article{Dabney_Rowland_Bellemare_Munos_2018, title={Distributional Reinforcement Learning With Quantile Regression}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11791}, DOI={10.1609/aaai.v32i1.11791}, abstractNote={ &lt;p&gt; In reinforcement learning (RL), an agent interacts with the environment by taking actions and observing the next state and reward. When sampled probabilistically, these state transitions, rewards, and actions can all induce randomness in the observed long-term return. Traditionally, reinforcement learning algorithms average over this randomness to estimate the value function. In this paper, we build on recent work advocating a distributional approach to reinforcement learning in which the distribution over returns is modeled explicitly instead of only estimating the mean. That is, we examine methods of learning the value distribution instead of the value function. We give results that close a number of gaps between the theoretical and algorithmic results given by Bellemare, Dabney, and Munos (2017). First, we extend existing results to the approximate distribution setting. Second, we present a novel distributional reinforcement learning algorithm consistent with our theoretical formulation. Finally, we evaluate this new algorithm on the Atari 2600 games, observing that it significantly outperforms many of the recent improvements on DQN, including the related distributional algorithm C51. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, Rémi}, year={2018}, month={Apr.} }

@article{is_there_a_need_for_fuzzy_logic,
title = {Is there a need for fuzzy logic?},
journal = {Information Sciences},
volume = {178},
number = {13},
pages = {2751-2779},
year = {2008},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508000716},
author = {Lotfi A. Zadeh},
keywords = {Fuzzy logic, Fuzzy sets, Approximate reasoning, Computing with words, Computing with perceptions, Generalized theory of uncertainty},
abstract = {“Is there a need for fuzzy logic?” is an issue which is associated with a long history of spirited discussions and debate. There are many misconceptions about fuzzy logic. Fuzzy logic is not fuzzy. Basically, fuzzy logic is a precise logic of imprecision and approximate reasoning. More specifically, fuzzy logic may be viewed as an attempt at formalization/mechanization of two remarkable human capabilities. First, the capability to converse, reason and make rational decisions in an environment of imprecision, uncertainty, incompleteness of information, conflicting information, partiality of truth and partiality of possibility – in short, in an environment of imperfect information. And second, the capability to perform a wide variety of physical and mental tasks without any measurements and any computations [L.A. Zadeh, From computing with numbers to computing with words – from manipulation of measurements to manipulation of perceptions, IEEE Transactions on Circuits and Systems 45 (1999) 105–119; L.A. Zadeh, A new direction in AI – toward a computational theory of perceptions, AI Magazine 22 (1) (2001) 73–84]. In fact, one of the principal contributions of fuzzy logic – a contribution which is widely unrecognized – is its high power of precisiation. Fuzzy logic is much more than a logical system. It has many facets. The principal facets are: logical, fuzzy-set-theoretic, epistemic and relational. Most of the practical applications of fuzzy logic are associated with its relational facet. In this paper, fuzzy logic is viewed in a nonstandard perspective. In this perspective, the cornerstones of fuzzy logic – and its principal distinguishing features – are: graduation, granulation, precisiation and the concept of a generalized constraint. A concept which has a position of centrality in the nontraditional view of fuzzy logic is that of precisiation. Informally, precisiation is an operation which transforms an object, p, into an object, p∗, which in some specified sense is defined more precisely than p. The object of precisiation and the result of precisiation are referred to as precisiend and precisiand, respectively. In fuzzy logic, a differentiation is made between two meanings of precision – precision of value, v-precision, and precision of meaning, m-precision. Furthermore, in the case of m-precisiation a differentiation is made between mh-precisiation, which is human-oriented (nonmathematical), and mm-precisiation, which is machine-oriented (mathematical). A dictionary definition is a form of mh-precisiation, with the definiens and definiendum playing the roles of precisiend and precisiand, respectively. Cointension is a qualitative measure of the proximity of meanings of the precisiend and precisiand. A precisiand is cointensive if its meaning is close to the meaning of the precisiend. A concept which plays a key role in the nontraditional view of fuzzy logic is that of a generalized constraint. If X is a variable then a generalized constraint on X, GC(X), is expressed as X isr R, where R is the constraining relation and r is an indexical variable which defines the modality of the constraint, that is, its semantics. The primary constraints are: possibilistic, (r=blank), probabilistic (r=p) and veristic (r=v). The standard constraints are: bivalent possibilistic, probabilistic and bivalent veristic. In large measure, science is based on standard constraints. Generalized constraints may be combined, qualified, projected, propagated and counterpropagated. The set of all generalized constraints, together with the rules which govern generation of generalized constraints, is referred to as the generalized constraint language, GCL. The standard constraint language, SCL, is a subset of GCL. In fuzzy logic, propositions, predicates and other semantic entities are precisiated through translation into GCL. Equivalently, a semantic entity, p, may be precisiated by representing its meaning as a generalized constraint. By construction, fuzzy logic has a much higher level of generality than bivalent logic. It is the generality of fuzzy logic that underlies much of what fuzzy logic has to offer. Among the important contributions of fuzzy logic are the following: 1.FL-generalization. Any bivalent-logic-based theory, T, may be FL-generalized, and hence upgraded, through addition to T of concepts and techniques drawn from fuzzy logic. Examples: fuzzy control, fuzzy linear programming, fuzzy probability theory and fuzzy topology.2.Linguistic variables and fuzzy if–then rules. The formalism of linguistic variables and fuzzy if–then rules is, in effect, a powerful modeling language which is widely used in applications of fuzzy logic. Basically, the formalism serves as a means of summarization and information compression through the use of granulation.3.Cointensive precisiation. Fuzzy logic has a high power of cointensive precisiation. This power is needed for a formulation of cointensive definitions of scientific concepts and cointensive formalization of human-centric fields such as economics, linguistics, law, conflict resolution, psychology and medicine.4.NL-Computation (computing with words). Fuzzy logic serves as a basis for NL-Computation, that is, computation with information described in natural language. NL-Computation is of direct relevance to mechanization of natural language understanding and computation with imprecise probabilities. More generally, NL-Computation is needed for dealing with second-order uncertainty, that is, uncertainty about uncertainty, or uncertainty2 for short. In summary, progression from bivalent logic to fuzzy logic is a significant positive step in the evolution of science. In large measure, the real-world is a fuzzy world. To deal with fuzzy reality what is needed is fuzzy logic. In coming years, fuzzy logic is likely to grow in visibility, importance and acceptance.}
}

@INPROCEEDINGS{equivalence_implications,  author={Ciftioglu, O.},  booktitle={FUZZ},   title={On the implication of equivalence of fuzzy systems to neural networks},   year={2003},  volume={1},  number={},  pages={19-24 vol.1},  
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/839006
@ARTICLE{fls_ann_equivalence,  author={Hong-Xing Li and Chen, C.L.P.},  journal={IEEE Transactions on Neural Networks},   title={The equivalence between fuzzy logic systems and feedforward neural networks},   year={2000},  volume={11},  number={2},  pages={356-365},  
}

% https://ieeexplore-ieee-org.prox.lib.ncsu.edu/document/977279
@ARTICLE{black_box_ext,  author={Castro, J.L. and Mantas, C.J. and Benitez, J.M.},  journal={IEEE Transactions on Neural Networks},   title={Interpretation of artificial neural networks by means of fuzzy rules},   year={2002},  volume={13},  number={1},  pages={101-116},  
}

@article{kosko_blue_book,
    author = {Kosko, Bart and Burgess, John C.},
    title = "{Neural Networks and Fuzzy Systems}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {103},
    number = {6},
    pages = {3131-3131},
    year = {1998},
    month = {06},
    issn = {0001-4966},
    doi = {10.1121/1.423096},
    url = {https://doi.org/10.1121/1.423096},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/103/6/3131/8084637/3131\_1\_online.pdf},
}

@article{kosko_unsupervised_1990,
	title = {Unsupervised learning in noise},
	volume = {1},
	issn = {1941-0093},
	doi = {10.1109/72.80204},
	abstract = {A new hybrid learning law, the differential competitive law, which uses the neuronal signal velocity as a local unsupervised reinforcement mechanism, is introduced, and its coding and stability behavior in feedforward and feedback networks is examined. This analysis is facilitated by the recent Gluck-Parker pulse-coding interpretation of signal functions in differential Hebbian learning systems. The second-order behavior of RABAM (random adaptive bidirectional associative memory) Brownian-diffusion systems is summarized by the RABAM noise suppression theorem: the mean-squared activation and synaptic velocities decrease exponentially quickly to their lower bounds, the instantaneous noise variances driving the system. This result is extended to the RABAM annealing model, which provides a unified framework from which to analyze Geman-Hwang combinatorial optimization dynamical systems and continuous Boltzmann machine learning.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Neural Networks},
	author = {Kosko, B.},
	month = mar,
	year = {1990},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Associative memory, Biological system modeling, Large-scale systems, Neural networks, Neurofeedback, Stability, Stochastic resonance, Stochastic system, Structural engineering, Unsupervised learning},
	pages = {44--57},
}

@article{quek_popfnn-aars_1999,
	title = {{POPFNN}-{AAR}({S}): a pseudo outer-product based fuzzy neural network},
	volume = {29},
	issn = {1941-0492},
	shorttitle = {{POPFNN}-{AAR}({S})},
	doi = {10.1109/3477.809038},
	abstract = {A novel fuzzy neural network, the pseudo outer-product-based fuzzy neural network using the singleton fuzzifier together with the approximate analogical reasoning schema, is proposed in this paper. The network is referred to as the singleton fuzzifier POPFNN-AARS, the singleton fuzzifier POPFNN-AARS employs the approximate analogical reasoning schema (AARS) instead of the commonly used truth value restriction (TVR) method. This makes the structure and learning algorithms of the singleton fuzzifier POPFNN-AARS simple and conceptually clearer than those of the POPFNN-TVR model. Different similarity measures (SM) and modification functions (FM) for AARS are investigated. The structures and learning algorithms of the proposed singleton fuzzifer POPFNN-AARS are presented. Several sets of real-life data are used to test the performance of the singleton fuzzifier POPFNN-AARS and their experimental results are presented for detailed discussion.},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Quek, C. and Zhou, R.W.},
	month = dec,
	year = {1999},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	keywords = {Computational complexity, Fuzzy neural network, Fuzzy reasoning, Handwriting recognition, Neuro-fuzzy network},
	pages = {859--870},
}

@inproceedings{zhou_pseudo_1996,
	title = {A pseudo outer-product based fuzzy neural network and its rule-identification algorithm},
	volume = {2},
	doi = {10.1109/ICNN.1996.549061},
	abstract = {A novel fuzzy neural network, called the pseudo outer-product based fuzzy neural network (POPFNN), is proposed in this paper. Similar to most existing fuzzy neural networks, the proposed POPFNN uses a self-organizing algorithm to learn and initialize the membership functions of the input and output variables from a set of training data. However, instead of employing the commonly used competitive learning, we proposed a novel one-pass lazy pseudo outer-product (LazyPOP) learning algorithm to identify the fuzzy rules that are supported by the training data. In contrast with other rule-identification algorithms the proposed LazyPOP learning algorithm is fast, reliable, and highly intuitive. Extensive experimental results and comparisons are presented.},
	booktitle = {Proceedings of {International} {Conference} on {Neural} {Networks} ({ICNN}'96)},
	author = {Zhou, R.W. and Quek, C.},
	month = jun,
	year = {1996},
	keywords = {Ambiguity criteria, Focusing criteria, Fuzzy logic, Fuzzy neural network, Fuzzy system, LazyPOP, Neural network, Neuro-fuzzy network, Noise criteria},
	pages = {1156--1161 vol.2},
}

@article{saad_structural_2020,
	title = {A {Structural} {Evolving} {Approach} for {Fuzzy} {Systems}},
	volume = {28},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2019.2904928},
	abstract = {A structural evolving approach (SEA) based on incremental partitioning learning is proposed in this paper. SEA starts with a simple fuzzy system with one fuzzy rule containing no fuzzy term for the antecedent part. After that, it keeps evolving by adding new fuzzy terms to the selected attribute in the selected partition. A new partitioning technique that locates sufficient splitting points is proposed. Furthermore, a dynamic partition-selection technique that leads to the best tradeoff between accuracy and interpretability is presented. In addition, a rule reduction mechanism that is able to locate rules with low and high impact on the system is developed. Finally, a local linear optimization is used to find the consequent parameters, which means that SEA uses only linear systems to find the antecedents and consequents parameters. Therefore, a simple and high interpretability system is offered. Six data sets are used to validate the performance of SEA with similar works. Despite the low complexity of SEA, the results show that SEA outperforms the existing methods with fewer fuzzy rules and fewer antecedent conditions too.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Sa’ad, Hisham Haider Yusef and Isa, Nor Ashidi Mat and Ahmed, Md. Manjur},
	month = feb,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Adaptive systems, Complexity theory, Error-driven method, Evolving fuzzy systems (EFSs), Evolving methods, Fuzzy systems, Greedy algorithm, Incremental learning, Linguistics, Optimization, Training},
	pages = {273--287},
}

@inproceedings{lewis_function_1995,
	title = {Function approximation by fuzzy systems},
	volume = {5},
	doi = {10.1109/ACC.1995.533841},
	abstract = {This paper provides an overview of our recent work on function approximation by fuzzy systems. Some scalar definitions in fuzzy logic control (FLC) are extended to the n-dimensional case, including the vector fuzzy number and membership vector. A mathematical expression is given for the function g(x) manufactured by a fuzzy system. It is shown that, under suitable assumptions, the fuzzy associative memory function g(x) is Lipschitz and approximates arbitrarily closely on compact set any specified continuous function. Relations are given between the accuracy of the approximation and the number of membership functions selected in each dimension. A major role is played in the analysis by the notion of the 'convex combination', which considerably simplifies the analysis compared to other approaches in the literature.},
	booktitle = {Proceedings of 1995 {American} {Control} {Conference} - {ACC}'95},
	author = {Lewis, F.L. and Zhu, S.Q. and Liu, K.},
	month = jun,
	year = {1995},
	keywords = {Associative memory, Automatic control, Function approximation, Fuzzy control, Fuzzy logic, Fuzzy sets, Fuzzy systems},
	pages = {3760--3764 vol.5},
}

@inproceedings{al-talabi_fuzzy_2017,
	title = {Fuzzy reinforcement learning algorithm for the pursuit-evasion differential games with superior evader},
	doi = {10.1109/CACS.2017.8284272},
	abstract = {This paper proposes a fuzzy reinforcement learning technique that enables a group of pursuers in pursuit-evasion (PE) differential games to learn how to capture a single superior evader in a decentralized manner. The superiority of the evader is in term of its maximum speed which means that this speed exceeds the maximum speed of the fastest pursuer in the game. The proposed learning technique uses a fuzzy actor-critic learning Automaton (FACLA) algorithm together with the so-called Apollonius circle technique and a specific formation control strategy which are used to define the necessary reward function for each pursuer. This enables each pursuer to update its value function accurately. Accordingly, the pursuer will take the right actions by tuning its fuzzy logic controller (FLC) parameters. The formation control strategy is also used such that during the capturing process the distribution angles of the pursuers around the evader are invariant as much as possible. Furthermore, it is also used to avoid a collision among them. It is assumed that the superior evader is an intelligent evader whose strategy is to continuously search for a gap during the evasion process by using the Apollonius circle method. If there is a gap, the evader will select its path through the gap to escape otherwise the evader will change its direction to increase the capture time. Simulation results are given to validate the proposed learning algorithm.},
	booktitle = {2017 {International} {Automatic} {Control} {Conference} ({CACS})},
	author = {Al-Talabi, Ahmad A.},
	month = nov,
	year = {2017},
	keywords = {Actor-critic, Fuzzy logic, Fuzzy logic controller, Game theory, Games, Mathematical model, Pursuit-evasion game, Reinforcement learning, Simulation, Tuning},
	pages = {1--6},
}

@misc{leandro_reverse_2016,
	title = {Reverse {Engineering} and {Symbolic} {Knowledge} {Extraction} on \{{\textbackslash}{L}\}ukasiewicz {Fuzzy} {Logics} using {Linear} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1604.02774},
	doi = {10.48550/arXiv.1604.02774},
	abstract = {This work describes a methodology to combine logic-based systems and connectionist systems. Our approach uses finite truth valued \{{\textbackslash}L\}ukasiewicz logic, where we take advantage of fact what in this type of logics every connective can be define by a neuron in an artificial network having by activation function the identity truncated to zero and one. This allowed the injection of first-order formulas in a network architecture, and also simplified symbolic rule extraction. Our method trains a neural network using Levenderg-Marquardt algorithm, where we restrict the knowledge dissemination in the network structure. We show how this reduces neural networks plasticity without damage drastically the learning performance. Making the descriptive power of produced neural networks similar to the descriptive power of \{{\textbackslash}L\}ukasiewicz logic language, simplifying the translation between symbolic and connectionist structures. This method is used in the reverse engineering problem of finding the formula used on generation of a truth table for a multi-valued \{{\textbackslash}L\}ukasiewicz logic. For real data sets the method is particularly useful for attribute selection, on binary classification problems defined using nominal attribute. After attribute selection and possible data set completion in the resulting connectionist model: neurons are directly representable using a disjunctive or conjunctive formulas, in the \{{\textbackslash}L\}ukasiewicz logic, or neurons are interpretations which can be approximated by symbolic rules. This fact is exemplified, extracting symbolic knowledge from connectionist models generated for the data set Mushroom from UCI Machine Learning Repository.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Leandro, Carlos},
	month = apr,
	year = {2016},
	note = {arXiv:1604.02774 [cs]},
}

@ARTICLE {gumbel_max_trick,
author = {I. M. Huijben and W. Kool and M. B. Paulus and R. G. van Sloun},
journal = {IEEE Transactions on Pattern Analysis &amp; Machine Intelligence},
title = {A Review of the Gumbel-max Trick and its Extensions for Discrete Stochasticity in Machine Learning},
year = {2023},
volume = {45},
number = {02},
issn = {1939-3539},
pages = {1353-1371},
abstract = {The Gumbel-max trick is a method to draw a sample from a categorical distribution, given by its unnormalized (log-)probabilities. Over the past years, the machine learning community has proposed several extensions of this trick to facilitate, e.g., drawing multiple samples, sampling from structured domains, or gradient estimation for error backpropagation in neural network optimization. The goal of this survey article is to present background about the Gumbel-max trick, and to provide a structured overview of its extensions to ease algorithm selection. Moreover, it presents a comprehensive outline of (machine learning) literature in which Gumbel-based algorithms have been leveraged, reviews commonly-made design choices, and sketches a future perspective.},
keywords = {data models;stochastic processes;random variables;laplace equations;computational modeling;standards;deep learning},
doi = {10.1109/TPAMI.2022.3157042},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {feb}
}

@InProceedings{network_morphism,
  title = 	 {Network Morphism},
  author = 	 {Wei, Tao and Wang, Changhu and Rui, Yong and Chen, Chang Wen},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {564--572},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/wei16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/wei16.html},
  abstract = 	 {We present a systematic study on how to morph a well-trained neural network to a new one so that its network function can be completely preserved. We define this as network morphism in this research. After morphing a parent network, the child network is expected to inherit the knowledge from its parent network and also has the potential to continue growing into a more powerful one with much shortened training time. The first requirement for this network morphism is its ability to handle diverse morphing types of networks, including changes of depth, width, kernel size, and even subnet. To meet this requirement, we first introduce the network morphism equations, and then develop novel morphing algorithms for all these morphing types for both classic and convolutional neural networks. The second requirement is its ability to deal with non-linearity in a network. We propose a family of parametric-activation functions to facilitate the morphing of any continuous non-linear activation neurons. Experimental results on benchmark datasets and typical neural networks demonstrate the effectiveness of the proposed network morphism scheme.}
}


@article{lin_neural_1995,
	series = {Modern {Fuzzy} {Control}},
	title = {A neural fuzzy control system with structure and parameter learning},
	volume = {70},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/016501149400216T},
	doi = {10.1016/0165-0114(94)00216-T},
	abstract = {A general connectionist model, called neural fuzzy control network (NFCN), is proposed for the realization of a fuzzy logic control system. The proposed NFCN is a feedforward multilayered network which integrates the basic elements and functions of a traditional fuzzy logic controller into a connectionist structure which has distributed learning abilities. The NFCN can be constructed from supervised training examples by machine learning techniques, and the connectionist structure can be trained to develop fuzzy logic rules and find membership functions. Associated with the NFCN is a two-phase hybrid learning algorithm which utilizes unsupervised learning schemes for structure learning and the backpropagation learning scheme for parameter learning. By combining both unsupervised and supervised learning schemes, the learning speed converges much faster than the original backpropagation algorithm. The two-phase hybrid learning algorithm requires exact supervised training data for learning. In some real-time applications, exact training data may be expensive or even impossible to obtain. To solve this problem, a reinforcement neural fuzzy control network (RNFCN) is further proposed. The RNFCN is constructed by integrating two NFCNs, one functioning as a fuzzy predictor and the other as a fuzzy controller. By combining a proposed on-line supervised structure-parameter learning technique, the temporal difference prediction method, and the stochastic exploratory algorithm, a reinforcement learning algorithm is proposed, which can construct a RNFCN automatically and dynamically through a reward-penalty signal (i.e., “good” or “bad” signal). Two examples are presented to illustrate the performance and applicability of the proposed models and learning algorithms.},
	language = {en},
	number = {2},
	urldate = {2023-01-05},
	journal = {Fuzzy Sets and Systems},
	author = {Lin, Chin-Teng},
	month = mar,
	year = {1995},
	keywords = {Connectionist, Fuzzy control, Fuzzy predictor, Gradient descent, Neural networks, Reinforcement learning, Supervised-unsupervised learning},
	pages = {183--212},
}

@article{ekemezie_self-organising_2001,
	title = {A {Self}-{Organising} {Fuzzy} {Logic} {Controller}},
	volume = {20},
	copyright = {Copyright (c)},
	issn = {2467-8821},
	url = {https://www.ajol.info/index.php/njt/article/view/123299},
	doi = {10.4314/njt.v20i1},
	abstract = {One major drawback of fuzzy logic controllers is the difficulty encountered in the construction of a rule- base that is suitable for the controlled process. In this paper we tackle this problem by proposing an algorithm that allows a designer to initially specify a possibly inaccurate rule-base, which is then made more and more accurate in the course of operation of the control system. The effectiveness of the proposed self-organizing procedure has been investigated by means of computer simulation. The results of the simulation studies indicate that the proposed algorithm is effective.},
	language = {en},
	number = {1},
	urldate = {2023-01-05},
	journal = {Nigerian Journal of Technology},
	author = {Ekemezie, P. N. and Osuagwu, C. C.},
	year = {2001},
	note = {Number: 1},
	pages = {1--10},
}

@article{khayat_novel_2009,
	title = {A novel hybrid algorithm for creating self-organizing fuzzy neural networks},
	volume = {73},
	issn = {0925-2312},
	url = {https://doi.org/10.1016/j.neucom.2009.06.013},
	doi = {10.1016/j.neucom.2009.06.013},
	abstract = {A novel hybrid algorithm based on a genetic algorithm and particle swarm optimization to design a fuzzy neural network, named self-organizing fuzzy neural network based on GA and PSO (SOFNNGAPSO), to implement Takagi-Sugeno (TS) type fuzzy models is proposed in this paper. The proposed algorithm, as a new hybrid algorithm, consists of two phases. A tuning based on TS's fuzzy model is applied to identify the fuzzy structure, and also a fuzzy cluster validity index is utilized to determine the optimal number of clusters. To obtain a more precision model, GA and PSO are performed to conduct fine tuning for the obtained parameter set of the premise parts and consequent parts in the aforementioned fuzzy model. The proposed algorithm is successfully applied to three tested examples.},
	number = {1-3},
	urldate = {2023-01-04},
	journal = {Neurocomputing},
	author = {Khayat, Omid and Ebadzadeh, Mohammad Mehdi and Shahdoosti, Hamid Reza and Rajaei, Ramin and Khajehnasiri, Iman},
	month = dec,
	year = {2009},
	keywords = {Fuzzy neural network, Genetic algorithm, Neuro-fuzzy network, Particle swarm optimization, Self-organizing, Xie-Beni index},
	pages = {517--524},
}

@article{figueroa-garcia_rule_2015,
	title = {Rule generation of fuzzy logic systems using a self-organized fuzzy neural network},
	volume = {151},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231214013307},
	doi = {10.1016/j.neucom.2014.09.079},
	abstract = {This paper proposes an algorithm for creating rules of a fuzzy logic system using a neuro-fuzzy approach. The proposal is based on the results of Juang and Tsao who use a Fuzzy Neural Network (FNN) to generate rules and fuzzy sets from input data. A time series example is solved using our proposal, which is tested using statistical analysis of the residuals of the model.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Neurocomputing},
	author = {Figueroa-García, Juan C. and Ochoa-Rey, Cynthia M. and Avellaneda-González, José A.},
	month = mar,
	year = {2015},
	keywords = {Fuzzy systems, Neural networks, Neuro-fuzzy network, Rule generation},
	pages = {955--962},
}

@article{tung_gensofnn_2002,
	title = {{GenSoFNN}: a generic self-organizing fuzzy neural network},
	volume = {13},
	issn = {1045-9227},
	shorttitle = {{GenSoFNN}},
	url = {http://ieeexplore.ieee.org/document/1031940/},
	doi = {10.1109/TNN.2002.1031940},
	abstract = {Existing neural fuzzy (neuro-fuzzy) networks proposed in the literature can be broadly classified into two groups. The first group is essentially fuzzy systems with self-tuning capabilities and requires an initial rule base to be specified prior to training. The second group of neural fuzzy networks, on the other hand, is able to automatically formulate the fuzzy rules from the numerical training data. No initial rule base needs to be specified prior to training. A cluster analysis is first performed on the training data and the fuzzy rules are subsequently derived through the proper connections of these computed clusters. However, most existing neural fuzzy systems (whether they belong to the first or second group) encountered one or more of the following major problems. They are 1) inconsistent rule-base; 2) heuristically defined node operations; 3) susceptibility to noisy training data and the stability–plasticity dilemma; and 4) needs for prior knowledge such as the number of clusters to be computed. Hence, a novel neural fuzzy system that is immune to the above-mentioned deficiencies is proposed in this paper. This new neural fuzzy system is named the generic self-organizing fuzzy neural network (GenSoFNN). The GenSoFNN network has strong noise tolerance capability by employing a new clustering technique known as discrete incremental clustering (DIC). The fuzzy rule base of the GenSoFNN network is consistent and compact as GenSoFNN has built-in mechanisms to identify and prune redundant and/or obsolete rules. Extensive simulations were conducted using the proposed GenSoFNN network and its performance is encouraging when benchmarked against other neural and neural fuzzy systems.},
	language = {en},
	number = {5},
	urldate = {2023-01-04},
	journal = {IEEE Transactions on Neural Networks},
	author = {Tung, W.L. and Quek, C.},
	month = sep,
	year = {2002},
	keywords = {Neuro-fuzzy network},
	pages = {1075--1086},
}

@article{ang_rspop_2005,
	title = {{RSPOP}: {Rough} {Set}-{Based} {Pseudo} {Outer}-{Product} {Fuzzy} {Rule} {Identification} {Algorithm}},
	volume = {17},
	shorttitle = {{RSPOP}},
	doi = {10.1162/0899766052530857},
	abstract = {System modeling with neuro-fuzzy systems involves two contradictory requirements: interpretability verses accuracy. The pseudo outer-product (POP) rule identification algorithm used in the family of pseudo outer-product-based fuzzy neural networks (POPFNN) suffered from an exponential increase in the number of identified fuzzy rules and computational complexity arising from high-dimensional data. This decreases the interpretability of the POPFNN in linguistic fuzzy modeling. This article proposes a novel rough set-based pseudo outer-product (RSPOP) algorithm that integrates the sound concept of knowledge reduction from rough set theory with the POP algorithm. The proposed algorithm not only performs feature selection through the reduction of attributes but also extends the reduction to rules without redundant attributes. As many possible reducts exist in a given rule set, an objective measure is developed for POPFNN to correctly identify the reducts that improve the inferred consequence. Experimental results are presented using published data sets and real-world application involving highway traffic flow prediction to evaluate the effectiveness of using the proposed algorithm to identify fuzzy rules in the POPFNN using compositional rule of inference and singleton fuzzifier (POPFNN-CRI(S)) architecture. Results showed that the proposed rough set-based pseudo outer-product algorithm reduces computational complexity, improves the interpretability of neuro-fuzzy systems by identifying significantly fewer fuzzy rules, and improves the accuracy of the POPFNN.},
	journal = {Neural computation},
	author = {Ang, Kai and Quek, Chai},
	month = feb,
	year = {2005},
	keywords = {Neuro-fuzzy network},
	pages = {205--43},
}

@article{ang_popfnn-cris_2003,
	title = {{POPFNN}-{CRI}(s): {Pseudo} {Outer} {Product} {Based} {Fuzzy} {Neural} {Network} {Using} the {Compositional} {Rule} of {Inference} and {Singleton} {Fuzzifier}},
	volume = {33},
	shorttitle = {{POPFNN}-{CRI}(s)},
	doi = {10.1109/TSMCB.2003.812850},
	abstract = {A pseudo-outer product based fuzzy neural network using the compositional rule of inference and singleton fuzzifier [POPFNN-CRI(S)] is proposed in this paper. The correspondence of each layer in the proposed POPFNN-CRI(S) to the compositional rule of inference using standard T-norm and fuzzy relation gives it a strong theoretical foundation. The proposed POPFNN-CRI(S) training consists of two phases; namely: the fuzzy membership derivation phase using the novel fuzzy Kohonen partition (FKP) and pseudo Kohonen partition (PFKP) algorithms, and the rule identification phase using the novel one-pass POP learning algorithm. The proposed two-phase learning process effectively constructs the membership functions and identifies the fuzzy rules. Extensive experimental results based on the classification performance of the POPFNN-CRI(S) using the Anderson's Iris data are presented for discussion. Results show that the POPFNN-CRI(S) has taken only 15 training iterations and misclassify only three out of all the 150 patterns in the Anderson's Iris data.},
	journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
	author = {Ang, Kai and Quek, Chai and Pasquier, Michel},
	month = feb,
	year = {2003},
	keywords = {Neuro-fuzzy network},
	pages = {838--49},
}

@article{das_ierspop_2016,
	title = {{ieRSPOP}: {A} novel incremental rough set-based pseudo outer-product with ensemble learning},
	volume = {46},
	issn = {1568-4946},
	shorttitle = {{ieRSPOP}},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494616301636},
	doi = {10.1016/j.asoc.2016.04.015},
	abstract = {The rough set-based pseudo outer-product fuzzy neural network (RSPOP FNN) is a member of the pseudo outer-product (POP) FNN family known for high accuracy and interpretability. The POP algorithm utilizes a one-pass rule identification and generation process and rough set theory to perform attribute and rule reduction, hence, producing highly interpretable if-then fuzzy rules while maintaining a high level of accuracy. However, non-incremental systems are heavily dependant on the quality and quantity of the training set, an issue especially prominent in time series data. The robustness of RSPOP FNN is improved using an adapted form of discrete incremental clustering (DIC), an incremental learning algorithm. This renders the system immune to deficiencies in the training set. Issues with the incremental rough set attribute reduction are also addressed using an adapted form of Learn++ Non-Stationary Environments (Learn++.NSE), a form of ensemble learning strong in datasets with the concept drift phenomenon. This is often found in time series data. The proposed system has been extensively benchmarked in traffic flow prediction, real life stock price and volatility predictions. The results show the strength of the online systems against offline systems. The promising results demonstrated the benefit of incremental learning in the accuracy and adaptability of its time series prediction ability.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {Das, Ron Tor and Ang, Kai Keng and Quek, Chai},
	month = sep,
	year = {2016},
	keywords = {Attribute and rule reduction, Highly interpretable, Neuro-fuzzy network, One-pass rule identification and generation process, Pseudo outer-product, Real life stock price prediction, Rough set theory, Traffic flow prediction, Volatility prediction},
	pages = {170--186},
}

@book{favieiro_proposal_2012,
	title = {Proposal of a {Neuro} {Fuzzy} {System} for {Myoelectric} {Signal} {Analysis} from {Hand}-{Arm} {Segment}},
	isbn = {978-953-51-0805-4},
	url = {https://www.intechopen.com/state.item.id},
	abstract = {Open access peer-reviewed chapter},
	language = {en},
	urldate = {2023-01-04},
	publisher = {IntechOpen},
	author = {Favieiro, Gabriela Winkler and Balbinot, Alexandre and Favieiro, Gabriela Winkler and Balbinot, Alexandre},
	month = oct,
	year = {2012},
	doi = {10.5772/48793},
	note = {Publication Title: Computational Intelligence in Electromyography Analysis - A Perspective on Current Applications and Future Challenges},
	keywords = {Neuro-fuzzy network},
}

@article{nauck_neuro-fuzzy_1997,
	series = {Application of {Neuro}-{Fuzzy} {Systems}},
	title = {A neuro-fuzzy method to learn fuzzy classification rules from data},
	volume = {89},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011497000092},
	doi = {10.1016/S0165-0114(97)00009-2},
	abstract = {Neuro-fuzzy systems have recently gained a lot of interest in research and application. Neuro-fuzzy models as we understand them are fuzzy systems that use local learning strategies to learn fuzzy sets and fuzzy rules. Neuro-fuzzy techniques have been developed to support the development of e.g. fuzzy controllers and fuzzy classifiers. In this paper we discuss a learning method for fuzzy classification rules. The learning algorithm is a simple heuristics that is able to derive fuzzy rules from a set of training data very quickly, and tunes them by modifying parameters of membership functions. Our approach is based on NEFCLASS, a neuro-fuzzy model for pattern classification. We also discuss some results obtained by our software implementation of NEFCLASS, which is freely available on the Internet.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Nauck, Detlef and Kruse, Rudolf},
	month = aug,
	year = {1997},
	keywords = {Fuzzy classification, Neuro-fuzzy network, Neuro-fuzzy system},
	pages = {277--288},
}

@article{liu_novel_2007,
	title = {A {Novel} {Generic} {Hebbian} {Ordering}-{Based} {Fuzzy} {Rule} {Base} {Reduction} {Approach} to {Mamdani} {Neuro}-{Fuzzy} {System}},
	volume = {19},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.2007.19.6.1656},
	doi = {10.1162/neco.2007.19.6.1656},
	abstract = {There are two important issues in neuro-fuzzy modeling: (1) interpretability—the ability to describe the behavior of the system in an interpretable way—and (2) accuracy—the ability to approximate the outcome of the system accurately. As these two objectives usually exert contradictory requirements on the neuro-fuzzy model, certain compromise has to be undertaken. This letter proposes a novel rule reduction algorithm, namely, Hebb rule reduction, and an iterative tuning process to balance interpretability and accuracy. The Hebb rule reduction algorithm uses Hebbian ordering, which represents the degree of coverage of the samples by the rule, as an importance measure of each rule to merge the membership functions and hence reduces the number of the rules. Similar membership functions (MFs) are merged by a specified similarity measure in an order of Hebbian importance, and the resultant equivalent rules are deleted from the rule base. The rule with a higher Hebbian importance will be retained among a set of rules. The MFs are tuned through the least mean square (LMS) algorithm to reduce the modeling error. The tuning of the MFs and the reduction of the rules proceed iteratively to achieve a balance between interpretability and accuracy. Three published data sets by Nakanishi (Nakanishi, Turksen, \&amp; Sugeno, 1993), the Pat synthetic data set (Pal, Mitra, \&amp; Mitra, 2003), and the traffic flow density prediction data set are used as benchmarks to demonstrate the effectiveness of the proposed method. Good interpretability, as well as high modeling accuracy, are derivable simultaneously and are suitably benchmarked against other well-established neuro-fuzzy models.},
	number = {6},
	urldate = {2023-01-04},
	journal = {Neural Computation},
	author = {Liu, Feng and Quek, Chai and Ng, Geok See},
	month = jun,
	year = {2007},
	keywords = {Neuro-fuzzy network},
	pages = {1656--1680},
}

@article{ang_stock_2006,
	title = {Stock {Trading} {Using} {RSPOP}: {A} {Novel} {Rough} {Set}-{Based} {Neuro}-{Fuzzy} {Approach}},
	volume = {17},
	issn = {1045-9227, 1941-0093},
	shorttitle = {Stock {Trading} {Using} {RSPOP}},
	url = {http://ieeexplore.ieee.org/document/1687938/},
	doi = {10.1109/TNN.2006.875996},
	abstract = {This paper investigates the method of forecasting stock price difference on artiﬁcially generated price series data using neuro-fuzzy systems and neural networks. As trading proﬁts is more important to an investor than statistical performance, this paper proposes a novel rough set-based neuro-fuzzy stock trading decision model called stock trading using rough set-based pseudo outer-product (RSPOP) which synergizes the price difference forecast method with a forecast bottleneck free trading decision model. The proposed stock trading with forecast model uses the pseudo outer-product based fuzzy neural network using the compositional rule of inference [POPFNN-CRI(S)] with fuzzy rules identiﬁed using the RSPOP algorithm as the underlying predictor model and simple moving average trading rules in the stock trading decision model. Experimental results using the proposed stock trading with RSPOP forecast model on real world stock market data are presented. Trading proﬁts in terms of portfolio end values obtained are benchmarked against stock trading with dynamic evolving neural-fuzzy inference system (DENFIS) forecast model, the stock trading without forecast model and the stock trading with ideal forecast model. Experimental results showed that the proposed model identiﬁed rules with greater interpretability and yielded signiﬁcantly higher proﬁts than the stock trading with DENFIS forecast model and the stock trading without forecast model.},
	language = {en},
	number = {5},
	urldate = {2023-01-04},
	journal = {IEEE Transactions on Neural Networks},
	author = {Ang, K.K. and Quek, C.},
	month = sep,
	year = {2006},
	keywords = {Neuro-fuzzy network},
	pages = {1301--1315},
}

@article{liu_rs-herr_2021,
	title = {{RS}-{HeRR}: a rough set-based {Hebbian} rule reduction neuro-fuzzy system},
	volume = {33},
	issn = {1433-3058},
	shorttitle = {{RS}-{HeRR}},
	url = {https://doi.org/10.1007/s00521-020-04997-2},
	doi = {10.1007/s00521-020-04997-2},
	abstract = {Interpretabilty is one of the desired characteristics in various classification task. Rule-based system and fuzzy logic can be used for interpretation in classification. The main drawback of rule-based system is that it may contain large complex rules for classification and sometimes it becomes very difficult in interpretation. Rule reduction is also difficult for various reasons. Removing important rules may effect in classification accuracy. This paper proposes a hybrid fuzzy-rough set approach named RS-HeRR for the generation of effective, interpretable and compact rule set. It combines a powerful rule generation and reduction fuzzy system, called Hebbian-based rule reduction algorithm (HeRR) and a novel rough-set-based attribute selection algorithm for rule reduction. The proposed hybridization leverages upon rule reduction through reduction in partial dependency as well as improvement in system performance to significantly reduce the problem of redundancy in HeRR, even while providing similar or better accuracy. RS-HeRR demonstrates these characteristics repeatedly over four diverse practical classification problems, such as diabetes identification, urban water treatment monitoring, sonar target classification, and detection of ovarian cancer. It also demonstrates excellent performance for highly biased datasets. In addition, it competes very well with established non-fuzzy classifiers and outperforms state-of-the-art methods that use rough sets for rule reduction in fuzzy systems.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {Neural Computing and Applications},
	author = {Liu, Feng and Sekh, Arif Ahmed and Quek, Chai and Ng, Geok See and Prasad, Dilip K.},
	month = feb,
	year = {2021},
	keywords = {Hebbian-based rule reduction, Neuro-fuzzy network, Neuro-fuzzy system, Pattern classification, Rough set, Rule reduction},
	pages = {1123--1137},
}

@article{kim_hybrid_1999,
	title = {Hybrid neuro-fuzzy inference systems and their application for on-line adaptive learning of nonlinear dynamical systems},
	url = {https://ourarchive.otago.ac.nz/handle/10523/1116},
	abstract = {In this paper, an adaptive neuro-fuzzy system, called HyFIS, is proposed to build and optimise fuzzy models. The proposed model introduces the learning power of neural networks into the fuzzy logic systems and provides linguistic meaning to the connectionist architectures. Heuristic fuzzy logic rules and input-output fuzzy membership functions can be optimally tuned from training examples by a hybrid learning scheme composed of two phases: the phase of rule generation from data, and the phase of rule tuning by using the error backpropagation learning scheme for a neural fuzzy system. In order to illustrate the performance and applicability of the proposed neuro-fuzzy hybrid model, extensive simulation studies of nonlinear complex dynamics are carried out. The proposed method can be applied to on-line incremental adaptive leaning for the purpose of prediction and control of non-linear dynamical systems.},
	language = {en},
	urldate = {2023-01-04},
	author = {Kim, Jaesoo and Kasabov, Nikola},
	month = mar,
	year = {1999},
	note = {Accepted: 2011-04-07T03:06:37Z
Publisher: University of Otago},
	keywords = {Neuro-fuzzy network},
}

@inproceedings{bayardo_mining_1999,
	address = {San Diego, California, United States},
	title = {Mining the most interesting rules},
	isbn = {978-1-58113-143-7},
	url = {http://portal.acm.org/citation.cfm?doid=312129.312219},
	doi = {10.1145/312129.312219},
	abstract = {Several algorithms have been proposed for finding the “best,” “optimal,” or “most interesting” rule(s) in a database according to a variety of metrics including confidence, support, gain, chi-squared value, gini, entropy gain, laplace, lift, and conviction. In this paper, we show that the best rule according to any of these metrics must reside along a support/confidence border. Further, in the case of conjunctive rule mining within categorical data, the number of rules along this border is conveniently small, and can be mined efficiently from a variety of real-world data-sets. We also show how this concept can be generalized to mine all rules that are best according to any of these criteria with respect to an arbitrary subset of the population of interest. We argue that by returning a broader set of rules than previous algorithms, our techniques allow for improved insight into the data and support more user-interaction in the optimized rule-mining process.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Proceedings of the fifth {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining  - {KDD} '99},
	publisher = {ACM Press},
	author = {Bayardo, Roberto J. and Agrawal, Rakesh},
	year = {1999},
	pages = {145--154},
}

@misc{noauthor_probabilistic_nodate,
	title = {A {Probabilistic} {Comparison} of {Commonly} {Used} {Interest} {Measures} for {Association} {Rules}},
	url = {https://mhahsler.github.io/arules/docs/measures},
	urldate = {2023-01-04},
}

@misc{noauthor_neucom_nodate,
	title = {{NeuCom} - {A} {Neuro}-computing {Decision} {Support} {Enviroment} - {KEDRI} - {AUT}},
	url = {https://kedri.aut.ac.nz/research-groups/data-mining-and-big-data-group/neucom-a-neuro-computing-decision-support-enviroment},
	urldate = {2023-01-04},
}

@article{ghosh_role_2011,
	title = {Role of {Certainty} {Factor} in {Generating} {Rough}-{Fuzzy} {Rule}},
	volume = {1},
	doi = {10.5121/ijcsea.2011.1604},
	abstract = {The generation of effective feature-based rules is essential to the development of any intelligent system. This paper presents an approach that integrates a powerful fuzzy rule generation algorithm with a rough set-assisted feature reduction method to generate diagnostic rule with a certainty factor. Certainty factor of each rule is calculated by considering both the membership value of each linguistic term introduced at time of fuzzyfication of data as well as possibility values, due to inconsistent data, generated by rough set theory at time of rule generation. In time of knowledge inferencing in an intelligent system, certainty factor of each rule will play an important role to find out the appropriate rule to be selected. Experimental results demonstrate the superiority of our approach.},
	journal = {International Journal of Computer Science, Engineering and Applications},
	author = {Ghosh, Jyotirmoy and Mukhopadhyay, S},
	month = dec,
	year = {2011},
}

@article{chai_mamdani_2009,
	title = {Mamdani {Model} based {Adaptive} {Neural} {Fuzzy} {Inference} {System} and its {Application}},
	volume = {5},
	abstract = {Hybrid algorithm is the hot issue in Computational Intelligence (CI) study. From in-depth discussion on Simulation Mechanism Based (SMB) classification method and composite pat- terns, this paper presents the Mamdani model based Adaptive Neural Fuzzy Inference System (M-ANFIS) and weight updating formula in consideration with qualitative representation of inference consequent parts in fuzzy neural networks. M-ANFIS model adopts Mamdani fuzzy inference system which has advantages in consequent part. Experiment results of applying M-ANFIS to evaluate traffic Level of service show that M-ANFIS, as a new hybrid algorithm in com- putational intelligence, has great advantages in non-linear modeling, membership functions in consequent parts, scale of training data and amount of adjusted parameters.},
	author = {Chai, Yuanyuan and Jia, Limin and Zhang, Zundong},
	month = jan,
	year = {2009},
}

@inproceedings{liu_categorizing_2021,
	address = {Online Streaming, --- Select a Country ---},
	title = {Categorizing {Quantities} using an {Interactive} {Fuzzy} {Membership} {Function}:},
	isbn = {978-989-758-488-6},
	shorttitle = {Categorizing {Quantities} using an {Interactive} {Fuzzy} {Membership} {Function}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010270801950202},
	doi = {10.5220/0010270801950202},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Proceedings of the 16th {International} {Joint} {Conference} on {Computer} {Vision}, {Imaging} and {Computer} {Graphics} {Theory} and {Applications}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Liu, Liqun and Vuillemot, Romain},
	year = {2021},
	pages = {195--202},
}

@misc{noauthor_certainty_nodate,
	title = {Certainty {Factor} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/computer-science/certainty-factor},
	urldate = {2023-01-04},
}

@article{hosseini_review_2012,
	title = {Review of {Medical} {Image} {Classification} using the {Adaptive} {Neuro}-{Fuzzy} {Inference} {System}},
	volume = {2},
	issn = {2228-7477},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3592505/},
	abstract = {Image classification is an issue that utilizes image processing, pattern recognition and classification methods. Automatic medical image classification is a progressive area in image classification, and it is expected to be more developed in the future. Because of this fact, automatic diagnosis can assist pathologists by providing second opinions and reducing their workload. This paper reviews the application of the adaptive neuro-fuzzy inference system (ANFIS) as a classifier in medical image classification during the past 16 years. ANFIS is a fuzzy inference system (FIS) implemented in the framework of an adaptive fuzzy neural network. It combines the explicit knowledge representation of an FIS with the learning power of artificial neural networks. The objective of ANFIS is to integrate the best features of fuzzy systems and neural networks. A brief comparison with other classifiers, main advantages and drawbacks of this classifier are investigated.},
	number = {1},
	urldate = {2023-01-04},
	journal = {Journal of Medical Signals and Sensors},
	author = {Hosseini, Monireh Sheikh and Zekri, Maryam},
	year = {2012},
	pmid = {23493054},
	pmcid = {PMC3592505},
	pages = {49--60},
}

@article{dwivedi_handling_nodate,
	title = {Handling {Uncertainties} - using {Probability} {Theory} to {Possibility} {Theory}},
	language = {en},
	author = {Dwivedi, Ashutosh and Mishra, D},
}

@incollection{kreinovich_relationships_2017,
	address = {Cham},
	title = {Relationships {Between} {Probability} and {Possibility} {Theories}},
	volume = {683},
	isbn = {978-3-319-51051-4 978-3-319-51052-1},
	url = {http://link.springer.com/10.1007/978-3-319-51052-1_7},
	abstract = {The goal of a new area of Computing with Words (CWW) is solving computationally tasks formulated in a natural language (NL). The extreme uncertainty of NL is the major challenge to meet this ambitious goal requiring computational approaches to handle NL uncertainties. Attempts to solve various CWW tasks lead to the methodological questions about rigorous and heuristic formulations and solutions of the CWW tasks. These attempts immediately reincarnated the long-time discussion about different methodologies to model uncertainty, namely: Probability Theory, Multi-valued logic, Fuzzy Sets, Fuzzy Logic, and the Possibility theory. The main forum of the recent discussion was an on-line Berkeley Initiative on Soft Computing group in 2014. Zadeh claims that some computing with words tasks are in the province of the fuzzy logic and possibility theory, and probabilistic solutions are not appropriate for these tasks. In this work we propose a useful constructive probabilistic approach for CWW based on sets of specialized K-Measure (Kolmogorov’s measure) probability spaces that differs from the random sets. This work clarifies the relationships between probability and possibility theories in the context of CWW.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Uncertainty {Modeling}},
	publisher = {Springer International Publishing},
	author = {Kovalerchuk, Boris},
	editor = {Kreinovich, Vladik},
	year = {2017},
	doi = {10.1007/978-3-319-51052-1_7},
	note = {Series Title: Studies in Computational Intelligence},
	pages = {97--122},
}

@article{liu_implementation_2020,
	title = {{THE} {IMPLEMENTATION} {OF} {HESITANT} {FUZZY} {SPATIAL} {CO}-{LOCATION} {PATTERN} {MINING} {ALGORITHM} {BASED} {ON} {PYTHON}},
	volume = {XLII-3/W10},
	doi = {10.5194/isprs-archives-XLII-3-W10-763-2020},
	abstract = {As one of the important research directions in the spatial data mining, spatial co-location pattern mining aimed at finding the spatial features whose the instances are frequent co-locate in neighbouring domain. With the introduction of fuzzy sets into traditional spatial co-location pattern mining, the research on fuzzy spatial co-location pattern mining has been deepened continuously, which extends traditional spatial co-location pattern mining to deal with fuzzy spatial objects and discover their laws of spatial symbiosis. In this paper, the operation principle of a classical join-based algorithm for mining spatial co-location patterns is briefly described firstly. Then, combining with the definition of classical participation rate and participation degree, a novel hesitant fuzzy spatial co-location pattern mining algorithm is proposed based on the establishment of the hesitant fuzzy participation rate and hesitant fuzzy participation formula according to the characteristics in fusion of hesitant fuzzy set theory, the score function and spatial co-location pattern mining. Finally, the proposed algorithm is written and implemented based on Python language, which uses a NumPy system to the expansion of the open source numerical calculation. The Python program of the proposed algorithm includes the method of computing hesitant fuzzy membership based on score function, the implementation of generating k-order candidate patterns, k-order frequent patterns and k-order table instances. A hesitant fuzzy spatial co-location pattern mining experiment is carried out and the experimental results show that the proposed and implemented algorithm is effective and feasible.},
	journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Liu, Z. and Wei, B. and Kang, C. and Jiang, J.},
	month = feb,
	year = {2020},
	pages = {763--767},
}

@article{kruse_fuzzy_2008,
	title = {Fuzzy neural network},
	volume = {3},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Fuzzy_neural_network},
	doi = {10.4249/scholarpedia.6043},
	language = {en},
	number = {11},
	urldate = {2023-01-04},
	journal = {Scholarpedia},
	author = {Kruse, Rudolf},
	month = nov,
	year = {2008},
	pages = {6043},
}

@article{jennings_developing_2010,
	title = {Developing {Creativity}: {Artificial} {Barriers} in {Artificial} {Intelligence}},
	volume = {20},
	issn = {1572-8641},
	shorttitle = {Developing {Creativity}},
	url = {https://doi.org/10.1007/s11023-010-9206-y},
	doi = {10.1007/s11023-010-9206-y},
	abstract = {The greatest rhetorical challenge to developers of creative artificial intelligence systems is convincingly arguing that their software is more than just an extension of their own creativity. This paper suggests that “creative autonomy,” which exists when a system not only evaluates creations on its own, but also changes its standards without explicit direction, is a necessary condition for making this argument. Rather than requiring that the system be hermetically sealed to avoid perceptions of human influence, developing creative autonomy is argued to be more plausible if the system is intimately embedded in a broader society of other creators and critics. Ideas are presented for constructing systems that might be able to achieve creative autonomy.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {Minds and Machines},
	author = {Jennings, Kyle E.},
	month = nov,
	year = {2010},
	keywords = {Autonomy, Computational creativity, Socially-inspired computing},
	pages = {489--501},
}

@incollection{chawla_framework_2009,
	address = {Berlin, Heidelberg},
	title = {A {Framework} for {Mining} {Fuzzy} {Association} {Rules} from {Composite} {Items}},
	volume = {5433},
	isbn = {978-3-642-00398-1 978-3-642-00399-8},
	url = {http://link.springer.com/10.1007/978-3-642-00399-8_6},
	abstract = {A novel framework is described for mining fuzzy Association Rules (ARs) relating the properties of composite attributes, i.e. attributes or items that each feature a number of values derived from a common schema. To apply fuzzy Association Rule Mining (ARM) we partition the property values into fuzzy property sets. This paper describes: (i) the process of deriving the fuzzy sets (Composite Fuzzy ARM or CFARM) and (ii) a unique property ARM algorithm founded on the correlation factor interestingness measure. The paper includes a complete analysis, demonstrating: (i) the potential of fuzzy property ARs, and (ii) that a more succinct set of property ARs (than that generated using a non-fuzzy method) can be produced using the proposed approach.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {New {Frontiers} in {Applied} {Data} {Mining}},
	publisher = {Springer Berlin Heidelberg},
	author = {Muyeba, Maybin and Khan, M. Sulaiman and Coenen, Frans},
	editor = {Chawla, Sanjay and Washio, Takashi and Minato, Shin-ichi and Tsumoto, Shusaku and Onoda, Takashi and Yamada, Seiji and Inokuchi, Akihiro},
	year = {2009},
	doi = {10.1007/978-3-642-00399-8_6},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {62--74},
}

@inproceedings{kolman_knowledge_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Knowledge {Extraction} from {Neural} {Networks} {Using} the {All}-{Permutations} {Fuzzy} {Rule} {Base}: {The} {LED} {Display} {Recognition} {Problem}},
	isbn = {978-3-540-32106-4},
	shorttitle = {Knowledge {Extraction} from {Neural} {Networks} {Using} the {All}-{Permutations} {Fuzzy} {Rule} {Base}},
	doi = {10.1007/11494669_150},
	abstract = {A major drawback of artificial neural networks is their black-box character. In this paper, we use the equivalence between artificial neural networks and a specific fuzzy rule base to extract the knowledge embedded in the network. We demonstrate this using a benchmark problem: the recognition of digits produced by a LED device. The method provides a symbolic and comprehensible description of the knowledge learned by the network during its training.},
	language = {en},
	booktitle = {Computational {Intelligence} and {Bioinspired} {Systems}},
	publisher = {Springer},
	author = {Kolman, Eyal and Margaliot, Michael},
	editor = {Cabestany, Joan and Prieto, Alberto and Sandoval, Francisco},
	year = {2005},
	pages = {1222--1229},
}

@article{averkin_fuzzy_nodate,
	title = {Fuzzy {Rules} {Extraction} from {Deep} {Neural} {Networks}},
	abstract = {This article presents the basic methods of machine learning and explanational artificial intelligence that can help in the issue of extracting rules and other models of knowledge representation not only from data, but from the artificial neural networks themselves. The paper discusses classification methods for rule-based learning methods for neural networks and the current state of technologies for extracting rules from neural networks. Next, we formulate the main problems that arise when extracting rules from neural networks, as well as the main methods for solving them.},
	language = {en},
	author = {Averkin, Alexey and Yarushev, Sergey},
}

@article{gevaert_distillation_nodate,
	title = {Distillation of {Deep} {Reinforcement} {Learning} {Models} using {Fuzzy} {Inference} {Systems}},
	language = {en},
	author = {Gevaert, Arne and Peck, Jonathan and Saeys, Yvan},
}

@article{ahmed_information_2015,
	title = {Information granularity model for evolving context-based fuzzy system},
	volume = {33},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494615002264},
	doi = {10.1016/j.asoc.2015.04.012},
	abstract = {An information granule has to be translated into significant frameworks of granular computing to realize interpretability–accuracy tradeoff. These two objectives are in conflict and constitute an open problem. A new operational framework to form the evolving information granule (EIG) is developed in this paper, which ensures a compromise between interpretability and reasonable accuracy. The evolving information granule is initiated with the first information granule by translating the knowledge of the entire output domain. The initial information granule is considered an underfitting state with a high approximation error. Then, the EIG starts evolving in the information granule by partitioning the output domain and uses a dynamic constraint to maintain semantic interpretability in the output-contexts. The important criterion in the EIG is to determine the prominent distinction (output-context) in the output domain and realize the distinct information granule that depicts the semantics at the fuzzy partition level. The EIG tends to evolve toward the lower error region and realizes the effective rulebase by avoiding overfitting. The outcome on the synthetic and real-world data using the EIG shows the effectiveness of the proposed system, which outperforms state-of-the art methods.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {Ahmed, Md. Manjur and Mat Isa, Nor Ashidi},
	month = aug,
	year = {2015},
	keywords = {Dynamic constraint, Evolving system, Information granule, Output-context fuzzy system, Overfitting state},
	pages = {183--196},
}

@inproceedings{smarandache_geometric_2011,
	address = {Kaohsiung, Taiwan},
	title = {A geometric interpretation of the neutrosophic set \&\#x2014; {A} generalization of the intuitionistic fuzzy set},
	isbn = {978-1-4577-0371-3 978-1-4577-0372-0},
	url = {http://ieeexplore.ieee.org/document/6122665/},
	doi = {10.1109/GRC.2011.6122665},
	abstract = {In this paper we give a geometric interpretation of the Neutrosophic Set using the Neutrosophic Cube. Distinctions between the neutrosophic set and intuitionistic fuzzy set are also presented.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {2011 {IEEE} {International} {Conference} on {Granular} {Computing}},
	publisher = {IEEE},
	author = {Smarandache, Florentin},
	month = nov,
	year = {2011},
	pages = {602--606},
}

@article{zhang_comprehensive_2015,
	title = {A {Comprehensive} {Survey} on {Particle} {Swarm} {Optimization} {Algorithm} and {Its} {Applications}},
	volume = {2015},
	issn = {1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2015/931256/},
	doi = {10.1155/2015/931256},
	abstract = {Particle swarm optimization (PSO) is a heuristic global optimization method, proposed originally by Kennedy and Eberhart in 1995. It is now one of the most commonly used optimization techniques. This survey presented a comprehensive investigation of PSO. On one hand, we provided advances with PSO, including its modifications (including quantum-behaved PSO, bare-bones PSO, chaotic PSO, and fuzzy PSO), population topology (as fully connected, von Neumann, ring, star, random, etc.), hybridization (with genetic algorithm, simulated annealing, Tabu search, artificial immune system, ant colony algorithm, artificial bee colony, differential evolution, harmonic search, and biogeography-based optimization), extensions (to multiobjective, constrained, discrete, and binary optimization), theoretical analysis (parameter selection and tuning, and convergence analysis), and parallel implementation (in multicore, multiprocessor, GPU, and cloud computing forms). On the other hand, we offered a survey on applications of PSO to the following eight fields: electrical and electronic engineering, automation control systems, communication theory, operations research, mechanical engineering, fuel and energy, medicine, chemistry, and biology. It is hoped that this survey would be beneficial for the researchers studying PSO algorithms.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Mathematical Problems in Engineering},
	author = {Zhang, Yudong and Wang, Shuihua and Ji, Genlin},
	month = oct,
	year = {2015},
	note = {Publisher: Hindawi},
	pages = {e931256},
}

@article{jafarlou_improving_nodate,
	title = {Improving {Fuzzy}-{Logic} based {Map}-{Matching} {Method} with {Trajectory} {Stay}-{Point} {Detection}},
	abstract = {The requirement to trace and process moving objects in the contemporary era gradually increases since numerous applications quickly demand precise moving object locations. The Map-matching method is employed as a preprocessing technique, which matches a moving object point on a corresponding road. However, most of the GPS trajectory datasets include stay-points irregularity, which makes mapmatching algorithms mismatch trajectories to irrelevant streets. Therefore, determining the stay-point region in GPS trajectory datasets result in better accurate matching and more rapid approaches. In this work, we cluster stay-points in a trajectory dataset with DBSCAN and eliminate redundant data to improve the efficiency of the map-matching algorithm by lowering processing time. We reckoned our proposed method’s performance and exactness with a ground truth dataset compared to a fuzzy-logic based map-matching algorithm. Fortunately, our approach yields 27.39\% data size reduction and 8.9\% processing time reduction with the same accurate results as the previous fuzzy-logic based map-matching approach.},
	language = {en},
	author = {Jafarlou, Minoo},
	keywords = {DBSCAN},
}

@article{aranibay_learning_nodate,
	title = {Learning fuzzy logic from examples},
	language = {en},
	author = {Aranibay, Luis Alfonso Quiroga},
}

@article{burda_interest_2014,
	title = {Interest {Measures} for {Fuzzy} {Association} {Rules} {Based} on {Expectations} of {Independence}},
	volume = {2014},
	issn = {1687-7101},
	url = {https://www.hindawi.com/journals/afs/2014/197876/},
	doi = {10.1155/2014/197876},
	abstract = {Lift, leverage, and conviction are three of the best commonly known interest measures for crisp association rules. All of them are based on a comparison of observed support and the support that is expected if the antecedent and consequent part of the rule were stochastically independent. The aim of this paper is to provide a correct definition of lift, leverage, and conviction measures for fuzzy association rules and to study some of their interesting mathematical properties.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Advances in Fuzzy Systems},
	author = {Burda, Michal},
	month = oct,
	year = {2014},
	note = {Publisher: Hindawi},
	pages = {e197876},
}

@book{adeli_machine_1994,
	title = {Machine {Learning}: {Neural} {Networks}, {Genetic} {Algorithms}, and {Fuzzy} {Systems}},
	isbn = {978-0-471-01633-5},
	shorttitle = {Machine {Learning}},
	abstract = {rtificial Intelligence/Neural Networks Cutting-edge approaches to designing machine learning technologies … One of the most fascinating and promising developments to emerge in the field of artificial intelligence over the past decade has been machine learning. While automatic learning is still in its infancy, enormous strides have already been made toward developing expert computing systems with an impressive degree of learning capability. This book offers in-depth coverage of the latest developments in machine learning algorithms using object-oriented programming, neural nets, genetic algorithms, and fuzzy systems. While they concentrate most heavily on neural nets, the authors describe a number of ingenious new ways of integrating neural learning models with other, fundamentally different problem-solving paradigms to create powerful hybrids that can radically improve the learning and decision-making skills of computing systems.The only book to apply neural nets, genetic algorithms, and fuzzy systems to the field of machine learningIncludes many specific algorithmsPresents applications in the domains of image recognition and engineering design},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Adeli, Hojjat and Hung, Shih-Lin},
	month = sep,
	year = {1994},
}

@article{hullermeier_fuzzy_2005,
	title = {Fuzzy methods in machine learning and data mining: {Status} and prospects},
	volume = {156},
	issn = {01650114},
	shorttitle = {Fuzzy methods in machine learning and data mining},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165011405002861},
	doi = {10.1016/j.fss.2005.05.036},
	abstract = {Over the past years, methods for the automated induction of models and the extraction of interesting patterns from empirical data have attracted considerable attention in the fuzzy set community. This paper brieﬂy reviews some typical applications and highlights potential contributions that fuzzy set theory can make to machine learning, data mining, and related ﬁelds. The paper concludes with a critical consideration of recent developments and some suggestions for future research directions.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Hüllermeier, Eyke},
	month = dec,
	year = {2005},
	pages = {387--406},
}

@article{mendel_computing_2007,
	title = {Computing with {Words}: {Zadeh}, {Turing}, {Popper} and {Occam}},
	volume = {2},
	issn = {1556-603X},
	shorttitle = {Computing with {Words}},
	url = {http://ieeexplore.ieee.org/document/4383064/},
	doi = {10.1109/MCI.2007.9066897},
	abstract = {In this article, after explaining Zadeh’s computing with words (CWW) paradigm, I argue that for this paradigm to be embraced, it must be validated using a Turinglike test, use a scientifically correct fuzzy set model for words, namely interval type-2 fuzzy sets (IT2 FSs), and be simple, meaning that fuzzy set operations should be as simple as possible. These conclusions are drawn using the ideas of Turing, Popper and Occam. Short descriptions are provided for a Perceptual Computer (Per-C), which is an architecture for CWW for making subjective judgments, IT2 FSs, IT2 FS models for words, and why an IT2 FS model captures first-order uncertainties about a word. Short biographies of Zadeh, Turing, Popper and Occam are also provided.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Mendel, Jerry},
	month = nov,
	year = {2007},
	pages = {10--17},
}

@article{kacprzyk_fquery_1989,
	series = {Fuzzy {Databases}},
	title = {{FQUERY} {III}+: {A} “human-consistent” database querying system based on fuzzy logic with linguistic quantifiers},
	volume = {14},
	issn = {0306-4379},
	shorttitle = {{FQUERY} {III}+},
	url = {https://www.sciencedirect.com/science/article/pii/0306437989900124},
	doi = {10.1016/0306-4379(89)90012-4},
	abstract = {Using a fuzzy-logic-based calculus of linguistically quantified propositions we present FQUERY III+, a new, more “human-friendly” and easier-to-use implementation of a querying scheme proposed originally by Kacprzyk and Ziołkowski to handle imprecise queries including a linguistic quantifier as, e.g. find all records in which most (almost all, much more than 75\%, … or any other linguistic quantifier) of the important attributes (out of a specified set) are as desired (e.g. equal to five, more than 10, large, more or less equal to 15, etc.). FQUERY III+ is an “add-on” to Ashton-Tate's dBase III Plus.},
	language = {en},
	number = {6},
	urldate = {2023-01-04},
	journal = {Information Systems},
	author = {Kacprzyk, Janusz and Zadrożny, Sławomir and Ziołkowski, Andrzej},
	month = jan,
	year = {1989},
	keywords = {Database querying, fuzzy logic, fuzzy set, imprecise query, linguistic quantifier},
	pages = {443--453},
}

@article{lindskog_pfuozinzty_nodate,
	title = {{PFuozinzty} {oIfdeVniteiwcation} from a {Grey} {Box} {Modeling}},
	language = {en},
	author = {Lindskog, P},
}

@article{ciaramella_fuzzy_2006,
	series = {Advances in {Fuzzy} {Sets} and {Rough} {Sets}},
	title = {Fuzzy relational neural network},
	volume = {41},
	issn = {0888-613X},
	url = {https://www.sciencedirect.com/science/article/pii/S0888613X0500054X},
	doi = {10.1016/j.ijar.2005.06.016},
	abstract = {In this paper a fuzzy neural network based on a fuzzy relational “IF-THEN” reasoning scheme is designed. To define the structure of the model different t-norms and t-conorms are proposed. The fuzzification and the defuzzification phases are then added to the model so that we can consider the model like a controller. A learning algorithm to tune the parameters that is based on a back-propagation algorithm and a recursive pseudoinverse matrix technique is introduced. Different experiments on synthetic and benchmark data are made. Several results using the UCI repository of Machine learning database are showed for classification and approximation tasks. The model is also compared with some other methods known in literature.},
	language = {en},
	number = {2},
	urldate = {2023-01-04},
	journal = {International Journal of Approximate Reasoning},
	author = {Ciaramella, A. and Tagliaferri, R. and Pedrycz, W. and Di Nola, A.},
	month = feb,
	year = {2006},
	keywords = {Classification and approximation tasks, Fuzzy relations, Neural networks, Neuro-fuzzy systems},
	pages = {146--163},
}

@article{herrera_apadraapmtaettieorns_nodate,
	title = {{APadraapmtaettieorns} {oBfaGseedneotnicFAuzlgzyorLitohgmic} {Controllers} ?},
	abstract = {The genetic algorithm behaviour is determined by the exploitation and exploration relationship kept throughout the run. Adaptive genetic algorithms have been built for inducing exploitation/exploration relationships that avoid the premature convergence problem and improve the nal results. One of the most widely studied adaptive approaches are the adaptive parameter setting techniques. In this paper, we study these techniques in depth, based on the use of fuzzy logic controllers. Furthermore, we design and discuss an adaptive realcoded genetic algorithm based on the use of fuzzy logic controllers. Although suitable results have been obtained by using this type of adaptive technique, we report some re ections on open problems that still remain.},
	language = {en},
	author = {Herrera, Francisco and Lozano, Manuel},
}

@article{alonso_interpretability_2015,
	title = {Interpretability of {Fuzzy} {Systems}: {Current} {Research} {Trends} and {Prospects}},
	shorttitle = {Interpretability of {Fuzzy} {Systems}},
	url = {https://www.academia.edu/13411159/Interpretability_of_Fuzzy_Systems_Current_Research_Trends_and_Prospects},
	abstract = {Interpretability of Fuzzy Systems: Current Research Trends and Prospects},
	language = {en},
	urldate = {2023-01-04},
	journal = {Springer Handbook of Computational Intelligence},
	author = {Alonso, Jose M. and Castiello, Ciro and Mencar, Corrado},
	year = {2015},
	pages = {219},
}

@article{nguyen_computational_nodate,
	title = {Computational {Complexity} and {Feasibility} of {Fuzzy} {Data} {Processing}: {Why} {Fuzzy} {Numbers}, {Which} {Fuzzy} {Numbers}, {Which} {Operations} with {Fuzzy} {Numbers}},
	language = {en},
	author = {Nguyen, Hung T and Kosheleva, Misha and Kosheleva, Olga and Kreinovich, Vladik and Mesiar, Radko},
}

@article{xu_concise_2019,
	title = {Concise {Fuzzy} {System} {Modeling} {Integrating} {Soft} {Subspace} {Clustering} and {Sparse} {Learning}},
	volume = {27},
	issn = {1063-6706, 1941-0034},
	url = {https://ieeexplore.ieee.org/document/8626516/},
	doi = {10.1109/TFUZZ.2019.2895572},
	language = {en},
	number = {11},
	urldate = {2023-01-04},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Xu, Peng and Deng, Zhaohong and Cui, Chen and Zhang, Te and Choi, Kup-Sze and Gu, Suhang and Wang, Jun and Wang, Shitong},
	month = nov,
	year = {2019},
	pages = {2176--2189},
}

@article{babuska_data-driven_2001,
	title = {Data-{Driven} {Fuzzy} {Modeling}: {Transparency} and {Complexity} {Issues}},
	shorttitle = {Data-{Driven} {Fuzzy} {Modeling}},
	abstract = {Recently, the interest in data-driven approaches to the modeling of nonlinear processes has increased. Techniques based on fuzzy sets and rule-based systems have proven suitable mainly because of their potential to yield transparent models that are at the same time reasonably accurate. Many of the data-driven fuzzy modeling algorithms, however, aim primarily at good numerical approximation, while little attention is paid to the complexity and interpretability of the resulting model. This paper deals with the issues of complexity and transparency in rule-based fuzzy models obtained through various data-driven identification algorithms. They include grid partition approaches and tree construction algorithms, fuzzy clustering and nonlinear parameter-optimization methods. Different rule base reduction techniques are addressed as well.},
	author = {Babuska, Robert},
	month = feb,
	year = {2001},
}

@article{riid_identification_2011,
	series = {Special {Issue} on {Interpretable} {Fuzzy} {Systems}},
	title = {Identification of transparent, compact, accurate and reliable linguistic fuzzy models},
	volume = {181},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025511000685},
	doi = {10.1016/j.ins.2011.01.041},
	abstract = {Transparency, accuracy, compactness and reliability all appear to be vital (even though somewhat contradictory) requirements when it comes down to linguistic fuzzy modeling. This paper presents a methodology for simultaneous optimization of these criteria by chaining previously published various algorithms – a heuristic fully automated identification algorithm that is able to extract sufficiently accurate, yet reliable and transparent models from data and two algorithms for subsequent simplification of the model that are able to reduce the number of output parameters as well as the number of fuzzy rules with only a marginal negative effect to the accuracy of the model.},
	language = {en},
	number = {20},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Riid, Andri and Rüstern, Ennu},
	month = oct,
	year = {2011},
	keywords = {Complexity reduction, Fuzzy modeling, Interpretability of fuzzy systems},
	pages = {4378--4393},
}

@article{rutkowski_explainable_2019,
	title = {On {Explainable} {Fuzzy} {Recommenders} and their {Performance} {Evaluation}},
	volume = {29},
	url = {https://sciendo.com/it/article/10.2478/amcs-2019-0044},
	doi = {10.2478/amcs-2019-0044},
	abstract = {AbstractThis paper presents a novel approach to the design of explainable recommender systems. It is based on the Wang–Mendel algorithm of fuzzy rule generation. A method for the learning and reduction of the fuzzy recommender is proposed along with feature encoding. Three criteria, including the Akaike information criterion, are used for evaluating an optimal balance between recommender accuracy and interpretability. Simulation results verify the effectiveness of the presented recommender system and illustrate its performance on the MovieLens 10M dataset.},
	language = {it},
	number = {3},
	urldate = {2023-01-04},
	journal = {International Journal of Applied Mathematics and Computer Science},
	author = {Rutkowski, Tomasz and Łapa, Krystian and Nielek, Radosław},
	month = aug,
	year = {2019},
	pages = {595--610},
}

@article{klir_principles_1995,
	series = {Nuclear {Engineering}},
	title = {Principles of uncertainty: {What} are they? {Why} do we need them?},
	volume = {74},
	issn = {0165-0114},
	shorttitle = {Principles of uncertainty},
	url = {https://www.sciencedirect.com/science/article/pii/016501149500032G},
	doi = {10.1016/0165-0114(95)00032-G},
	abstract = {The meaning and utility of three principles of uncertainty is discussed. These principles, which are referred to as a principle of minimum uncertainty, a principle of maximum uncertainty, and a principle of uncertainty invariance, depend on the theory in which uncertainty is conceptualized. Due to a connection between uncertainty and information, the principles may also be conceived as principles of information. To make the principles operational in a particular uncertainty theory, we need to measure the amount of relevant uncertainty (and associated information) in each problem situation describable within the theory. Well justified measures of uncertainty have thus far been established only in some uncertainty theories. These theories, their uncertainty measures, and the associated uncertainty principles are overviewed in the paper.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Klir, George J.},
	month = aug,
	year = {1995},
	keywords = {Dempster-Shafer theory, Fuzzy set theory, Information, Maximum uncertainty principle, Minimum uncertainty principle, Possibility theory, Probability theory, Uncertainty, Uncertainty invariance principle},
	pages = {15--31},
}

@article{medasani_overview_1998,
	title = {An overview of membership function generation techniques for pattern recognition},
	volume = {19},
	issn = {0888-613X},
	url = {https://www.sciencedirect.com/science/article/pii/S0888613X98100178},
	doi = {10.1016/S0888-613X(98)10017-8},
	abstract = {The estimation of membership functions from data is an important step in many applications of fuzzy theory. In this paper, we provide a general overview of several methods for generating membership functions for fuzzy pattern recognition applications. We discuss methods based on heuristics, probability to possibility transformations, histograms, nearest neighbor techniques, feed-forward neural networks, clustering, and mixture decomposition. We also illustrate these membership generation methods using synthetic and real data sets, and discuss the suitability and applicability of these membership function generation techniques to particular situations.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {International Journal of Approximate Reasoning},
	author = {Medasani, Swarup and Kim, Jaeseok and Krishnapuram, Raghu},
	month = oct,
	year = {1998},
	keywords = {Clustering, K-nearest neighbor, Membership function generation, Mixture decomposition, Multiprototype classification, Probability to possibility transformations, Typicality},
	pages = {391--417},
}

@article{yang_generating_2006,
	title = {Generating fuzzy membership function with self-organizing feature map},
	volume = {27},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865505002370},
	doi = {10.1016/j.patrec.2005.08.026},
	abstract = {Automatic fuzzy membership generation is important in pattern recognition. A new scheme is proposed to generate fuzzy membership functions with unsupervised learning using self-organizing feature map. Simulation results on different datasets support this new scheme.},
	language = {en},
	number = {5},
	urldate = {2023-01-04},
	journal = {Pattern Recognition Letters},
	author = {Yang, Chih-Chung and Bose, N. K.},
	month = apr,
	year = {2006},
	keywords = {Computational intelligence, Fuzzy membership function, Pattern recognition, Self-organizing feature map},
	pages = {356--365},
}

@misc{noauthor_numeracy_nodate,
	title = {Numeracy, {Maths} and {Statistics} - {Academic} {Skills} {Kit}},
	url = {https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html},
	urldate = {2023-01-04},
}

@misc{badr_5_2019,
	title = {5 {Ways} to {Detect} {Outliers} {That} {Every} {Data} {Scientist} {Should} {Know} ({Python} {Code})},
	url = {https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623},
	abstract = {Detecting Anomalies is critical to any business either by identifying faults or being proactive. This article discusses 5 different ways…},
	language = {en},
	urldate = {2023-01-04},
	journal = {Medium},
	author = {Badr, Will},
	month = apr,
	year = {2019},
}

@article{lee_what_2018,
	title = {What is the proper way to apply the multiple comparison test?},
	volume = {71},
	issn = {2005-6419},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6193594/},
	doi = {10.4097/kja.d.18.00242},
	abstract = {Multiple comparisons tests (MCTs) are performed several times on the mean of experimental conditions. When the null hypothesis is rejected in a validation, MCTs are performed when certain experimental conditions have a statistically significant mean difference or there is a specific aspect between the group means. A problem occurs if the error rate increases while multiple hypothesis tests are performed simultaneously. Consequently, in an MCT, it is necessary to control the error rate to an appropriate level. In this paper, we discuss how to test multiple hypotheses simultaneously while limiting type I error rate, which is caused by α inflation. To choose the appropriate test, we must maintain the balance between statistical power and type I error rate. If the test is too conservative, a type I error is not likely to occur. However, concurrently, the test may have insufficient power resulted in increased probability of type II error occurrence. Most researchers may hope to find the best way of adjusting the type I error rate to discriminate the real differences between observed data without wasting too much statistical power. It is expected that this paper will help researchers understand the differences between MCTs and apply them appropriately.},
	number = {5},
	urldate = {2023-01-04},
	journal = {Korean Journal of Anesthesiology},
	author = {Lee, Sangseok and Lee, Dong Kyu},
	month = oct,
	year = {2018},
	pmid = {30157585},
	pmcid = {PMC6193594},
	pages = {353--360},
}

@article{streiner_correction_2011,
	title = {Correction for {Multiple} {Testing}: {Is} {There} a {Resolution}?},
	volume = {140},
	issn = {0012-3692},
	shorttitle = {Correction for {Multiple} {Testing}},
	url = {https://www.sciencedirect.com/science/article/pii/S0012369211603401},
	doi = {10.1378/chest.11-0523},
	abstract = {In most studies, many statistical tests are performed. They can be run to compare the groups at baseline, look at relationships among the various measures, and, for intervention trials, examine more than one end point. As the number of tests increases, so does the probability of finding at least one of them to be statistically significant just by chance (the problem of multiplicity). A number of procedures have been developed to deal with multiplicity, such as the Bonferroni correction, but there is continuing controversy regarding if and when these procedures should be used. In this article, we offer recommendations about when they should and should not be brought into play.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Chest},
	author = {Streiner, David L. and Norman, Geoffrey R.},
	month = jul,
	year = {2011},
	pages = {16--18},
}

@article{ghasemi_normality_2012,
	title = {Normality {Tests} for {Statistical} {Analysis}: {A} {Guide} for {Non}-{Statisticians}},
	volume = {10},
	issn = {1726-913X},
	shorttitle = {Normality {Tests} for {Statistical} {Analysis}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3693611/},
	doi = {10.5812/ijem.3505},
	abstract = {Statistical errors are common in scientific literature and about 50\% of the published articles have at least one error. The assumption of normality needs to be checked for many statistical procedures, namely parametric tests, because their validity depends on it. The aim of this commentary is to overview checking for normality in statistical analysis using SPSS.},
	number = {2},
	urldate = {2023-01-04},
	journal = {International Journal of Endocrinology and Metabolism},
	author = {Ghasemi, Asghar and Zahediasl, Saleh},
	year = {2012},
	pmid = {23843808},
	pmcid = {PMC3693611},
	pages = {486--489},
}

@misc{gunes_answer_2020,
	title = {Answer to "{Is} the number of cells in a keras {LSTM} or {RNN} layer equal to the number of time steps?"},
	shorttitle = {Answer to "{Is} the number of cells in a keras {LSTM} or {RNN} layer equal to the number of time steps?},
	url = {https://stats.stackexchange.com/a/447801},
	urldate = {2023-01-04},
	journal = {Cross Validated},
	author = {gunes},
	month = feb,
	year = {2020},
}

@misc{a-ar_is_2020,
	type = {Forum post},
	title = {Is the number of cells in a keras {LSTM} or {RNN} layer equal to the number of time steps?},
	url = {https://stats.stackexchange.com/q/447793},
	urldate = {2023-01-04},
	journal = {Cross Validated},
	author = {A-ar},
	month = feb,
	year = {2020},
}

@misc{noauthor_understanding_nodate,
	title = {Understanding {LSTM} {Networks} -- colah's blog},
	url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	urldate = {2023-01-04},
}

@article{chi_evaluation_nodate,
	title = {An {Evaluation} of {Pedagogical} {Tutorial} {Tactics} for a {Natural} {Language} {Tutoring} {System}: {A} {Reinforcement} {Learning} {Approach}},
	abstract = {Pedagogical strategies are policies for a tutor to decide the next action when there are multiple actions available. When the content is controlled to be the same across experimental conditions, there has been little evidence that tutorial decisions have an impact on students’ learning. In this paper, we applied Reinforcement Learning (RL) to induce two sets of pedagogical policies from pre-existing human interaction data. The NormGain set was derived with the goal of enhancing tutorial decisions that contribute to learning while the InvNormGain set was derived with the goal of enhancing those decisions that contribute less or even nothing to learning. The two sets were then tested with human students. Our results show that when the content was controlled to be the same, different pedagogical policies did make a difference in learning and more speciﬁcally, the NormGain students outperformed their peers. Overall our results suggest that content exposure and practice opportunities can help students to learn even when tutors have poor pedagogical tutorial tactics. However, with effective tutorial tactics, students can learn even more.},
	language = {en},
	author = {Chi, Min and VanLehn, Kurt and Litman, Diane and Jordan, Pamela},
	keywords = {Intelligent tutoring system},
}

@article{anderson_cognitive_1995,
	title = {Cognitive {Tutors}: {Lessons} {Learned}},
	volume = {4},
	issn = {1050-8406, 1532-7809},
	shorttitle = {Cognitive {Tutors}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327809jls0402_2},
	doi = {10.1207/s15327809jls0402_2},
	abstract = {This paper reviews the ten year history of tutor development based on the ACT theory (Anderson, 1983, 1993). We developed production system models in ACT of how students solved problems in LISP, geometry, and algebra. Computer tutors were developed around these cognitive models. Construction of these tutors was guided by a set of eight principles loosely based on the ACT theory. Early evaluations of these tutors usually but not always showed significant achievement gains. Best case evaluations showed that students could achieve at least the same level of proficiency as conventional instruction in one-third of the time. Empirical studies showed that students were learning skills in production-rule units and that the best tutorial interaction style was one in which the tutor provides immediate feedback, consisting of short and directed error messages. The tutors appear to work better if they present themselves to students as non human tools to assist learning rather than as emulations of human tutors. Students working with these tutors display transfer to other environments to the degree that they can map the tutor environment into the test environment. These experiences have coalesced into a new system for developing and deploying tutors. This system involves first selecting a problem-solving interface, then constructing a curriculum under the guidance of a domain expert, then designing a cognitive model for solving problems in that environment, then building instruction around the productions in that model, and finally deploying the tutor in the classroom. New tutors are being built in this system to achieve the NCTM standards for high school mathematics in an urban setting.},
	language = {en},
	number = {2},
	urldate = {2023-01-04},
	journal = {Journal of the Learning Sciences},
	author = {Anderson, John R. and Corbett, Albert T. and Koedinger, Kenneth R. and Pelletier, Ray.},
	month = apr,
	year = {1995},
	keywords = {Intelligent tutoring system},
	pages = {167--207},
}

@inproceedings{hatzilygeroudis_knowledge_2004,
	title = {Knowledge {Representation} {Requirements} for {Intelligent} {Tutoring} {Systems}},
	volume = {3220},
	isbn = {978-3-540-22948-3},
	doi = {10.1007/978-3-540-30139-4_9},
	abstract = {In this paper, we make a first effort to define requirements for knowledge representation (KR) in an ITS. The requirements concern all stages of an ITS’s life cycle (construction, operation and maintenance), all types of users (experts, engineers, learners) and all its modules (domain knowledge, user model, pedagogical model). We also briefly present and compare various KR formalisms used (or that could be used) in ITSs as far as the specified KR requirements are concerned. It appears that various hybrid approaches to knowledge representation can satisfy the requirements in a greater degree than that of single representations. Another finding is that there is not a hybrid formalism that can satisfy the requirements of all of the modules of an ITS, but each one individually. So, a multi-paradigm representation environment could provide a solution to requirements satisfaction.},
	author = {Hatzilygeroudis, Ioannis and Prentzas, Jim},
	month = aug,
	year = {2004},
	keywords = {Intelligent tutoring system},
	pages = {87--97},
}

@incollection{mihalis_application_1995,
	address = {Boston, MA},
	series = {{IFIP} — {The} {International} {Federation} for {Information} {Processing}},
	title = {An application of fuzzy logic to student modelling},
	isbn = {978-0-387-34844-5},
	url = {https://doi.org/10.1007/978-0-387-34844-5_10},
	abstract = {In this paper we discuss the principles of the design of a student model module within an educational teaching program in the domain of vertical projectile motion. Taking into account knowledge in the students as well as their individual learning skills the model allows steering of the educational process through the use of fuzzy logic and quantitative measurements. The teacher can still adapt the teaching strategy to specific needs of the student. The model has a decision component which chooses the teaching strategy on the basis of recorded history. A prototype program of the ‘Fuzzy student model’ is described.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {World {Conference} on {Computers} in {Education} {VI}: {WCCE} ’95 {Liberating} the {Learner}, {Proceedings} of the sixth {IFIP} {World} {Conference} on {Computers} in {Education}, 1995},
	publisher = {Springer US},
	author = {Mihalis, Panagiotou and Maria, Grigoriadou},
	editor = {Tinsley, J. David and van Weert, Tom J.},
	year = {1995},
	doi = {10.1007/978-0-387-34844-5_10},
	keywords = {Intelligent tutoring system},
	pages = {87--96},
}

@article{lagoudakis_least-squares_nodate,
	title = {Least-{Squares} {Policy} {Iteration}},
	abstract = {We propose a new approach to reinforcement learning for control problems which combines value-function approximation with linear architectures and approximate policy iteration. This new approach is motivated by the least-squares temporal-diﬀerence learning algorithm (LSTD) for prediction problems, which is known for its eﬃcient use of sample experiences compared to pure temporal-diﬀerence algorithms. Heretofore, LSTD has not had a straightforward application to control problems mainly because LSTD learns the state value function of a ﬁxed policy which cannot be used for action selection and control without a model of the underlying process. Our new algorithm, least-squares policy iteration (LSPI), learns the state-action value function which allows for action selection without a model and for incremental policy improvement within a policy-iteration framework. LSPI is a model-free, oﬀ-policy method which can use eﬃciently (and reuse in each iteration) sample experiences collected in any manner. By separating the sample collection method, the choice of the linear approximation architecture, and the solution method, LSPI allows for focused attention on the distinct elements that contribute to practical reinforcement learning. LSPI is tested on the simple task of balancing an inverted pendulum and the harder task of balancing and riding a bicycle to a target location. In both cases, LSPI learns to control the pendulum or the bicycle by merely observing a relatively small number of trials where actions are selected randomly. LSPI is also compared against Q-learning (both with and without experience replay) using the same value function architecture. While LSPI achieves good performance fairly consistently on the diﬃcult bicycle task, Q-learning variants were rarely able to balance for more than a small fraction of the time needed to reach the target location.},
	language = {en},
	author = {Lagoudakis, Michail G and Parr, Ronald},
}

@article{yeung_lecture_nodate,
	title = {Lecture 2: {Deep} {Learning} {Fundamentals}},
	language = {en},
	author = {Yeung, Serena},
}

@misc{noauthor_kl-divergence_nodate,
	title = {{KL}-divergence as an objective function — {Graduate} {Descent}},
	url = {https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/},
	urldate = {2023-01-04},
}

@misc{noauthor_edward_nodate,
	title = {Edward – {KL}(p{\textbar}{\textbar}q) {Minimization}},
	url = {http://edwardlib.org/tutorials/klpq},
	urldate = {2023-01-04},
}

@article{ramos_fuzzy-based_2019,
	title = {Fuzzy-{Based} {Language} {Grounding} of {Geographical} {References}: {From} {Writers} to {Readers}},
	volume = {12},
	issn = {1875-6883},
	shorttitle = {Fuzzy-{Based} {Language} {Grounding} of {Geographical} {References}},
	url = {https://www.atlantis-press.com/journals/ijcis/125917291},
	doi = {10.2991/ijcis.d.190826.002},
	abstract = {We describe an applied methodology to build fuzzy models of geographical expressions, which are meant to be used for natural language generation purposes. Our approach encompasses a language grounding task within the development of an actual data-to-text system for the generation of textual descriptions of live weather data. For this, we gathered data...},
	language = {en},
	number = {2},
	urldate = {2023-01-04},
	journal = {International Journal of Computational Intelligence Systems},
	author = {Ramos, Alejandro and Alonso, Jose M. and Reiter, Ehud and Deemter, Kees van and Gatt, Albert},
	month = sep,
	year = {2019},
	note = {Publisher: Atlantis Press},
	pages = {970--983},
}

@article{korning_training_1995,
	title = {Training neural networks by means of genetic algorithms working on very long chromosomes},
	volume = {06},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/10.1142/s0129065795000226},
	doi = {10.1142/S0129065795000226},
	abstract = {In the neural network/genetic algorithm community, rather limited success in the training of neural networks by genetic algorithms has been reported. In a paper by Whitley et al. (1991), he claims that, due to “the multiple representations problem”, genetic algorithms will not effectively be able to train multilayer perceptrons, whose chromosomal representation of its weights exceeds 300 bits. In the following paper, by use of a “real-life problem”, known to be non-trivial, and by a comparison with “classic” neural net training methods, I will try to show, that the modest success of applying genetic algorithms to the training of perceptrons, is caused not so much by the “multiple representations problem” as by the fact that problem-specific knowledge available is often ignored, thus making the problem unnecessarily tough for the genetic algorithm to solve. Special success is obtained by the use of a new fitness function, which takes into account the fact that the search performed by a genetic algorithm is holistic, and not local as is usually the case when perceptrons are trained by traditional methods.},
	number = {03},
	urldate = {2023-01-04},
	journal = {International Journal of Neural Systems},
	author = {Korning, Peter G.},
	month = sep,
	year = {1995},
	note = {Publisher: World Scientific Publishing Co.},
	pages = {299--316},
}

@article{yager_ordered_1988,
	title = {On ordered weighted averaging aggregation operators in multicriteria decisionmaking},
	volume = {18},
	issn = {2168-2909},
	doi = {10.1109/21.87068},
	abstract = {The author is primarily concerned with the problem of aggregating multicriteria to form an overall decision function. He introduces a type of operator for aggregation called an ordered weighted aggregation (OWA) operator and investigates the properties of this operator. The OWA's performance is found to be between those obtained using the AND operator, which requires all criteria to be satisfied, and the OR operator, which requires at least one criteria to be satisfied.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Yager, R.R.},
	month = jan,
	year = {1988},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {Aggregates, Machine intelligence, Open wireless architecture},
	pages = {183--190},
}

@article{chrysafiadi_knowledge_2013,
	title = {A knowledge representation approach using fuzzy cognitive maps for better navigation support in an adaptive learning system},
	volume = {2},
	issn = {2193-1801},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3607740/},
	doi = {10.1186/2193-1801-2-81},
	abstract = {In this paper a knowledge representation approach of an adaptive and/or personalized tutoring system is presented. The domain knowledge should be represented in a more realistic way in order to allow the adaptive and/or personalized tutoring system to deliver the learning material to each individual learner dynamically taking into account her/his learning needs and her/his different learning pace. To succeed this, the domain knowledge representation has to depict the possible increase or decrease of the learner’s knowledge. Considering that the domain concepts that constitute the learning material are not independent from each other, the knowledge representation approach has to allow the system to recognize either the domain concepts that are already partly or completely known for a learner, or the domain concepts that s/he has forgotten, taking into account the learner’s knowledge level of the related concepts. In other words, the system should be informed about the knowledge dependencies that exist among the domain concepts of the learning material, as well as the strength on impact of each domain concept on others. Fuzzy Cognitive Maps (FCMs) seem to be an ideal way for representing graphically this kind of information. The suggested knowledge representation approach has been implemented in an e-learning adaptive system for teaching computer programming. The particular system was used by the students of a postgraduate program in the field of Informatics in the University of Piraeus and was compared with a corresponding system, in which the domain knowledge was represented using the most common used technique of network of concepts. The results of the evaluation were very encouraging.},
	urldate = {2023-01-04},
	journal = {SpringerPlus},
	author = {Chrysafiadi, Konstantina and Virvou, Maria},
	month = mar,
	year = {2013},
	pmid = {23543890},
	pmcid = {PMC3607740},
	keywords = {Intelligent tutoring system},
	pages = {81},
}

@article{eryilmaz_development_2020,
	title = {Development of an {Intelligent} {Tutoring} {System} {Using} {Bayesian} {Networks} and {Fuzzy} {Logic} for a {Higher} {Student} {Academic} {Performance}},
	volume = {10},
	doi = {10.3390/app10196638},
	abstract = {In this experimental study, an intelligent tutoring system called the fuzzy Bayesian intelligent tutoring system (FB-ITS), is developed by using artificial intelligence methods based on fuzzy logic and the Bayesian network technique to adaptively support students in learning environments. The effectiveness of the FB-ITS was evaluated by comparing it with two other versions of an Intelligent Tutoring System (ITS), fuzzy ITS and Bayesian ITS, separately. Moreover, it was evaluated by comparing it with an existing traditional e-learning system. In order to evaluate whether the academic performance of the students in different learning groups differs or not, analysis of covariance (ANCOVA) was used based on the students' pre-test and post-test scores. The study was conducted with 120 undergraduate university students. Results showed that students who studied using FB-ITS had significantly higher academic performance on average compared to other students who studied with the other systems. Regarding the time taken to perform the post-test, the results indicated that students who used the FB-ITS needed less time on average compared to students who used the traditional e-learning system. From the results, it could be concluded that the new system contributed in terms of the speed of performing the final exam and high academic success.},
	journal = {Applied Sciences},
	author = {Eryilmaz, Meltem and Adabashi, Afaf},
	month = sep,
	year = {2020},
	keywords = {Intelligent tutoring system},
}

@incollection{kacprzyk_large_2000,
	address = {Heidelberg},
	title = {Large {Population} or {Many} {Generations} for {Genetic} {Algorithms}? {Implications} in {Information} {Retrieval}},
	volume = {50},
	isbn = {978-3-7908-2473-5 978-3-7908-1849-9},
	shorttitle = {Large {Population} or {Many} {Generations} for {Genetic} {Algorithms}?},
	url = {http://link.springer.com/10.1007/978-3-7908-1849-9_9},
	abstract = {Artiﬁcial intelligence models may be used to improve performance of information retrieval (IR) systems and the genetic algorithms (GAs) are an example of such a model. This paper presents an application of GAs as a relevance feedback method aiming to improve the document representation and indexing. In this particular form of GAs, various document descriptions compete with each other and a better collection indexing is sought through reproduction, crossover and mutation operations. In this paradigm, we are searching for the optimal balance between two genetic parameters: the population size and the number of generations. We try to discover the optimal parameter choice both by experiments using the CACM and CISI collections, and by a theoretical analysis providing explanation of the experimental results. The general conclusion tends to be that larger populations have better chance of signiﬁcantly improving the eﬀectiveness of retrieval.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Soft {Computing} in {Information} {Retrieval}},
	publisher = {Physica-Verlag HD},
	author = {Vrajitoru, Dana},
	editor = {Kacprzyk, Janusz and Crestani, Fabio and Pasi, Gabriella},
	year = {2000},
	doi = {10.1007/978-3-7908-1849-9_9},
	note = {Series Title: Studies in Fuzziness and Soft Computing},
	pages = {199--222},
}

@article{baldwin_fuzzy_1979,
	title = {Fuzzy logic and fuzzy reasoning},
	volume = {11},
	issn = {0020-7373},
	url = {https://www.sciencedirect.com/science/article/pii/S0020737379800383},
	doi = {10.1016/S0020-7373(79)80038-3},
	abstract = {The concepts of truth value restriction and fuzzy logical relation are used to give a general approach to fuzzy logic and also fuzzy reasoning involving propositions with imprecise or vague description.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {International Journal of Man-Machine Studies},
	author = {Baldwin, J. F.},
	month = jul,
	year = {1979},
	pages = {465--480},
}

@article{vague_logic,
 ISSN = {00318248, 1539767X},
 URL = {http://www.jstor.org/stable/184414},
 author = {Max Black},
 journal = {Philosophy of Science},
 number = {4},
 pages = {427--455},
 publisher = {[The University of Chicago Press, Philosophy of Science Association]},
 title = {Vagueness. An Exercise in Logical Analysis},
 urldate = {2024-01-30},
 volume = {4},
 year = {1937}
}

@ARTICLE{fuzzy_logic,
  author={Zadeh, L.A.},
  journal={Computer}, 
  title={Fuzzy logic}, 
  year={1988},
  volume={21},
  number={4},
  pages={83-93},
  keywords={Fuzzy logic;Decision making;Linguistics;Application software;Process control;Fuzzy sets;Expert systems;Uncertainty;Precision engineering},
  doi={10.1109/2.53}}

@article{giles1976lukasiewicz,
  title={{\L}ukasiewicz logic and fuzzy set theory},
  author={Giles, Robin},
  journal={International Journal of Man-Machine Studies},
  volume={8},
  number={3},
  pages={313--327},
  year={1976},
  publisher={Elsevier}
}

@article{keller_backpropagation_1992,
	title = {Backpropagation neural networks for fuzzy logic},
	volume = {62},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/0020025592900162},
	doi = {10.1016/0020-0255(92)90016-2},
	abstract = {Expert systems play a crucial role in the application of artificial intelligence to real problems. There are numerous methods of dealing with uncertainty in expert systems. Fuzzy logic is one such approach, in which the uncertainty is represented by possibility distributions for the antecedents and consequent of a rule. An uncertain input can be propagated to the consequent by a variety of mechanisms. This generality results in a higher computational burden for the system. More importantly, a means of controlling the response of the system to variations in input conditions is needed. In this paper, feedforward neural networks are proposed as a means of controlling this generality as well as providing the parallel computation necessary for fuzzy logic. It is demonstrated that these networks can learn and extrapolate complex relationships between antecedents and consequents for rules containing single and conjunctive antecedent clauses. Also, multiple compatible rules can be stored in a single network structure, increasing the efficiency of rule storage, and providing a natural mechanism for conflict resolution.},
	language = {en},
	number = {3},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Keller, James M. and Tahani, Hossein},
	month = aug,
	year = {1992},
	pages = {205--221},
}

@article{han_temporal_2020,
	title = {Temporal {Association} {Rule} {Mining} and {Updating} and {Their} {Application} to {Blast} {Furnace} in the {Steel} {Industry}},
	volume = {2020},
	issn = {1687-5265},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7238356/},
	doi = {10.1155/2020/7467213},
	abstract = {Blast furnace (BF) is the main method of modern iron-making. Ensuring the stability of the BF conditions can effectively improve the quality and output of iron and steel. However, operations of BF depend on mainly human experience, which causes two problems: (1) human experience is not objective and is difficult to inherit and learn and (2) it is difficult to acquire knowledge that contains time information among multiple variables in BF. To address these problems, a data-driven method is proposed. In this article, we propose a novel and efficient algorithm for discovering underlying knowledge in the form of temporal association rules (TARs) in BF iron-making data. First, a new TAR mining framework is proposed for mining temporal frequent patterns. Then, a novel TAR mining algorithm is proposed for mining underlying, up-to-date, and effective knowledge in the form of TARs. Finally, considering the updating of the BF database, a rule updating method is proposed that is based on the algorithm that is proposed in this article. Our extensive experiments demonstrate the satisfactory performance of the proposed algorithm in discovering TARs in comparison with the state-of-the-art algorithms. Experiments on BF iron-making data have demonstrated the superior performance and practicability of the proposed method.},
	urldate = {2023-01-04},
	journal = {Computational Intelligence and Neuroscience},
	author = {Han, Yinghua and Yu, Deshui and Yin, Chunhui and Zhao, Qiang},
	month = may,
	year = {2020},
	pmid = {32454810},
	pmcid = {PMC7238356},
	pages = {7467213},
}

@article{reddy_sk_exchange_2015,
	title = {Exchange {Rate} {Forecasting} using {ARIMA}, {Neural} {Network} and {Fuzzy} {Neuron}},
	volume = {04},
	issn = {21689458},
	url = {http://www.omicsgroup.org/journals/exchange-rate-forecasting-using-arima-neural-network-and-fuzzyneuron-2168-9458-1000155.php?aid=61262},
	doi = {10.4172/2168-9458.1000155},
	abstract = {Prediction of Exchange rates has been a challenging task for traders and practitioners in modern financial markets. Statistical and econometric models are extensively used in the analysis and prediction of foreign exchange rates. This paper investigates the behavior of daily exchange rates of the Indian Rupee (INR) against the United States Dollar (USD), British Pound (GBP), Euro (EUR) and Japanese Yen (JPY). This paper attempts to examine the performance of ARIMA, Neural Network and Fuzzy neuron models in forecasting the currencies traded in Indian foreign exchange markets. Daily RBI reference exchange rates from January 2010-April 2015 were used for the analysis.},
	language = {en},
	number = {03},
	urldate = {2023-01-04},
	journal = {Journal of Stock \& Forex Trading},
	author = {Reddy SK, Babu AS},
	year = {2015},
}

@article{hayashi_fuzzy_1993,
	title = {Fuzzy neural network with fuzzy signals and weights},
	volume = {8},
	issn = {1098-111X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.4550080405},
	doi = {10.1002/int.4550080405},
	abstract = {We discuss the direct fuzzification of a standard layered, feedforward, neural network where the signals and weights are fuzzy sets. A fuzzified delta rule is presented for learning. Three applications are given including fuzzy expert systems, fuzzy hierarchical analysis, and fuzzy systems modeling. © 1993 John Wiley \& Sons, Inc.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {International Journal of Intelligent Systems},
	author = {Hayashi, Yoichi and Buckley, James J. and Czogala, Ernest},
	year = {1993},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.4550080405},
	pages = {527--537},
}

@inproceedings{ying_necessary_1994,
	title = {Some necessary conditions for single-input single-output fuzzy systems as universal approximators},
	doi = {10.1109/IJCF.1994.375124},
	abstract = {In this paper, we investigate necessary conditions for some typical single-input single-output fuzzy systems as universal approximators for continuous functions defined on compact domains with arbitrarily small uniform approximation error bounds. The necessary conditions we found provide a basis for insightful analysis of strength as well as limitation of the fuzzy systems. The main strength is that only a small number of fuzzy rules may be needed to uniformly approximate continuous functions that have a complicated formulation but a relatively small number of extrema. The limitation is that in order to approximate frequently oscillatory continuous functions, the number of fuzzy rules must be large.{\textless}{\textgreater}},
	booktitle = {{NAFIPS}/{IFIS}/{NASA} '94. {Proceedings} of the {First} {International} {Joint} {Conference} of {The} {North} {American} {Fuzzy} {Information} {Processing} {Society} {Biannual} {Conference}. {The} {Industrial} {Fuzzy} {Control} and {Intellige}},
	author = {Ying, Hao and Chen, Guanrong},
	month = dec,
	year = {1994},
	keywords = {Approximation error, Approximation methods, Biomedical engineering, Biophysics, Fuzzy sets, Fuzzy systems, Input variables, Mechanical factors, Physiology, Polynomials, Universal approximation},
	pages = {264--265},
}

@article{wang_wm_2003,
	title = {The {WM} method completed: a flexible fuzzy system approach to data mining},
	volume = {11},
	issn = {1941-0034},
	shorttitle = {The {WM} method completed},
	doi = {10.1109/TFUZZ.2003.819839},
	abstract = {In this paper, the so-called Wang-Mendel (WM) method for generating fuzzy rules from data is enhanced to make it a comprehensive and flexible fuzzy system approach to data description and prediction. In the description part, the core ideas of the WM method are used to develop three methods to extract fuzzy IF-THEN rules from data. The first method shows how to extract rules for the user-specified cases, the second method generates all the rules that can be generated directly from the data, and the third method extrapolates the rules generated by the second method over the entire domain of interest. In the prediction part, two fuzzy predictive models are constructed based on the fuzzy IF-THEN rules extracted by the methods of the description part. The first model gives a continuous output and is suitable for predicting continuous variables, and the second model gives a piecewise constant output and is suitable for predicting categorical variables. We show that by comparing the prediction accuracy of the fuzzy predictive models with different numbers of fuzzy sets covering the input variables, we can rank the importance of the input variables. We also propose an algorithm to optimize the fuzzy predictive models, and show how to use the models to solve pattern recognition problems. Throughout this paper, we use a set of real data from a steel rolling plant to demonstrate the ideas and test the models.},
	number = {6},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Wang, Li-Xin},
	month = dec,
	year = {2003},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Accuracy, Data mining, Decision trees, Fuzzy logic, Fuzzy sets, Fuzzy systems, Input variables, Neural networks, Pattern recognition, Predictive models, Wang-Mendel method},
	pages = {768--782},
}

@inproceedings{bouchon-meunier_fuzzy_2012,
	title = {Fuzzy linguistic summaries: {Where} are we, where can we go?},
	shorttitle = {Fuzzy linguistic summaries},
	doi = {10.1109/CIFEr.2012.6327810},
	abstract = {Along with the increase of the amount of data stored and to be analyzed, different techniques of data analysis have been developed over the years. One of them, the linguistic summary, aims at summing up large volume of data into simple sentences. In this paper, we present an overview of two main streams of research, namely fuzzy logic based systems and natural language generation, covering the methods designed to work with numerical data, time series, or simple labels (enumerations). We focus on the former stream and we give some hints to go further on fuzzy quantifiers.},
	booktitle = {2012 {IEEE} {Conference} on {Computational} {Intelligence} for {Financial} {Engineering} \& {Economics} ({CIFEr})},
	author = {Bouchon-Meunier, Bernadette and Moyse, Gilles},
	month = mar,
	year = {2012},
	note = {ISSN: 2380-8454},
	keywords = {Data mining, Databases, Fuzzy logic, Marketing and sales, Natural languages, Pragmatics, Turbines},
	pages = {1--8},
}

@article{george_soft_1996,
	title = {A soft computing approach to intensional answering in databases},
	volume = {92},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/0020025596000497},
	doi = {10.1016/0020-0255(96)00049-7},
	abstract = {An approach to intensional answering in databases utilizing soft computing methodologies is described. The general form of a intensional answer is QY's are F, where Q is a fuzzy linguistic quantifier, Y is a class of objects, and F is a property of the class or a summary that applies to the class quantified by Q. Fuzzy descriptions of linguistic quantifiers and labels help to evaluate the degree to which an intensional answer describes a given set of tuples. Bounds on such descriptions can be defined in terms of a most general specification constituent description and a most specific generalization constraint description. A genetic algorithm technique is used to obtain near-optimal intensional answers that fit a given set of tuples.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {George, Roy and Srikanth, Radhakrishnan},
	month = jul,
	year = {1996},
	pages = {313--328},
}

@article{noauthor_computational_1983,
	title = {A computational approach to fuzzy quantifiers in natural languages},
	volume = {9},
	issn = {0898-1221},
	url = {https://www.sciencedirect.com/science/article/pii/0898122183900135},
	doi = {10.1016/0898-1221(83)90013-5},
	abstract = {The generic term fuzzy quantifier is employed in this paper to denote the collection of quantifiers in natural languages whose representative elements…},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Computers \& Mathematics with Applications},
	month = jan,
	year = {1983},
	note = {Publisher: Pergamon},
	pages = {149--184},
}

@inproceedings{rodriguez_extracting_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Extracting {Composite} {Summaries} from {Qualitative} {Data}},
	isbn = {978-3-030-89691-1},
	doi = {10.1007/978-3-030-89691-1_26},
	abstract = {The paper proposes a model combining association rules and elements of Rhetorical Structure Theory (RST) to generate composite linguistic summaries from qualitative data. The specifications of three new abstract forms of composite linguistic summaries for qualitative data are presented. The proposed abstract forms represent relations of Evidence, Contrast, and Emphasis inspired by RST, consisting of at least two semantically related constituent statements linked by a connector specific to each relation. The constituent statements have the structure of the classical protoforms of linguistic summaries, which in this paper are built from an association rule, to which a fuzzy linguistic quantifier is assigned. Moreover, the definitions of truth degree, relation strength, and coverage degree for composite relations are presented. The model applicability was checked through a use case performed with a database of 2128 cases of the Economic Chamber of the Provincial People’s Court of Havana.},
	language = {en},
	booktitle = {Progress in {Artificial} {Intelligence} and {Pattern} {Recognition}},
	publisher = {Springer International Publishing},
	author = {Rodríguez, Carlos R. Rodríguez and Abreu, Marieta Peña and Zuev, Denis Sergeevich},
	editor = {Hernández Heredia, Yanio and Milián Núñez, Vladimir and Ruiz Shulcloper, José},
	year = {2021},
	keywords = {Association rules, Linguistic data summarization, Linguistic descriptions of data, Rhetorical structure theory},
	pages = {260--269},
}

@article{kacprzyk_linguistic_nodate,
	title = {{LINGUISTIC} {SUMMARIES} {OF} {TIME} {SERIES}: {A} {POWERFUL} {TOOL} {FOR} {DISCOVERING} {KNOWLEDGE} {ON} {TIME} {VARYING} {PROCESSES} {AND} {SYSTEMS}},
	abstract = {We present linguistic data summarization, meant as a process for a comprehensive description of big and complex data sets via short statements in natural language represented by protoforms in the form of linguistically quantiﬁed propositions dealt with using tools and techniques of fuzzy logic to grasp an inherent imprecision of natural language. Such linguistic data summaries can provide a human user, whose only natural means of articulation and communication is natural language, with a simple yet effective and efﬁcient means for the representation and manipulation of knowledge about processes and systems. We concentrate on the linguistic summarization of dynamic processes and systems, dealing with data represented as time series. We extend the basic, static data oriented concept of a linguistic data summary to the case of time series data, present various possible protoforms of linguistic summaries, and an analysis of their properties and ways of generation. We show two our own real applications of the new tools of linguistic summarization of time series, for the summarization of quotations of an investment (mutual) fund, and of Web server logs, to show the power of the tool. We also mention some other applications known from the literature. We conclude with some remarks on the strength of the linguistic summarization for broadly perceived data mining and knowledge discovery and some possible further research directions.},
	language = {en},
	author = {Kacprzyk, Janusz},
}

@article{dicesare_linguistic_1990,
	title = {Linguistic summarization of fuzzy data},
	volume = {52},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/002002559090039D},
	doi = {10.1016/0020-0255(90)90039-D},
	abstract = {This paper presents a new approach to the summarization of linguistic data. A fuzzy mean, or average, for linguistic data is defined. Linguistic approximation is used to label the average membership function computed using the definition. A measure of variation of the data, a fuzzy variance, is defined. Using the fuzzy variance and the range of the fuzzy data, a normalized measure of dispersion is constructed. A method for labeling this normalized measure is provided using linguistic approximation. Thus the concepts of mean, variance and range are extended to the theory of fuzzy sets and the values obtained are interpreted in a linguistic fashion. Examples illustrate each of these concepts.},
	language = {en},
	number = {2},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {DiCesare, Frank and Sahnoun, Zaidi and Bonissone, Piero P.},
	month = nov,
	year = {1990},
	pages = {141--152},
}

@article{kacprzyk_linguistic_2005,
	series = {Dealing with {Uncertainty} in {Data} {Mining} and {Information} {Extraction}},
	title = {Linguistic database summaries and their protoforms: towards natural language based knowledge discovery tools},
	volume = {173},
	issn = {0020-0255},
	shorttitle = {Linguistic database summaries and their protoforms},
	url = {https://www.sciencedirect.com/science/article/pii/S002002550500085X},
	doi = {10.1016/j.ins.2005.03.002},
	abstract = {We consider linguistic data(base) summaries in the sense of Yager [Information Sciences 28 (1982) 69–86], exemplified by “most employees are young and well paid” (with some degree of truth added), for a personnel database, as an intuitive, human consistent and natural language based knowledge discovery tool. We present first an extension of the classic Yager’s approach to involve more sophisticated criteria of goodness, search methods, etc. We advocate the use of the concept of a protoform (prototypical form), that is recently vividly advocated by Zadeh [A prototype-centered approach to adding deduction capabilities to search engines—the concept of a protoform. BISC Seminar, University of California, Berkeley, 2002], as a general form of a linguistic data summary. We present an extension of our interactive approach, based on fuzzy logic and fuzzy database queries, which makes it possible to implement such linguistic data summaries. We show how fuzzy queries are related to linguistic summaries, and show that one can introduce a hierarchy of protoforms, or abstract summaries in the sense of latest Zadeh’s [A prototype-centered approach to adding deduction capabilities to search engines—the concept of a protoform. BISC Seminar, University of California, Berkeley, 2002] ideas meant mainly for increasing deduction capabilities of search engines. For illustration we show an implementation for a sales database in a computer retailer, employing some type of a protoform of a linguistic summary.},
	language = {en},
	number = {4},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Kacprzyk, Janusz and Zadrożny, Sławomir},
	month = jun,
	year = {2005},
	keywords = {Computing with words and perceptions, Data mining, Fuzzy logic, Linguistic summarization, Protoform},
	pages = {281--304},
}

@article{kacprzyk_linguistic_nodate-1,
	title = {Linguistic {Summarization} of {Trends}: {A} {Fuzzy} {Logic} {Based} {Approach}},
	abstract = {The purpose of this paper is to propose a new easily implementable approach to a linguistic summarization of trends that may be present in temporal data. It is based on fuzzy linguistic summaries of data (databases) in the sense of Yager (cf. Yager [20], Kacprzyk and Yager [9], and Kacprzyk, Yager and Zadroz˙ny [10]) which in the form of natural language-like sentences subsume the very essence of a set of data.},
	language = {en},
	author = {Kacprzyk, Janusz and Wilbik, Anna and Zadroz, Slawomir},
}

@article{lee_discovery_2005,
	title = {Discovery of {Fuzzy} {Temporal} {Association} {Rules}},
	volume = {34},
	doi = {10.1109/TSMCB.2004.835352},
	abstract = {We propose a data mining system for discovering interesting temporal patterns from large databases. The mined patterns are expressed in fuzzy temporal association rules which satisfy the temporal requirements specified by the user. Temporal requirements specified by human beings tend to be ill-defined or uncertain. To deal with this kind of uncertainty, a fuzzy calendar algebra is developed to allow users to describe desired temporal requirements in fuzzy calendars easily and naturally. Fuzzy operations are provided and users can define complicated fuzzy calendars to discover the knowledge in the time intervals that are of interest to them. A border-based mining algorithm is proposed to find association rules incrementally. By keeping useful information of the database in a border, candidate itemsets can be computed in an efficient way. Updating of the discovered knowledge due to addition and deletion of transactions can also be done efficiently. The kept information can be used to help save the work of counting and unnecessary scans over the updated database can be avoided. Simulation results show the effectiveness of the proposed system. A performance comparison with other systems is also given.},
	journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
	author = {Lee, Wan-Jui and Lee, Shie-Jue},
	month = jan,
	year = {2005},
	keywords = {Fuzzy calendars},
	pages = {2330--42},
}

@article{gu_self-organising_2018,
	title = {Self-organising fuzzy logic classifier},
	volume = {447},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025518301737},
	doi = {10.1016/j.ins.2018.03.004},
	abstract = {In this paper, we present a self-organising nonparametric fuzzy rule-based classifier. The proposed approach identifies prototypes from the observed data through an offline training process and uses them to build a 0-order AnYa type fuzzy rule-based system for classification. Once primed offline, it is able to continuously learn from the streaming data afterwards to follow the changing data pattern by updating the system structure and meta-parameters recursively. The meta-parameters of the proposed approach are derived from data directly. By changing the level of granularity, the proposed approach can make a trade-off between performance and computational efficiency, and, thus, the classifier is able to address a wide variety of problems with specific needs. The classifier also supports different types of distance measures. Numerical examples based on benchmark datasets demonstrate the high performance of the proposed approach and its ability of handling high-dimensional, complex, large-scale problems.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Gu, Xiaowei and Angelov, Plamen P.},
	month = jun,
	year = {2018},
	keywords = {Classification, Fuzzy rule-based systems, Recursive, Self-organising},
	pages = {36--51},
}

@inproceedings{tan_direct_2007,
	title = {Direct {Code} {Access} in {Self}-{Organizing} {Neural} {Networks} for {Reinforcement} {Learning}.},
	abstract = {TD-FALCON is a self-organizing neural network that incorporates Temporal Difference (TD) meth- ods for reinforcement learning. Despite the advan- tages of fast and stable learning, TD-FALCON still relies on an iterative process to evaluate each avail- able action in a decision cycle. To remove this defi- ciency, this paper presents a direct code access pro- cedure whereby TD-FALCON conducts instanta- neous searches for cognitive nodes that match with the current states and at the same time provide max- imal reward values. Our comparative experiments show that TD-FALCON with direct code access produces comparable performance with the origi- nal TD-FALCON while improving significantly in computation efficiency and network complexity.},
	author = {Tan, Ah-Hwee},
	month = jan,
	year = {2007},
	pages = {1071--1076},
}

@inproceedings{kuremoto_improved_2019,
	title = {An {Improved} {Fuzzy} {Neural} {Network} for {Reinforcement} {Learning}},
	doi = {10.1145/3372454.3372476},
	author = {Kuremoto, Takashi and Matsusaka, Hiroki and Obayashi, Masanao and Mabu, Shingo and Kobayashi, Kunikazu},
	month = nov,
	year = {2019},
	pages = {88--93},
}

@article{chen_mining_2016,
	title = {Mining fuzzy temporal association rules by item lifespans},
	volume = {41},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494616000156},
	doi = {10.1016/j.asoc.2016.01.008},
	abstract = {Data mining is the process of extracting desirable knowledge or interesting patterns from existing databases for specific purposes. In real-world applications, transactions may contain quantitative values and each item may have a lifespan from a temporal database. In this paper, we thus propose a data mining algorithm for deriving fuzzy temporal association rules. It first transforms each quantitative value into a fuzzy set using the given membership functions. Meanwhile, item lifespans are collected and recorded in a temporal information table through a transformation process. The algorithm then calculates the scalar cardinality of each linguistic term of each item. A mining process based on fuzzy counts and item lifespans is then performed to find fuzzy temporal association rules. Experiments are finally performed on two simulation datasets and the foodmart dataset to show the effectiveness and the efficiency of the proposed approach.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {Chen, Chun-Hao and Lan, Guo-Cheng and Hong, Tzung-Pei and Lin, Shih-Bin},
	month = apr,
	year = {2016},
	keywords = {Fuzzy data mining, Fuzzy set, Fuzzy temporal association rule, Item lifespan},
	pages = {265--274},
}

@inproceedings{chen_mining_2011,
	title = {Mining fuzzy temporal knowledge from quantitative transactions},
	doi = {10.1109/ICSSE.2011.5961937},
	abstract = {In this paper, we propose a data mining algorithm for deriving fuzzy temporal association rules. It first transforms each quantitative value into a fuzzy set using the given membership functions. Meanwhile, item lifespans are collected and recorded in a temporal information table during the transformation process. The algorithm then calculates the scalar cardinality of each linguistic term of each item. The mining process based on fuzzy counts and item lifespans is then performed to find fuzzy temporal association rules. Experiments on a simulation dataset are also made to show the effectiveness and the efficiency of the proposed approach.},
	booktitle = {Proceedings 2011 {International} {Conference} on {System} {Science} and {Engineering}},
	author = {Chen, Chun-Hao and Hong, Tzung-Pei and Lin, Shih-Bin},
	month = jun,
	year = {2011},
	note = {ISSN: 2325-0925},
	keywords = {Algorithm design and analysis, Association rules, Itemsets, Pragmatics, fuzzy data mining, fuzzy set, fuzzy temporal association rule, item lifespan},
	pages = {405--409},
}

@inproceedings{hong_mining_1999,
	title = {Mining fuzzy sequential patterns from quantitative data},
	volume = {3},
	doi = {10.1109/ICSMC.1999.823358},
	abstract = {Data mining is the process of extracting desirable knowledge or interesting patterns from existing databases for specific purposes. Most of the conventional data mining algorithms can identify the relationships among transactions with binary values. Temporal transactions with quantitative values are, however, commonly seen in real-world applications. This paper thus attempts to propose a new data mining algorithm, which takes advantage of fuzzy set theory to enhance the capability of exploring interesting sequential patterns from databases with quantitative values. The proposed algorithm integrates the concepts of fuzzy sets and the AprioriAll algorithm to find interesting sequential patterns and fuzzy association rules from transaction data.},
	booktitle = {{IEEE} {SMC}'99 {Conference} {Proceedings}. 1999 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({Cat}. {No}.{99CH37028})},
	author = {Hong, Tzung-Pei and Kuo, Chan-Sheng and Chi, Sheng-Chai},
	month = oct,
	year = {1999},
	note = {ISSN: 1062-922X},
	keywords = {Association rules, Data mining, Electronic mail, Fuzzy set theory, Fuzzy sets, Information management, Itemsets, Knowledge management, Machine learning, Transaction databases},
	pages = {962--966 vol.3},
}

@inproceedings{nomura_learning_1992,
	title = {A learning method of fuzzy inference rules by descent method},
	doi = {10.1109/FUZZY.1992.258618},
	abstract = {The authors propose a learning method for fuzzy inference rules by a descent method. From input-output data gathered from specialists, the inference rules expressing the input-output relation of the data are obtained automatically. The membership functions in the antecedent part and the real number in the consequent part of the inference rules are tuned by means of the descent method. The learning speed and the generalization capability of this method are higher than those of a conventional backpropagation type neural network. This method has the capability to express the knowledge acquired from input-output data in the form of fuzzy inference rules. Some numerical examples are described to show these advantages over the conventional neural network. An application of the method to a mobile robot that avoids a moving obstacle and its computer simulation are reported.{\textless}{\textgreater}},
	booktitle = {[1992 {Proceedings}] {IEEE} {International} {Conference} on {Fuzzy} {Systems}},
	author = {Nomura, H. and Hayashi, I. and Wakami, N.},
	month = mar,
	year = {1992},
	keywords = {Application software, Backpropagation, Computer simulation, Learning systems, Mobile robots, Neural networks},
	pages = {203--210},
}

@article{de_campos_souza_fuzzy_2020,
	title = {Fuzzy neural networks and neuro-fuzzy networks: {A} review the main techniques and applications used in the literature},
	volume = {92},
	issn = {1568-4946},
	shorttitle = {Fuzzy neural networks and neuro-fuzzy networks},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494620302155},
	doi = {10.1016/j.asoc.2020.106275},
	abstract = {This paper presents a review of the central theories involved in hybrid models based on fuzzy systems and artificial neural networks, mainly focused on supervised methods for training hybrid models. The basic concepts regarding the history of hybrid models, from the first proposed model to the current advances, the composition and the functionalities in their architecture, the data treatment and the training methods of these intelligent models are presented to the reader so that the evolution of this category of intelligent systems can be evidenced. Finally, the features of the leading models and their applications are presented to the reader. We conclude that the fuzzy neural network models and their derivations are efficient in constructing a system with a high degree of accuracy and an appropriate level of interpretability working in a wide range of areas of economics and science.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {de Campos Souza, Paulo Vitor},
	month = jul,
	year = {2020},
	keywords = {Fuzzy neural network, Hybrid models, Neuro-fuzzy network},
	pages = {106275},
}

@article{nguyen_gsetsk_2015,
	title = {{GSETSK}: a generic self-evolving {TSK} fuzzy neural network with a novel {Hebbian}-based rule reduction approach},
	volume = {35},
	issn = {1568-4946},
	shorttitle = {{GSETSK}},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494615003555},
	doi = {10.1016/j.asoc.2015.06.008},
	abstract = {Takagi–Sugeno–Kang (TSK) fuzzy systems have been widely applied for solving function approximation and regression-centric problems. Existing dynamic TSK models proposed in the literature can be broadly classified into two classes. Class I TSK models are essentially fuzzy systems that are limited to time-invariant environments. Class II TSK models are generally evolving systems that can learn in time-variant environments. This paper attempts to address the issues of achieving compact, up-to-date fuzzy rule bases and interpretable knowledge bases in TSK models. It proposes a novel rule pruning method which is simple, computationally efficient and biologically plausible. This rule pruning algorithm applies a gradual forgetting approach and adopts the Hebbian learning mechanism behind the long-term potentiation phenomenon in the brain. It also proposes a merging approach which is used to improve the interpretability of the knowledge bases. This approach can prevent derived fuzzy sets from expanding too many times to protect their semantic meanings. These two approaches are incorporated into a generic self-evolving Takagi–Sugeno–Kang fuzzy framework (GSETSK) which adopts an online data-driven incremental-learning-based approach. Extensive experiments were conducted to evaluate the performance of the proposed GSETSK against other established evolving TSK systems. GSETSK has also been tested on real world dataset using the high-way traffic flow density and Dow Jones index time series. The results are encouraging. GSETSK demonstrates its fast learning ability in time-variant environments. In addition, GSETSK derives an up-to-date and better interpretable fuzzy rule base while maintaining a high level of modeling accuracy at the same time.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {Nguyen, Ngoc Nam and Zhou, Weigui Jair and Quek, Chai},
	month = oct,
	year = {2015},
	keywords = {Fuzzy neural network, Neuro-fuzzy systems, Self-evolving},
	pages = {29--42},
}

@article{wichasilp_design_nodate,
	title = {Design of {Fuzzy} {Logic} {Controllers} by {Fuzzy} c-{Means} {Clustering}},
	volume = {8},
	abstract = {In this paper, the use of Fuzzy c-meansclustering algorithm in the design of membership functions andfuzzy rulesof a fuzry logic controller.aredescribed.In the designprocedure,an autotuning PID controllerwas usedto operatean exampleplant which is a model of the air-conditioning system,and the plant operatingdata were collected.Thefuzry c-partitionof the data was then analyzedby Fuzzy c-meansclusteringto achieveoptimum fuzzy sets andfuzzy rules of the FLC. The FLC was then implementedand simulatedin controllingthe plant.The resultsfrom simulationshow that when comparedto conventionallydesignedFLC, the proposedFLC gives better temperature characteristics.},
	language = {en},
	number = {2},
	author = {Wichasilp, Chaned and Wiriyasuttiwong, Watcharachai and Kantapanit, Kajornsak},
}

@article{dutu_fast_2018,
	title = {A {Fast} and {Accurate} {Rule}-{Base} {Generation} {Method} for {Mamdani} {Fuzzy} {Systems}},
	volume = {26},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2017.2688349},
	abstract = {The problem of learning fuzzy rule bases is analyzed from the perspective of finding a favorable balance between the accuracy of the system, the speed required to learn the rules, and, finally, the interpretability of the rule bases obtained. Therefore, we introduce a complete design procedure to learn and then optimize the system rule base, called the precise and fast fuzzy modeling approach. Under this paradigm, fuzzy rules are generated from numerical data using a parameterizable greedy-based learning method called selection-reduction, whose accuracy-speed efficiency is confirmed through empirical results and comparisons with reference methods. Qualitative justification for this method is provided based on the coaction between fuzzy logic and the intrinsic properties of greedy algorithms. To complete the precise and fast fuzzy modeling strategy, we finally present a rule-base optimization technique driven by a novel rule redundancy index, which takes into account the concepts of the distance between rules and the influence of a rule over the dataset. Experimental results show that the proposed index can be used to obtain compact rule bases, which remain very accurate, thus increasing system interpretability.},
	number = {2},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Duţu, Liviu-Cristian and Mauris, Gilles and Bolon, Philippe},
	month = apr,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Accuracy–speed tradeoff, Fuzzy logic, Fuzzy systems, Indexes, Learning systems, Numerical models, Pragmatics, Redundancy, double-consequent linguistic rules, fuzzy modeling, greedy rule selection, inductive rule learning, interpretability–accuracy tradeoff, rule-base (RB) reduction},
	pages = {715--733},
}

@inproceedings{chua_new_2009,
	title = {A {New} {Fuzzy} {Rule}-{Based} {Initialization} {Method} for {K}-{Nearest} {Neighbor} {Classifier}},
	doi = {10.1109/FUZZY.2009.5277215},
	abstract = {The performances of conventional crisp and fuzzy K-nearest neighbor (K-NN) algorithms trained using finite samples tends to be poor . With ldquoholesrdquo in the training data, it is unlikely that the decision area formed can actually represent the underlying data distribution. There is a need to capture more useful information from the limited training samples, therefore we propose a new fuzzy rule-based K-NN algorithm. A fuzzy rule-based initialization procedure differentiates our proposed algorithm from the conventional fuzzy K-NN algorithm. The new initialization procedure allows us to handle the imprecise inputs (neighborhood density and distance) through the natural framework of fuzzy logic system. Unlike conventional K-NN algorithms, the ability to fine tune the membership functions can lead to a highly versatile decision boundary. Thus, the new algorithm can be specifically tuned for different problems to achieve better results. The advantage is demonstrated on a synthetic data set in two-dimensional space. In addition, we also adopt weighted Euclidean distance measurement to overcome the curse of dimensionality . The Euclidean distance weights and the parameters of the fuzzy rule-based system are then optimized with genetic algorithm (GA) simultaneously. The practical applicability of the proposed algorithm is verified on four UCI data sets (Bupa liver disorders, Glass, Pima Indians diabetes and Wisconsin breast cancer) and Ford automotive data set with an improvement of 3.42\% in classification rate on average.},
	author = {Chua, Teckwee and Tan, Woei},
	month = sep,
	year = {2009},
	pages = {415--420},
}

@inproceedings{wang_fuzzy_2010,
	title = {Fuzzy knowledge representation based on an improving spiking neural {P} system},
	volume = {6},
	doi = {10.1109/ICNC.2010.5584281},
	abstract = {This paper presents a new method to express fuzzy knowledge based on an improving spiking neural P system. In knowledge base of a rule-based system, the fuzzy production rules can be modeled by the improving spiking neural P system. The original definition of neurons is no longer the number of spikes, instead by fuzzy numbers. An example is used to illustrate the fuzzy reasoning process.},
	booktitle = {2010 {Sixth} {International} {Conference} on {Natural} {Computation}},
	author = {Wang, Jun and Peng, Hong},
	month = aug,
	year = {2010},
	note = {ISSN: 2157-9563},
	keywords = {Biomembranes, Computational modeling, Fuzzy reasoning, Knowledge based systems, Knowledge representation, Neurons, Production},
	pages = {3012--3015},
}

@article{schmidhuber_learning_1992,
	title = {Learning {Factorial} {Codes} by {Predictability} {Minimization}},
	volume = {4},
	issn = {0899-7667},
	doi = {10.1162/neco.1992.4.6.863},
	abstract = {I propose a novel general principle for unsupervised learning of distributed nonredundant internal representations of input patterns. The principle is based on two opposing forces. For each representational unit there is an adaptive predictor, which tries to predict the unit from the remaining units. In turn, each unit tries to react to the environment such that it minimizes its predictability. This encourages each unit to filter "abstract concepts" out of the environmental input such that these concepts are statistically independent of those on which the other units focus. I discuss various simple yet potentially powerful implementations of the principle that aim at finding binary factorial codes (Barlow et al. 1989), i.e., codes where the probability of the occurrence of a particular input is simply the product of the probabilities of the corresponding code symbols. Such codes are potentially relevant for (1) segmentation tasks, (2) speeding up supervised learning, and (3) novelty detection. Methods for finding factorial codes automatically implement Occam's razor for finding codes using a minimal number of units. Unlike previous methods the novel principle has a potential for removing not only linear but also nonlinear output redundancy. Illustrative experiments show that algorithms based on the principle of predictability minimization are practically feasible. The final part of this paper describes an entirely local algorithm that has a potential for learning unique representations of extended input sequences.},
	number = {6},
	journal = {Neural Computation},
	author = {Schmidhuber, Jürgen},
	month = nov,
	year = {1992},
	note = {Conference Name: Neural Computation},
	pages = {863--879},
}

@article{schmidhuber_learning_nodate,
	title = {Learning {Factorial} {Codes} by {Predictability} {Minimization} ; {CU}-{CS}-565-91},
	author = {Schmidhuber, Jurgen},
}

@article{zarandi_fuzzy_2012,
	title = {A {Fuzzy} {Expert} {System} {Architecture} for {Intelligent} {Tutoring} {Systems}: {A} {Cognitive} {Mapping} {Approach}},
	volume = {04},
	shorttitle = {A {Fuzzy} {Expert} {System} {Architecture} for {Intelligent} {Tutoring} {Systems}},
	url = {http://www.scirp.org/journal/PaperInformation.aspx?PaperID=17551&#abstract},
	doi = {10.4236/jilsa.2012.41003},
	abstract = {An Intelligent Tutoring System (ITS) is a computer based instruction tool that attempts to provide individualized instructions based on learner’s educational status. Advances in development of these systems have rose and fell since their emergence. Perhaps the main reason for this is the absence of appropriate framework for ITS development. This paper proposes a framework for designing two main parts of ITSs. Besides development framework, the second main reason for lack of significant advances in ITS development is its development cost. In general, this cost for instructional material is quite high and it becomes more in ITS development. The proposed method can significantly reduce the development cost. The cost reduction mainly is because of characteristics of applied mapping techniques. These maps are human readable and easily understandable by people who are not aware of knowledge representation techniques. The proposed framework is implemented for a graduate course at a technical university in Asia. This experiment provides an individualized instruction which is the main designing purpose of the ITSs.},
	language = {en},
	number = {01},
	urldate = {2023-01-04},
	journal = {Journal of Intelligent Learning Systems and Applications},
	author = {Zarandi, Mohammad Hossein Fazel and Khademian, Mahdi and Minaei-Bidgoli, Behrouz and Türk?en, Ismail Burhan},
	month = feb,
	year = {2012},
	note = {Number: 01
Publisher: Scientific Research Publishing},
	pages = {29},
}

@inproceedings{wilamowski_suitability_2012,
	title = {Suitability of fuzzy systems and neural networks for industrial applications},
	doi = {10.1109/OPTIM.2012.6231989},
	abstract = {The presentation provides a comparison of fuzzy and neural systems for industrial applications. Both neural networks and fuzzy systems perform nonlinear mapping and both systems internally operate within a limited signal range between zero and one. Neural networks can handle basically an unlimited number of inputs and outputs while fuzzy systems have one output and number of inputs is practically limited to 2 or 3. The resulted nonlinear function produced by neural networks is smooth while functions produced by fuzzy systems are relatively rough. At the same time the design of fuzzy systems transparent and easy to follow while the development of neural networks is much more labor intensive. It is shows that most commonly used neural network architecture of MLP - Multi Layer Perceptron is also one of the least efficient ones. Also most commonly used EBP - Error Back Propagation algorithm is not only very slow, but also it is not able to find solutions for optimal neural network architectures. EBP can solve problems only when large number of neurons is used, but this way neural network loses its generalization property. Performances of both fuzzy systems and neural networks are compared leading to the conclusion that neural networks can produce much more accurate nonlinear mapping and they may require less hardware.},
	booktitle = {2012 13th {International} {Conference} on {Optimization} of {Electrical} and {Electronic} {Equipment} ({OPTIM})},
	author = {Wilamowski, Bogdan M.},
	month = may,
	year = {2012},
	note = {ISSN: 1842-0133},
	keywords = {Biological neural networks, Computer architecture, Fuzzy systems, Neurons, Topology, Training},
	pages = {1--7},
}

@inproceedings{partouche_intelligent_2007,
	title = {Intelligent {Speed} {Adaptation} {Using} a {Self}-{Organizing} {Neuro}-{Fuzzy} {Controller}},
	url = {https://hal.inria.fr/inria-00181662},
	abstract = {The need to increase road safety is a major concern, with millions of road users and pedestrians being killed in traffic accidents each year. The Centre for Computational Intelligence (C2i) at NTU has developed an intelligent driving system based on hybrid fuzzy neural networks, which is able to park autonomously, drive on highways, and take some decisions such as lane changing, car following, and overtaking. This paper presents a new approach to autonomously adapt the speed of a vehicle by learning from a human driver and using anticipation. The architecture of the system is a specific fuzzy neural network realized at C2i: the Generic Self Organizing Fuzzy Neural Network using the Yager inference scheme (GenSoFNN(Yager)). Experiments have been conducted in simulation to test the longitudinal control and the ability of the system to anticipate curves. Results found are very promising.},
	language = {en},
	urldate = {2023-01-04},
	author = {Partouche, David and Spalanzani, Anne and Pasquier, Michel},
	year = {2007},
}

@inproceedings{allende-cid_self-organizing_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Self-{Organizing} {Neuro}-{Fuzzy} {Inference} {System}},
	isbn = {978-3-540-85920-8},
	doi = {10.1007/978-3-540-85920-8_53},
	abstract = {The architectural design of neuro-fuzzy models is one of the major concern in many important applications. In this work we propose an extension to Rogers’s ANFIS model by providing it with a selforganizing mechanism. The main purpose of this mechanism is to adapt the architecture during the training process by identifying the optimal number of premises and consequents needed to satisfy a user’s performance criterion. Using both synthetic and real data, our proposal yields remarkable results compared to the classical ANFIS.},
	language = {en},
	booktitle = {Progress in {Pattern} {Recognition}, {Image} {Analysis} and {Applications}},
	publisher = {Springer},
	author = {Allende-Cid, Héctor and Veloz, Alejandro and Salas, Rodrigo and Chabert, Steren and Allende, Héctor},
	editor = {Ruiz-Shulcloper, José and Kropatsch, Walter G.},
	year = {2008},
	keywords = {ANFIS, Flexible Architecture, Nonlinear modeling},
	pages = {429--436},
}

@article{lin_neuro-fuzzy-based_2012,
	title = {Neuro-fuzzy-based skill learning for robots},
	volume = {30},
	issn = {1469-8668, 0263-5747},
	url = {https://www.cambridge.org/core/journals/robotica/article/abs/neuro-fuzzy-based-skill-learning-for-robots/0B061627FDF72FF4C3023EB845ADB0CB},
	doi = {10.1017/S026357471100124X},
	abstract = {Endowing robots with the ability of skill learning enables them to be versatile and skillful in performing various tasks. This paper proposes a neuro-fuzzy-based, self-organizing skill-learning framework, which differs from previous work in its capability of decomposing a skill by self-categorizing it into significant stimulus-response units (SRU, a fundamental unit of our skill representation), and self-organizing learned skills into a new skill. The proposed neuro-fuzzy-based, self-organizing skill-learning framework can be realized by skill decomposition and skill synthesis. Skill decomposition aims at representing a skill and acquiring it by SRUs, and is implemented by stages with a five-layer neuro-fuzzy network with supervised learning, resolution control, and reinforcement learning to enable robots to identify a sufficient number of significant SRUs for accomplishing a given task without extraneous actions. Skill synthesis aims at organizing a new skill by sequentially planning learned skills composed of SRUs, and is realized by stages, which establish common SRUs between two similar skills and self-organize a new skill from these common SRUs and additional new SRUs by reinforcement learning. Computer simulations and experiments with a Pioneer 3-DX mobile robot were conducted to validate the self-organizing capability of the proposed skill-learning framework in identifying significant SRUs from task examples and in common SRUs between similar skills and learning new skills from learned skills.},
	language = {en},
	number = {6},
	urldate = {2023-01-04},
	journal = {Robotica},
	author = {Lin, Hsien-I. and Lee, C. S. George},
	month = oct,
	year = {2012},
	note = {Publisher: Cambridge University Press},
	keywords = {Neuro-fuzzy network, Reinforcement learning, Self-organizing skill learning, Skill decomposition, Skill synthesis},
	pages = {1013--1027},
}

@article{hullermeier_does_2015,
	series = {Special {Issue} {Celebrating} the 50th {Anniversary} of {Fuzzy} {Sets}},
	title = {Does machine learning need fuzzy logic?},
	volume = {281},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011415004133},
	doi = {10.1016/j.fss.2015.09.001},
	abstract = {This article is a short position paper in which the author outlines his (necessarily subjective) perception of current research in fuzzy machine learning, that is, the use of formal concepts and mathematical tools from fuzzy sets and fuzzy logic in the field of machine learning. The paper starts with a critical appraisal of previous contributions to fuzzy machine learning and ends with a suggestion of some directions for future work.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Hüllermeier, Eyke},
	month = dec,
	year = {2015},
	keywords = {Fuzzy logic, Fuzzy sets, Machine learning},
	pages = {292--299},
}

@article{juang_recurrent_1999,
	title = {A recurrent self-organizing neural fuzzy inference network},
	volume = {10},
	issn = {1045-9227},
	url = {https://doi.org/10.1109/72.774232},
	doi = {10.1109/72.774232},
	abstract = {A recurrent self-organizing neural fuzzy inference network (RSONFIN) is proposed. The RSONFIN is inherently a recurrent multilayered connectionist network for realizing the basic elements and functions of dynamic fuzzy inference, and may be considered to be constructed from a series of dynamic fuzzy rules. The temporal relations embedded in the network are built by adding some feedback connections representing the memory elements to a feedforward neural fuzzy network. Each weight as well as node in the RSONFIN has its own meaning and represents a special element in a fuzzy rule. There are no hidden nodes initially in the RSONFIN. They are created online via concurrent structure identification and parameter identification. The structure learning together with the parameter learning forms a fast learning algorithm for building a small, yet powerful, dynamic neural fuzzy network. Two major characteristics of the RSONFIN can thus be seen: 1) the recurrent property of the RSONFIN makes it suitable for dealing with temporal problems and 2) no predetermination, like the number of hidden nodes, must be given, since the RSONFIN can find its optimal structure and parameters automatically and quickly. Moreover, to reduce the number of fuzzy rules generated, a flexible input partition method, the aligned clustering-based algorithm, is proposed. Various simulations on temporal problems are done and performance comparisons with some existing recurrent networks are also made. Efficiency of the RSONFIN is verified from these results},
	number = {4},
	urldate = {2023-01-04},
	journal = {IEEE Transactions on Neural Networks},
	author = {Juang, Chia-Feng and Lin, Chin-Teng},
	month = jul,
	year = {1999},
	pages = {828--845},
}

@article{leng_-line_2004,
	title = {An on-line algorithm for creating self-organizing fuzzy neural networks},
	volume = {17},
	issn = {0893-6080},
	url = {https://doi.org/10.1016/j.neunet.2004.07.009},
	doi = {10.1016/j.neunet.2004.07.009},
	abstract = {This paper presents a new on-line algorithm for creating a self-organizing fuzzy neural network (SOFNN) from sample patterns to implement a singleton or Takagi-Sugeno (TS) type fuzzy model. The SOFNN is based on ellipsoidal basis function (EBF) neurons consisting of a center vector and a width vector. New methods of the structure learning and the parameter learning, based on new adding and pruning techniques and a recursive on-line learning algorithm, are proposed and developed. A proof of the convergence of both the estimation error and the linear network parameters is also given in the paper. The proposed methods are very simple and effective and generate a fuzzy neural model with a high accuracy and compact structure. Simulation work shows that the SOFNN has the capability of self-organization to determine the structure and parameters of the network automatically.},
	number = {10},
	urldate = {2023-01-04},
	journal = {Neural Networks},
	author = {Leng, Gang and Prasad, Girijesh and McGinnity, Thomas Martin},
	month = dec,
	year = {2004},
	keywords = {EBF, TS model, recursive least squares algorithm, self-organizing fuzzy neural network},
	pages = {1477--1493},
}

@article{torra_hesitant_2010,
	title = {Hesitant fuzzy sets},
	volume = {25},
	issn = {1098-111X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.20418},
	doi = {10.1002/int.20418},
	abstract = {Several extensions and generalizations of fuzzy sets have been introduced in the literature, for example, Atanassov's intuitionistic fuzzy sets, type 2 fuzzy sets, and fuzzy multisets. In this paper, we propose hesitant fuzzy sets. Although from a formal point of view, they can be seen as fuzzy multisets, we will show that their interpretation differs from the two existing approaches for fuzzy multisets. Because of this, together with their definition, we also introduce some basic operations. In addition, we also study their relationship with intuitionistic fuzzy sets. We prove that the envelope of the hesitant fuzzy sets is an intuitionistic fuzzy set. We prove also that the operations we propose are consistent with the ones of intuitionistic fuzzy sets when applied to the envelope of the hesitant fuzzy sets. © 2010 Wiley Periodicals, Inc.},
	language = {en},
	number = {6},
	urldate = {2023-01-04},
	journal = {International Journal of Intelligent Systems},
	author = {Torra, Vicenç},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.20418},
	pages = {529--539},
}

@article{angelov_empirical_2018,
	title = {Empirical {Fuzzy} {Sets}},
	volume = {33},
	issn = {1098-111X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.21935},
	doi = {10.1002/int.21935},
	abstract = {In this paper, we introduce a new form of describing fuzzy sets (FSs) and a new form of fuzzy rule-based (FRB) systems, namely, empirical fuzzy sets (εFSs) and empirical fuzzy rule-based (εFRB) systems. Traditionally, the membership functions (MFs), which are the key mathematical representation of FSs, are designed subjectively or extracted from the data by clustering projections or defined subjectively. εFSs, on the contrary, are described by the empirically derived membership functions (εMFs). The new proposal made in this paper is based on the recently introduced Empirical Data Analytics (EDA) computational framework and is closely linked with the density of the data. This allows to keep and improve the link between the objective data and the subjective labels, linguistic terms, and classes definition. Furthermore, εFSs can deal with heterogeneous data combining categorical with continuous and/or discrete data in a natural way. εFRB systems can be extracted from data including data streams and can have dynamically evolving structure. However, they can also be used as a tool to represent expert knowledge. The main difference from the traditional FSs and FRB systems is that the expert does not need to define the MF per variable; instead, possibly multimodal, densities will be extracted automatically from the data and used as εMFs in a vector form for all numerical variables. This is done in a seamless way whereby the human involvement is only required to label the classes and linguistic terms. Moreover, even this intervention is optional. Thus, the proposed new approach to define and design the FSs and FRB systems puts the human “in the driving seat.” Instead of asking experts to define features and MFs correspondingly, to parameterize them, to define algorithm parameters, to choose types of MFs, or to label each individual item, it only requires (optionally) to select prototypes from data and (again, optionally) to label them. Numerical examples as well as a naïve empirical fuzzy (εF) classifier are presented with an illustrative purpose. Due to the very fundamental nature of the proposal, it can have a very wide area of applications resulting in a series of new algorithms such as εF classifiers, εF predictors, εF controllers, and so on. This is left for the future research.},
	language = {en},
	number = {2},
	urldate = {2023-01-04},
	journal = {International Journal of Intelligent Systems},
	author = {Angelov, Plamen P. and Gu, Xiaowei},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.21935},
	pages = {362--395},
}

@article{lesot_interpretability_2016,
	series = {Special {Issue} in {Honor} of {Francesc} {Esteva} on the {Occasion} of his 70th {Birthday}},
	title = {Interpretability of fuzzy linguistic summaries},
	volume = {292},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/S0165011414004667},
	doi = {10.1016/j.fss.2014.10.019},
	abstract = {This paper investigates the question of the interpretability of fuzzy linguistic summaries, both at the sentence level and at the summary level, seen as a set of sentences. The individual sentence interpretability is examined as depending both on its representativity measured by a quality degree and on its linguistic expression. Different properties at the summary level are also discussed, namely their consistency, their non-redundancy and the information they convey.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Fuzzy Sets and Systems},
	author = {Lesot, Marie-Jeanne and Moyse, Gilles and Bouchon-Meunier, Bernadette},
	month = jun,
	year = {2016},
	keywords = {Fuzzy linguistic summaries, Generalised protoform, Interpretability, Summary consistency},
	pages = {307--317},
}

@article{zeng_languages_2014,
	title = {On languages generated by spiking neural {P} systems with weights},
	volume = {278},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025514003533},
	doi = {10.1016/j.ins.2014.03.062},
	abstract = {Spiking neural P systems with weights (WSN P systems, for short) are a class of distributed parallel computing devices inspired from the way neurons communicate by means of spikes. It has been proved that WSN P systems can generate/recognize Turing computable set of numbers (i.e., they are Turing universal as number generators/recognizers). In this work, we investigate the language generation power of WSN P systems, where the set of spike trains of halting computations of a given WSN P system constitutes the language generated by that system. Several relationships of the families of languages generated by WSN P systems with the family of finite languages and the family of regular languages are obtained. The family of recursively enumerable languages is characterized by projections of inverse-morphic images of languages generated by WSN P systems.},
	language = {en},
	urldate = {2023-01-04},
	journal = {Information Sciences},
	author = {Zeng, Xiangxiang and Xu, Lei and Liu, Xiangrong and Pan, Linqiang},
	month = sep,
	year = {2014},
	keywords = {Membrane computing, Natural computing, Recursively enumerable language, Spiking neural P system, Turing universality},
	pages = {423--433},
}

@article{chen_fuzzy_2012,
	title = {Fuzzy data mining for time-series data},
	volume = {12},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494611002894},
	doi = {10.1016/j.asoc.2011.08.006},
	abstract = {Time series analysis has always been an important and interesting research field due to its frequent appearance in different applications. In the past, many approaches based on regression, neural networks and other mathematical models were proposed to analyze the time series. In this paper, we attempt to use the data mining technique to analyze time series. Many previous studies on data mining have focused on handling binary-valued data. Time series data, however, are usually quantitative values. We thus extend our previous fuzzy mining approach for handling time-series data to find linguistic association rules. The proposed approach first uses a sliding window to generate continues subsequences from a given time series and then analyzes the fuzzy itemsets from these subsequences. Appropriate post-processing is then performed to remove redundant patterns. Experiments are also made to show the performance of the proposed mining algorithm. Since the final results are represented by linguistic rules, they will be friendlier to human than quantitative representation.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Applied Soft Computing},
	author = {Chen, Chun-Hao and Hong, Tzung-Pei and Tseng, Vincent S.},
	month = jan,
	year = {2012},
	keywords = {Association rule, Data mining, Fuzzy set, Sliding window, Time series},
	pages = {536--542},
}

@article{shao_fuzzy_1988,
	series = {Fuzzy {Control}},
	title = {Fuzzy self-organizing controller and its application for dynamic processes},
	volume = {26},
	issn = {0165-0114},
	url = {https://www.sciencedirect.com/science/article/pii/0165011488902059},
	doi = {10.1016/0165-0114(88)90205-9},
	abstract = {This paper deals with a Self-Organizing Controller used in real time and its application for dynamic processes. The control policy of the controller is able to develop and improve automatically. A new self-organizing control algorithm which modifies the fuzzy control decision table is presented in this paper. The control algorithm needs much less computation time and memory of the computer. This paper provides two examples of the fuzzy self-organizing control. A set of experiment results is described. It shows that the controller can be applied to some processes, such as processes with time lag and non-linearity or one whose parameter or running conditions are varied, which were usually not controlled very well with a conventional controller.},
	language = {en},
	number = {2},
	urldate = {2023-01-03},
	journal = {Fuzzy Sets and Systems},
	author = {Shao, Shihuang},
	month = may,
	year = {1988},
	keywords = {Fuzzy sets, Production and process control},
	pages = {151--164},
}

@article{Mamdani1974ApplicationsOF,
  title={Applications of fuzzy algorithms for control of a simple dynamic plant},
  author={Ebrahim H. Mamdani},
  journal={Proceedings of the IEEE},
  year={1974},
  url={https://api.semanticscholar.org/CorpusID:59806637}
}

@article{procyk_linguistic_1979,
	title = {A linguistic self-organizing process controller},
	volume = {15},
	issn = {0005-1098},
	url = {https://www.sciencedirect.com/science/article/pii/0005109879900840},
	doi = {10.1016/0005-1098(79)90084-0},
	abstract = {A heuristic controller for dynamic processes is presented in this paper whose control policy is able to develop and improve automatically. The controller's heuristics take the form of a set of linguistic decision rules which are expressed quantitatively and manipulated by using the theory of fuzzy sets. A series of experiments are described which show that the controller can be applied to a wide range of different processes which can be multivariable and also nonlinear and demonstrate the controller's robustness. This form of control can therefore find an application in those complex systems which have been too difficult to control or which in the past have had to rely on the experience of a human operator.},
	language = {en},
	number = {1},
	urldate = {2023-01-03},
	journal = {Automatica},
	author = {Procyk, T. J. and Mamdani, E. H.},
	month = jan,
	year = {1979},
	pages = {15--30},
}

@article{wilson_neuro-fuzzy_1997,
	series = {Supplement to {Computers} and {Chemical} {Engineering}},
	title = {Neuro-fuzzy modeling and control of a batch process involving simultaneous reaction and distillation},
	volume = {21},
	issn = {0098-1354},
	url = {https://www.sciencedirect.com/science/article/pii/S0098135497876715},
	doi = {10.1016/S0098-1354(97)87671-5},
	abstract = {This paper is concerned with a novel approach to batch process automation using fuzzy modeling and reinforcement learning. The core part of the automation strategy is an autonomous agent that continuously learns to implement control actions that can drive the batch process state very close to the desired one with near-optimal performance. An efficient algorithm for reinforcement learning called fuzzy Q-Learning is proposed to build the agent (controller). The use of linguistic information to guide the learning process and to implement near-optimal actions provides the means for both knowledge integration and scaling reinforcement learning. The methodology is exemplified using a batch process involving simultaneous reaction and distillation.},
	language = {en},
	urldate = {2023-01-03},
	journal = {Computers \& Chemical Engineering},
	author = {Wilson, J. A. and Martinez, E. C.},
	month = may,
	year = {1997},
	pages = {S1233--S1238},
}

@misc{zhou_reinforcement_2009,
	title = {Reinforcement {Learning} in {Generating} {Fuzzy} {Systems}},
	url = {https://www.semanticscholar.org/paper/Reinforcement-Learning-in-Generating-Fuzzy-Systems-Zhou-Er/90202255c74bf856a73e8c4dc7d1fb3864221d9c},
	abstract = {This work has provided a paradigm of acquiring the parameters of fuzzy rules and found that both DFQL and CQGAF methods achieve online structure identification by creating fuzzy rules when the input space is not well partitioned. Fuzzy-logic-based modelling and control is very efficient in dealing with imprecision and nonlinearity [1]. However, the conventional approaches for designing Fuzzy Inference Systems (FISs) are subjective, which require significant human’s efforts. Other than time consuming, the subjective approaches may not be successful if the system is too complex or uncertain. Therefore, many researchers have been seeking automatic methods for generating the FIS [2]. The main issues for designing an FIS are structure identification and parameter estimation. Structure identification is concerned with how to partition the input space and determine the number of fuzzy rules according to the task requirements while parameter estimation involves the determination of parameters for both premises and consequents of fuzzy rules [3]. Structure identification and input classification can be accomplished by Supervised Learning (SL), Unsupervised Learning (UL) and Reinforcement Learning (RL). SL is a learning approach that adopts a supervisor, through which, the training system can adjust the structure and parameters according to a given training data set. In [4], the author provided a paradigm of acquiring the parameters of fuzzy rules. Besides adjusting parameters, self-identified structures have been achieved by SL approaches termed Dynamic Fuzzy Neural Networks in [3] and Generalized Dynamic Fuzzy Neural Networks in [5]. However, the training data are not always available especially when a human being has little knowledge about the system or the system is uncertain. In those situations, UL and RL are preferred over SL as UL and RL are learning processes that do not need any supervisor to tell the learner what action to take. Through RL, those state-action pairs which achieve positive reward will be encouraged in future selections while those which produce negative reward will be discouraged. A number of researchers have applied RL to train the consequent parts of an FIS [6.8]. The preconditioning parts of the FIS are either predefined as in [6] or through the e-completeness and the squared TD error criteria in [7] or through the “aligned clustering” in [8]. Both DFQL and CQGAF methods achieve online structure identification by creating fuzzy rules when the input space is not well partitioned. However, both methods cannot adjust the premise parameters except when creating new rules. The center position and width of fuzzy neurons are allocated by only considering the input clustering. Moreover, both methods cannot delete fuzzy rules once they are generated even when the rules become redundant. O pe n A cc es s D at ab as e w w w .in te ch w eb .o rg},
	language = {en},
	urldate = {2023-01-03},
	author = {Zhou, Yi and Er, M.},
	year = {2009},
}

@inproceedings{zhou_7_2012,
	title = {7 {Reinforcement} {Learning} in {Generating} {Fuzzy} {Systems}},
	url = {https://www.semanticscholar.org/paper/7-Reinforcement-Learning-in-Generating-Fuzzy-Zhou-Er/f1f22430c94e6680c3a5b1a3aedb3ecdcab2afae?p2df},
	abstract = {Fuzzy-logic-based modelling and control is very efficient in dealing with imprecision and nonlinearity [1]. However, the conventional approaches for designing Fuzzy Inference Systems (FISs) are subjective, which require significant human’s efforts. Other than time consuming, the subjective approaches may not be successful if the system is too complex or uncertain. Therefore, many researchers have been seeking automatic methods for generating the FIS [2]. The main issues for designing an FIS are structure identification and parameter estimation. Structure identification is concerned with how to partition the input space and determine the number of fuzzy rules according to the task requirements while parameter estimation involves the determination of parameters for both premises and consequents of fuzzy rules [3]. Structure identification and input classification can be accomplished by Supervised Learning (SL), Unsupervised Learning (UL) and Reinforcement Learning (RL). SL is a learning approach that adopts a supervisor, through which, the training system can adjust the structure and parameters according to a given training data set. In [4], the author provided a paradigm of acquiring the parameters of fuzzy rules. Besides adjusting parameters, self-identified structures have been achieved by SL approaches termed Dynamic Fuzzy Neural Networks in [3] and Generalized Dynamic Fuzzy Neural Networks in [5]. However, the training data are not always available especially when a human being has little knowledge about the system or the system is uncertain. In those situations, UL and RL are preferred over SL as UL and RL are learning processes that do not need any supervisor to tell the learner what action to take. Through RL, those state-action pairs which achieve positive reward will be encouraged in future selections while those which produce negative reward will be discouraged. A number of researchers have applied RL to train the consequent parts of an FIS [6.8]. The preconditioning parts of the FIS are either predefined as in [6] or through the ε-completeness and the squared TD error criteria in [7] or through the “aligned clustering” in [8]. Both DFQL and CQGAF methods achieve online structure identification by creating fuzzy rules when the input space is not well partitioned. However, both methods cannot adjust the premise parameters except when creating new rules. The center position and width of fuzzy neurons are allocated by only considering the input clustering. Moreover, both methods cannot delete fuzzy rules once they are generated even when the rules become redundant. O pe n A cc es s D at ab as e w w w .in te ch w eb .o rg},
	urldate = {2023-01-03},
	author = {Zhou, Yi and Er, M.},
	year = {2012},
}
